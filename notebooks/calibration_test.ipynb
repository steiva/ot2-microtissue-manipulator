{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the upstream directory to sys.path\n",
    "upstream_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if upstream_dir not in sys.path:\n",
    "    sys.path.insert(0, upstream_dir)\n",
    "\n",
    "# Now you can import the module\n",
    "from opentrons_api import ot2_api\n",
    "from microtissue_manipulator import core, utils, camera\n",
    "import numpy as np \n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import keyboard\n",
    "# from pynput import keyboard\n",
    "import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import datetime\n",
    "import threading\n",
    "import queue\n",
    "import string\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from dataclasses import dataclass, fields, asdict, MISSING\n",
    "from typing import get_type_hints, get_origin, get_args, Tuple, List, Dict, Any, Union\n",
    "from ultralytics import YOLO\n",
    "from enum import Enum\n",
    "# from typeguard import typechecked\n",
    "# from typeguard import install_import_hook\n",
    "# install_import_hook('__main__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected cameras:\n",
      "{'underview_cam': 'Arducam B0478 (USB3 48MP)', 'overview_cam': 'HD USB Camera'}\n"
     ]
    }
   ],
   "source": [
    "cam_manager = camera.CameraManagerWindows()\n",
    "print(\"Connected cameras:\")\n",
    "print(cam_manager.list_labels())\n",
    "\n",
    "under_cam = camera.open_capture('underview_cam', cam_manager=cam_manager, resolution = (2000,1500), focus = 940)\n",
    "over_cam = camera.open_capture('overview_cam', cam_manager=cam_manager)\n",
    "frame_ops = camera.frameOperations(*over_cam.shape[0:-1])\n",
    "\n",
    "calibration_profile = 'checkerboard'\n",
    "frame_ops.load_camera_intrinsics(config_profile=calibration_profile, use_new_cam_mtx=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam = camera.open_capture('underview_cam', cam_manager=cam_manager, resolution = (4000,3000), focus = 940)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on camera\n",
    "# calibration_profile = 'checkerboard'\n",
    "# cap = core.Camera(1, config_profile=calibration_profile, use_new_cam_mtx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_cam = camera.open_capture('overview_cam', cam_manager=cam_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam = camera.open_capture('underview_cam', cam_manager=cam_manager, resolution = (2000,1500), focus = 890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "\n",
    "# manual_movement = utils.ManualRobotMovement(openapi)\n",
    "capture = under_cam\n",
    "if not capture.is_opened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "else:\n",
    "    print(\"Streaming video. Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        # frame = frame_ops.undistort_frame(frame)\n",
    "\n",
    "        cv2.imshow(\"video\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            save_dir = \"../outputs/images/over_cam_cuboid_dataset\"\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"frame_{timestamp}.png\"\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "            cv2.imwrite(filepath, frame)\n",
    "            print(f\"Frame saved as {filepath}\")\n",
    "\n",
    "# capture.release()\n",
    "# keyboard.unhook_all()  # Unhook all keyboard listeners\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(paths.ML_MODELS_DIR,'tip_detector_v1.pt')\n",
    "model = YOLO(model_path)\n",
    "# Run inference\n",
    "frame = frame[..., ::-1]  # Convert BGR to RGB as YOLO expects RGB input\n",
    "results = model.predict(source=frame, save=False, imgsz=640,conf=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # 0 is the default camera\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture.\")\n",
    "else:\n",
    "    print(\"Video capture opened successfully.\")\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 8000)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 6000)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'YUY2'))\n",
    "\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "\n",
    "def set_focus(val):\n",
    "    cap.set(cv2.CAP_PROP_FOCUS, val)\n",
    "set_focus(900)\n",
    "\n",
    "\n",
    "circle_center = (0, 0)\n",
    "\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    global circle_center\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        circle_center = (x, y)\n",
    "        print(f\"Circle center set to: {circle_center}\")\n",
    "\n",
    "cv2.setMouseCallback('video', draw_circle)\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if circle_center != (0, 0):\n",
    "        cv2.circle(frame, circle_center, 475, (0, 255, 0), 2)\n",
    "    cv2.imshow('video', frame)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == ord('s'):\n",
    "        print(\"frame saved\")\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # filename = f'../outputs/images/underneath_dataset/saved_frame_{timestamp}.png'\n",
    "        filename = f'../outputs/images/underneath_cuboids/saved_frame_{timestamp}.png'\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "keyboard.unhook_all()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = cap.get_window()\n",
    "\n",
    "robot_coords = []\n",
    "camera_coords = []\n",
    "\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "    elif key_pressed == ord('s'):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y_%m_%d_%H-%M-%S')\n",
    "        filename = f\"frame_{timestamp}.png\"\n",
    "        cv2.imwrite(os.path.join(paths.BASE_DIR, 'outputs', 'images', 'segmentation_test', filename), frame)\n",
    "        print(f\"Frame saved as {filename}\")\n",
    "   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the robot to the computer and this notebook\n",
    "openapi = ot2_api.OpentronsAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.add_slot_offsets([5,8], (0,0,65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the light control to see if the robot is connected as a sanity check\n",
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [200]>\n",
      "{\n",
      "  \"message\": \"Homing robot.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always do once after robot was just turned on\n",
    "openapi.home_robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of runs: 14\n",
      "Current run ID: 0c570c52-24ca-41f3-8706-c01128eae8ba\n",
      "Current run status: idle\n"
     ]
    }
   ],
   "source": [
    "# Use to restore labware and general run information after the notebook crashes\n",
    "r = openapi.get_run_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.retract_axis('leftZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [201]>\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": \"0c570c52-24ca-41f3-8706-c01128eae8ba\",\n",
      "    \"ok\": true,\n",
      "    \"createdAt\": \"2025-05-24T10:44:32.597082Z\",\n",
      "    \"status\": \"idle\",\n",
      "    \"current\": true,\n",
      "    \"actions\": [],\n",
      "    \"errors\": [],\n",
      "    \"hasEverEnteredErrorRecovery\": false,\n",
      "    \"pipettes\": [],\n",
      "    \"modules\": [],\n",
      "    \"labware\": [],\n",
      "    \"liquids\": [],\n",
      "    \"liquidClasses\": [],\n",
      "    \"labwareOffsets\": [],\n",
      "    \"runTimeParameters\": [],\n",
      "    \"outputFileIds\": []\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do after first launch\n",
    "openapi.create_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [201]>\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": \"049f78eb-2417-4dce-af30-86131a6b0e36\",\n",
      "    \"createdAt\": \"2025-05-24T10:44:33.329572Z\",\n",
      "    \"commandType\": \"loadPipette\",\n",
      "    \"key\": \"049f78eb-2417-4dce-af30-86131a6b0e36\",\n",
      "    \"status\": \"succeeded\",\n",
      "    \"params\": {\n",
      "      \"pipetteName\": \"p300_single_gen2\",\n",
      "      \"mount\": \"left\"\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"pipetteId\": \"ad702c56-f804-4bfb-8e67-95dde6ccd3fe\"\n",
      "    },\n",
      "    \"startedAt\": \"2025-05-24T10:44:33.332814Z\",\n",
      "    \"completedAt\": \"2025-05-24T10:44:35.294747Z\",\n",
      "    \"intent\": \"setup\",\n",
      "    \"notes\": []\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let the robot know that it has the P300 pipette\n",
    "openapi.load_pipette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_coordinates((300,50,115), min_z_height=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.control_run(\"stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under cam auto calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam = camera.open_capture('underview_cam', cam_manager=cam_manager, resolution = (2000,1500), focus = 940)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robot coordinate system gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tip_coordinates(results):\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if model.names[cls] == 'tip':\n",
    "                tip_coords = ((int(box.xyxy[0][0]) + int(box.xyxy[0][2])) // 2, \n",
    "                                (int(box.xyxy[0][1]) + int(box.xyxy[0][3])) // 2)\n",
    "                return tip_coords\n",
    "\n",
    "movements = [None,('x', 3), ('y', 3)]\n",
    "\n",
    "capture = under_cam\n",
    "if not capture.is_opened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "else:\n",
    "    for movement in movements:\n",
    "        if movement is not None:\n",
    "            axis, distance = movement\n",
    "            openapi.move_relative(axis, distance)\n",
    "            time.sleep(1)\n",
    "        time.sleep(0.5)\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame from video stream.\")\n",
    "        else:   \n",
    "            frame = frame[..., ::-1]  # Convert BGR to RGB as YOLO expects RGB input\n",
    "            results = model.predict(\n",
    "                    source=frame,  # Now pointing to a directory instead of a single file\n",
    "                    conf=0.25,         # Confidence threshold\n",
    "                    save=False,         # Save the annotated images\n",
    "                    save_txt=False,    # Save YOLO-format prediction labels (optional)\n",
    "                    show=False,         # Show images in pop-up windows (if GUI available)\n",
    "                    imgsz=2000,\n",
    "                    verbose = False        # Ensure inference matches your training resolution\n",
    "                )\n",
    "            tip_coords = get_tip_coordinates(results)\n",
    "            print(f\"Tip coordinates: {tip_coords}\")\n",
    "        if movement is not None:\n",
    "            openapi.move_relative(axis, -distance)\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find distance to tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_movement = utils.ManualRobotMovement(openapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('x', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard.unhook_all()  # Unhook all keyboard listeners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under_cam = camera.open_capture('underview_cam', cam_manager=cam_manager, resolution = (2000,1500), focus = 920)\n",
    "\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "model_path = os.path.join(paths.ML_MODELS_DIR,'tip_detector_v1.pt')\n",
    "model = YOLO(model_path)\n",
    "\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "capture = under_cam\n",
    "if not capture.is_opened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "else:\n",
    "    print(\"Streaming video. Press 'q' to quit.\")\n",
    "    while True:\n",
    "        # if not capture.is_opened() or not capture.frame_ready.value:\n",
    "        #     print(\"frame not ready or capture not opened, skipping frame.\")\n",
    "        #     continue\n",
    "        ret, frame = capture.read()\n",
    "        frame = frame[..., ::-1]  # Convert BGR to RGB as YOLO expects RGB input\n",
    "        results = model.predict(\n",
    "                source=frame,  # Now pointing to a directory instead of a single file\n",
    "                conf=0.25,         # Confidence threshold\n",
    "                save=False,         # Save the annotated images\n",
    "                save_txt=False,    # Save YOLO-format prediction labels (optional)\n",
    "                show=False,         # Show images in pop-up windows (if GUI available)\n",
    "                imgsz=2016,\n",
    "                verbose = False               # Ensure inference matches your training resolution\n",
    "            )\n",
    "\n",
    "        image = frame.copy()\n",
    "        image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "        data = []\n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                data.append({'class': model.names[cls], 'confidence': conf, 'center_x': center_x, 'center_y': center_y})\n",
    "\n",
    "        # Create a dataframe\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Calculate the distance of each \"point\" to the center of the frame\n",
    "        # df['distance_to_center'] = ((df['center_x'] - image_center[0]) ** 2 + (df['center_y'] - image_center[1]) ** 2) ** 0.5\n",
    "\n",
    "        # # Identify the closest \"point\" to the center of the frame\n",
    "        # df['is_closest_to_center'] = (df['class'] == 'point') & (df['distance_to_center'] == df.loc[df['class'] == 'point', 'distance_to_center'].min()) & (df['distance_to_center'] < 100)\n",
    "\n",
    "        # if df['is_closest_to_center'].any():\n",
    "        #     distances_from_closest = np.sqrt(\n",
    "        #         (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_x'].values[0] - df.loc[df['class'] == 'point', 'center_x'])**2 +\n",
    "        #         (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_y'].values[0] - df.loc[df['class'] == 'point', 'center_y'])**2\n",
    "        #     )\n",
    "        #     distances_from_closest = distances_from_closest[distances_from_closest > 0]\n",
    "        #     linear_distance_ratio = 20.25 / np.mean(distances_from_closest)\n",
    "        #      # Calculate the distance from the center-most \"point\" class to the \"tip\" class\n",
    "        #     center_point_coords = df.loc[df['is_closest_to_center'], ['center_x', 'center_y']].values[0]\n",
    "        #     # tip_coords = df.loc[df['class'] == 'tip', ['center_x', 'center_y']].values[0]\n",
    "\n",
    "        #     # x_dist_to_tip = center_point_coords[0] - tip_coords[0]\n",
    "        #     # y_dist_to_tip = center_point_coords[1] - tip_coords[1]\n",
    "        #     # print(x_dist_to_tip, y_dist_to_tip)\n",
    "\n",
    "        #     # y_dist_to_tip_mm = x_dist_to_tip * linear_distance_ratio\n",
    "        #     # x_dist_to_tip_mm = y_dist_to_tip * linear_distance_ratio\n",
    "        #     # print(f\"x_dist_to_tip_mm: {x_dist_to_tip_mm}, y_dist_to_tip_mm: {y_dist_to_tip_mm}\")\n",
    "\n",
    "        #     # Draw center point coordinates\n",
    "        #     cv2.circle(image, tuple(center_point_coords), 3, (0, 255, 0), -1)  # Green circle\n",
    "        #     cv2.putText(image, f\"Center {tuple(center_point_coords)}\", tuple(center_point_coords), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw tip coordinates\n",
    "        # cv2.circle(image, tuple(tip_coords), 3, (0, 0, 255), -1)  # Red circle\n",
    "        # cv2.putText(image, f\"Tip {tuple(tip_coords)}\", tuple(tip_coords), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"video\", image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "# capture.release()\n",
    "keyboard.unhook_all()  # Unhook all keyboard listeners\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_frame = frame.copy()\n",
    "for idx, row in df.iterrows():\n",
    "    center = (int(row['center_x']), int(row['center_y']))\n",
    "    label = f\"{row['class']}\"\n",
    "    cv2.circle(output_frame, center, 5, (0, 255, 0), -1)\n",
    "    cv2.putText(output_frame, label, (center[0] + 10, center[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    conf_text = f\"{row['confidence']:.2f}\"\n",
    "    cv2.putText(output_frame, conf_text, (center[0] + 10, center[1] + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"video\", output_frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"output_frame.png\", output_frame)\n",
    "print(\"Output frame saved as output_frame.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('x', x_dist_to_tip_mm)\n",
    "openapi.move_relative('y', y_dist_to_tip_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labware offsets to a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\n",
    "#   \"data\": {\n",
    "#     \"definitionUri\": \"opentrons/corning_384_wellplate_112ul_flat/1\",\n",
    "#     \"locationSequence\": [\n",
    "#       {\n",
    "#         \"kind\": \"onAddressableArea\",\n",
    "#         \"addressableAreaName\": \"3\"\n",
    "#       }\n",
    "#     ],\n",
    "#     \"vector\": {\n",
    "#       \"x\": 0,\n",
    "#       \"y\": 0,\n",
    "#       \"z\": 65\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "\n",
    "data = {\n",
    "    \"data\": {\n",
    "                \"definitionUri\": \"opentrons/corning_24_wellplate_3.4ml_flat/1\",\n",
    "                \"location\": {\n",
    "                    \"slotName\": \"3\",\n",
    "                    },\n",
    "                \"vector\": {\n",
    "                    \"x\": 0,\n",
    "                    \"y\": 0,\n",
    "                    \"z\": 65\n",
    "                    }\n",
    "}\n",
    "}\n",
    "payload = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(url = openapi.BASE_URL+'/runs/'+openapi.run_id +'/labware_offsets', headers = openapi.HEADERS, data = payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"data\": {\n",
    "#         \"labwareOffsets\": [\n",
    "#             {\n",
    "#                 \"definitionUri\": \"opentrons/corning_384_wellplate_112ul_flat/1\",\n",
    "#                 \"location\": {\n",
    "#                     \"slotName\": \"6\",\n",
    "#                     },\n",
    "#                 \"vector\": {\n",
    "#                     \"x\": 0,\n",
    "#                     \"y\": 0,\n",
    "#                     \"z\": 65\n",
    "#                     }\n",
    "#             }\n",
    "#     ]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# data = {\n",
    "#   \"data\": {\n",
    "#     \"definitionUri\": \"opentrons/corning_384_wellplate_112ul_flat/1\",\n",
    "#     \"locationSequence\": [\n",
    "#       {\n",
    "#         \"kind\": \"onAddressableArea\",\n",
    "#         \"addressableAreaName\": \"3\"\n",
    "#       },\n",
    "#       {\n",
    "#         \"kind\": \"onAddressableArea\",\n",
    "#         \"addressableAreaName\": \"6\"\n",
    "#       }\n",
    "#     ],\n",
    "#     \"vector\": {\n",
    "#       \"x\": 0,\n",
    "#       \"y\": 0,\n",
    "#       \"z\": 65\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# payload = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(url = openapi.BASE_URL+'/labwareOffsets', headers = openapi.HEADERS, data = payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url = openapi.BASE_URL+'/labwareOffsets', headers = openapi.HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.post(\"runs\", openapi.HEADERS, data = json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_dict = {\n",
    "            \"data\": {\n",
    "                \"commandType\": \"verifyTipPresence\",\n",
    "                \"params\": {\n",
    "                    \"pipetteId\": openapi.pipette_id,\n",
    "                    \"expectedState\": \"present\",\n",
    "                },\n",
    "                \"intent\": \"setup\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "command_payload = json.dumps(command_dict)\n",
    "r = openapi.post(\"commands\", headers = openapi.HEADERS,\n",
    "                params={\"waitUntilComplete\": True}, data = command_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labware declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opentrons 300 ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a tip rack. This is the default tip rack for the robot.\n",
    "TIP_RACK = \"opentrons_96_tiprack_300ul\"\n",
    "#Load the tip rack. Slot = 1 by default.\n",
    "r = openapi.load_labware(TIP_RACK, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.pick_up_tip(openapi.labware_dct['11'], \"A1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWR 200ul Wide bore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_labware_path = os.path.join(paths.BASE_DIR,'protocols','vwr_96_tiprack_200ul.json')\n",
    "with open(custom_labware_path, 'r') as json_file:\n",
    "    custom_labware = json.load(json_file)\n",
    "\n",
    "command_dict = {\n",
    "            \"data\": custom_labware\n",
    "        }\n",
    "\n",
    "command_payload = json.dumps(command_dict)\n",
    "\n",
    "url = openapi.get_url('runs')+ f'/{openapi.run_id}/'+ 'labware_definitions'\n",
    "r = requests.post(url = url, headers = openapi.HEADERS, params = {\"waitUntilComplete\": True}, data = command_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a tip rack. This is the default tip rack for the robot.\n",
    "TIP_RACK = \"wide_bore_200ul\"\n",
    "#Load the tip rack. Slot = 1 by default.\n",
    "openapi.load_labware(TIP_RACK, 10, namespace='custom_beta',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.pick_up_tip(openapi.labware_dct['10'], \"A1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip_in_place()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VWR 200 ul XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_labware_path = os.path.join(paths.BASE_DIR,'protocols','vwr_96_tiprack_200ul_xl.json')\n",
    "with open(custom_labware_path, 'r') as json_file:\n",
    "    custom_labware = json.load(json_file)\n",
    "\n",
    "command_dict = {\n",
    "            \"data\": custom_labware\n",
    "        }\n",
    "\n",
    "command_payload = json.dumps(command_dict)\n",
    "\n",
    "url = openapi.get_url('runs')+ f'/{openapi.run_id}/'+ 'labware_definitions'\n",
    "r = requests.post(url = url, headers = openapi.HEADERS, params = {\"waitUntilComplete\": True}, data = command_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labware ID:\n",
      "b12c76a9-b751-407b-9e5a-1233a6ba4d70\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a tip rack. This is the default tip rack for the robot.\n",
    "TIP_RACK = \"vwr_96_tiprack_200ul_xl\"\n",
    "#Load the tip rack. Slot = 1 by default.\n",
    "openapi.load_labware(TIP_RACK, 10, namespace='custom_beta',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.pick_up_tip(openapi.labware_dct['10'], \"B4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoir and well plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labware ID:\n",
      "17683673-e918-4c05-aada-0f2d8ca88c28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RESERVOIR = \"corning_6_wellplate_16.8ml_flat\"\n",
    "r = openapi.load_labware(RESERVOIR, 4, namespace='opentrons',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset (0, 0, 65) added to run for corning_96_wellplate_360ul_flat in slot 5.\n",
      "Labware URI:\n",
      "opentrons/corning_96_wellplate_360ul_flat/1\n",
      "\n",
      "Check offset before using ...\n",
      "Labware ID:\n",
      "a65ff2f7-dc2a-4185-93d4-d60001846f44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WELL_PLATE = \"corning_96_wellplate_360ul_flat\"\n",
    "# WELL_PLATE = \"corning_24_wellplate_3.4ml_flat\"\n",
    "# WELL_PLATE = \"corning_384_wellplate_112ul_flat\"\n",
    "r = openapi.load_labware(WELL_PLATE, 5, namespace='opentrons',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip(openapi.labware_dct['10'], \"B11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='center', volume = 70, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_well(openapi.labware_dct['4'], \"A1\", well_location='top', offset=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_labware(openapi.labware_dct['8'], new_location='offDeck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_rate = 200\n",
    "volume = 100\n",
    "\n",
    "openapi.aspirate_in_place(flow_rate = flow_rate, volume = volume, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_rate = 200\n",
    "volume = 100\n",
    "openapi.dispense_in_place(flow_rate = flow_rate, volume = volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling a well plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rinse pipette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rinse_location = 3\n",
    "well_to_wash = \"A1\"\n",
    "well_to_rinse = \"B1\"\n",
    "for i in range(3):\n",
    "    openapi.aspirate(openapi.labware_dct[str(rinse_location)], well_to_wash, well_location='bottom', offset=(0,0,1), volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct[str(rinse_location)], well_to_wash, well_location='bottom', offset=(0,0,1), volume = 100, flow_rate = 200)\n",
    "\n",
    "for i in range(3):\n",
    "    openapi.aspirate(openapi.labware_dct[str(rinse_location)], well_to_rinse, well_location='bottom', offset=(0,0,1), volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct[str(rinse_location)], well_to_rinse, well_location='bottom', offset=(0,0,1), volume = 100, flow_rate = 200)\n",
    "\n",
    "openapi.move_to_well(openapi.labware_dct[str(rinse_location)], well_to_rinse, well_location='top', offset=(0,0,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_well(openapi.labware_dct['5'], \"H2\", well_location='bottom', offset=(-1.5,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_movement = utils.ManualRobotMovement(openapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.get_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard.unhook_all()  # Unhook all keyboard listeners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take solution off the well palte with cuboids\n",
    "\n",
    "columns = list(range(1,5))\n",
    "# rows = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "rows = ['A']\n",
    "x_offset = -1.5\n",
    "y_offset = 0\n",
    "z_offset = 0\n",
    "takeoff_volume = 100\n",
    "\n",
    "row_idx = 0\n",
    "column_idx = 0\n",
    "\n",
    "while row_idx < len(rows):\n",
    "    row = rows[row_idx]\n",
    "    while column_idx < len(columns):\n",
    "        column = columns[column_idx]\n",
    "        # r = openapi.aspirate(openapi.labware_dct['5'], f\"{row}{column}\", well_location = 'center', offset = (x_offset, y_offset, -2), volume = takeoff_volume//2, flow_rate = 20)\n",
    "        # responce_dict = json.loads(r.text)['data']\n",
    "        r = openapi.aspirate(openapi.labware_dct['5'], f\"{row}{column}\", well_location = 'bottom', offset = (x_offset, y_offset, z_offset), volume = takeoff_volume, flow_rate = 10)\n",
    "        openapi.move_relative('z', 20)\n",
    "        responce_dict = json.loads(r.text)['data']\n",
    "        if responce_dict['status'] == 'failed':\n",
    "            if responce_dict['error']['errorType'] == 'InvalidAspirateVolumeError':\n",
    "                print('Dumping fluid')\n",
    "                openapi.blow_out(openapi.labware_dct['4'], \"A2\", well_location='center', flow_rate = 200)\n",
    "        else:\n",
    "            column_idx += 1\n",
    "    column_idx = 0\n",
    "    row_idx += 1\n",
    "\n",
    "openapi.blow_out(openapi.labware_dct['4'], \"A2\", well_location='center', flow_rate = 200)\n",
    "openapi.move_relative('z', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out(openapi.labware_dct['5'], \"A1\", well_location='top', flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.dispense(openapi.labware_dct['3'], f\"A1\", well_location = 'center', volume = 70, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.move_to_well(openapi.labware_dct['5'], \"A1\", well_location='top', offset=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refilling pipette\n",
      "Refilling pipette\n",
      "Refilling pipette\n",
      "Refilling pipette\n",
      "Refilling pipette\n",
      "Refilling pipette\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.retract_axis('leftZ')\n",
    "\n",
    "columns = list(range(1,13))\n",
    "# rows = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "rows = ['G']\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "\n",
    "row_idx = 0\n",
    "column_idx = 0\n",
    "\n",
    "while row_idx < len(rows):\n",
    "    row = rows[row_idx]\n",
    "    while column_idx < len(columns):\n",
    "        column = columns[column_idx]\n",
    "        r = openapi.dispense(openapi.labware_dct['5'], f\"{row}{column}\", well_location = 'bottom', offset = (x_offset, y_offset, 0), volume = 100, flow_rate = 200)\n",
    "        openapi.move_relative('z', 20)\n",
    "        responce_dict = json.loads(r.text)['data']\n",
    "        if responce_dict['status'] == 'failed':\n",
    "            if responce_dict['error']['errorType'] == 'InvalidDispenseVolumeError':\n",
    "                print('Refilling pipette')\n",
    "                openapi.aspirate(openapi.labware_dct['4'], \"A1\", well_location ='bottom', volume = 200, flow_rate = 200)\n",
    "        else:\n",
    "            column_idx += 1\n",
    "    column_idx = 0\n",
    "    row_idx += 1\n",
    "\n",
    "openapi.blow_out(openapi.labware_dct['4'], \"A1\", well_location='center', flow_rate = 200)\n",
    "openapi.aspirate(openapi.labware_dct['4'], \"A2\", volume = 50, flow_rate = 200)\n",
    "openapi.dispense(openapi.labware_dct['4'], \"A2\", volume = 50, flow_rate = 200)\n",
    "openapi.retract_axis('leftZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.blow_out(openapi.labware_dct['4'], \"A1\", well_location='center', flow_rate = 200)\n",
    "openapi.aspirate(openapi.labware_dct['4'], \"A2\", volume = 50, flow_rate = 200)\n",
    "openapi.dispense(openapi.labware_dct['4'], \"A2\", volume = 50, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.aspirate(openapi.labware_dct['4'], \"A1\", well_location='bottom', volume = 10, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.dispense(openapi.labware_dct['4'], \"A1\", volume = 10, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(r.text)['data']['error']['errorType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot <-> camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Emergency stop! Shutting down...\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n",
      "\n",
      "[CONTROL] Robot RESUMED\n"
     ]
    }
   ],
   "source": [
    "squaresX=7\n",
    "squaresY=5 \n",
    "squareLength=0.022\n",
    "markerLength=0.011\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "params = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "board = cv2.aruco.CharucoBoard((squaresX, squaresY), squareLength, markerLength, aruco_dict)\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "calib_origin = calibration_data['calib_origin']\n",
    "openapi.move_to_coordinates(calib_origin, min_z_height=1, verbose=False)\n",
    "\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "\n",
    "robot_coords = []\n",
    "camera_coords = []\n",
    "\n",
    "while True:\n",
    " # Capture frame-by-frame\n",
    "    ret, frame = over_cam.read()\n",
    "    frame = frame_ops.undistort_frame(frame)\n",
    "\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 100), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    center_screen_x = frame.shape[1] // 2\n",
    "    center_screen_y = frame.shape[0] // 2\n",
    "    cv2.circle(frame, (center_screen_x, center_screen_y), 5, (0, 0, 255), -1)\n",
    "    cv2.putText(frame, f\"Center: ({center_screen_x}, {center_screen_y})\", (center_screen_x + 10, center_screen_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Calculate the center of each quarter of the screen\n",
    "    quarter_centers = [\n",
    "        (center_screen_x // 2, center_screen_y // 2),\n",
    "        (3 * center_screen_x // 2, center_screen_y // 2),\n",
    "        (center_screen_x // 2, 3 * center_screen_y // 2),\n",
    "        (3 * center_screen_x // 2, 3 * center_screen_y // 2)\n",
    "    ]\n",
    "\n",
    "    # Draw circles at the center of each quarter\n",
    "    for qx, qy in quarter_centers:\n",
    "        cv2.circle(frame, (qx, qy), 5, (0, 255, 255), -1)\n",
    "        cv2.putText(frame, f\"({qx}, {qy})\", (qx + 10, qy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(frame)\n",
    "    if marker_corners:\n",
    "        for corner in marker_corners:\n",
    "            corner = corner.reshape((4, 2))\n",
    "            for point in corner:\n",
    "                cv2.circle(frame, tuple(point.astype(int)), 5, (0, 255, 0), -1)\n",
    "\n",
    "            center_x = int(np.mean(corner[:, 0]))\n",
    "            center_y = int(np.mean(corner[:, 1]))\n",
    "            cv2.circle(frame, (center_x, center_y), 5, (255, 0, 0), -1)\n",
    "            cv2.putText(frame, f\"({center_x}, {center_y})\", (center_x + 10, center_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Calculate side lengths\n",
    "    side_lengths = []\n",
    "    if marker_corners:\n",
    "        for corner in marker_corners[0]:\n",
    "            for i in range(4):\n",
    "                side_length = np.linalg.norm(corner[i] - corner[(i + 1) % 4])\n",
    "                side_lengths.append(side_length)\n",
    "\n",
    "    # Calculate the average side length\n",
    "        average_side_length = np.mean(side_lengths)\n",
    "        area = cv2.contourArea(marker_corners[0])\n",
    "        one_d_ratio = 13.83 / average_side_length\n",
    "        size_conversion_ratio = 13.83 ** 2 / area\n",
    "        cv2.putText(frame, f\"Area of marker: {area:.2f}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"video\", frame)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "    elif key_pressed == ord('s'):\n",
    "        x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "        robot_coords.append((x, y))\n",
    "        camera_coords.append((center_x, center_y))\n",
    "\n",
    "# When everything done, release the capture\n",
    "# cap.release_camera()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "calibration_data['size_conversion_ratio'] = size_conversion_ratio\n",
    "calibration_data['one_d_ratio'] = one_d_ratio\n",
    "utils.save_calibration_config(calibration_profile, calibration_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 5  # Distance from the calib_point in mm\n",
    "\n",
    "# Calculate the four coordinates\n",
    "calibration_points = [\n",
    "    (calib_origin[0] + spacing, calib_origin[1] + spacing),  # Right\n",
    "    (calib_origin[0] + spacing, calib_origin[1] - spacing),  # Left\n",
    "    (calib_origin[0] - spacing, calib_origin[1] - spacing),  # Up\n",
    "    (calib_origin[0] - spacing, calib_origin[1] + spacing)   # Down\n",
    "]\n",
    "\n",
    "robot_coords = []\n",
    "camera_coords = []\n",
    "\n",
    "\n",
    "# window = cap.get_window()\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "\n",
    "for calib_pt in calibration_points:\n",
    "    openapi.move_to_coordinates((*calib_pt, 100), min_z_height=1, verbose=False)\n",
    "    cv2.waitKey(1000)\n",
    "    # frame = cap.get_frame(undist=True)\n",
    "    ret, frame = over_cam.read()\n",
    "    frame = frame_ops.undistort_frame(frame)\n",
    "    \n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    center_screen_x = frame.shape[1] // 2\n",
    "    center_screen_y = frame.shape[0] // 2\n",
    "    cv2.circle(frame, (center_screen_x, center_screen_y), 5, (0, 0, 255), -1)\n",
    "    cv2.putText(frame, f\"Center: ({center_screen_x}, {center_screen_y})\", (center_screen_x + 10, center_screen_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Calculate the center of each quarter of the screen\n",
    "    quarter_centers = [\n",
    "        (center_screen_x // 2, center_screen_y // 2),\n",
    "        (3 * center_screen_x // 2, center_screen_y // 2),\n",
    "        (center_screen_x // 2, 3 * center_screen_y // 2),\n",
    "        (3 * center_screen_x // 2, 3 * center_screen_y // 2)\n",
    "    ]\n",
    "\n",
    "    # Draw circles at the center of each quarter\n",
    "    for qx, qy in quarter_centers:\n",
    "        cv2.circle(frame, (qx, qy), 5, (0, 255, 255), -1)\n",
    "        cv2.putText(frame, f\"({qx}, {qy})\", (qx + 10, qy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(frame)\n",
    "    if marker_corners:\n",
    "        for corner in marker_corners:\n",
    "            corner = corner.reshape((4, 2))\n",
    "            for point in corner:\n",
    "                cv2.circle(frame, tuple(point.astype(int)), 5, (0, 255, 0), -1)\n",
    "\n",
    "            center_x = int(np.mean(corner[:, 0]))\n",
    "            center_y = int(np.mean(corner[:, 1]))\n",
    "            cv2.circle(frame, (center_x, center_y), 5, (255, 0, 0), -1)\n",
    "            cv2.putText(frame, f\"({center_x}, {center_y})\", (center_x + 10, center_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "    cv2.imshow(\"video\", frame)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    robot_coords.append((x, y))\n",
    "    camera_coords.append((center_x, center_y))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "camera_coords = utils.sort_coordinates(camera_coords)\n",
    "robot_coords = utils.sort_coordinates(robot_coords, reverse_y=True)\n",
    "\n",
    "robot_to_camera_coords = {tuple(robot_coord): tuple(camera_coord) for robot_coord, camera_coord in zip(robot_coords, camera_coords)}\n",
    "tf_mtx = utils.compute_tf_mtx(robot_to_camera_coords)\n",
    "\n",
    "calibration_data['tf_mtx'] = tf_mtx.tolist()\n",
    "\n",
    "utils.save_calibration_config(calibration_profile, calibration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipette offset calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    global circle_center\n",
    "    global circle_radius\n",
    "    global filtered_contours\n",
    "    global X_init, Y_init\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONDOWN:\n",
    "        circle_center = (x, y)\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            circle_radius += 10\n",
    "        else:\n",
    "            circle_radius -= 10\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        for contour in filtered_contours:\n",
    "            r=cv2.pointPolygonTest(contour, (x,y), False)\n",
    "            if r>0:\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "                    x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                    diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "                    X = X_init + diff[0] + offset[0]\n",
    "                    Y = Y_init + diff[1] + offset[1]\n",
    "                    \n",
    "                    print(f\"Robot coords: ({x}, {y})\")\n",
    "                    print(f\"Clicked on: ({X}, {Y})\")\n",
    "                    openapi.move_to_coordinates((X, Y, 69), min_z_height=1, verbose=False)\n",
    "                    # openapi.aspirate_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Contour center could not be found\")\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False)\n",
    "\n",
    "        \n",
    "\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "circle_center = (int(1296.0), int(972.0))\n",
    "circle_radius = 300\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.circle(frame, circle_center, circle_radius, (255, 0, 0), 2)\n",
    "    # Create a mask with the same dimensions as the frame\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "\n",
    "    # Draw a filled circle on the mask\n",
    "    cv2.circle(mask, circle_center, circle_radius, (255, 255, 255), -1)\n",
    "\n",
    "    # Apply the mask to the frame\n",
    "    masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "    # Convert the masked frame to grayscale\n",
    "    gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply thresholding to the grayscale image\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Fill the area outside the circle with black pixels\n",
    "    # Convert the mask to grayscale\n",
    "    mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "\n",
    "    # Find contours in the masked frame\n",
    "    contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter the contours to exclude the outermost\n",
    "    # filtered_contours = [contour for contour, h in zip(contours, hei[0]) if h[3] == 1]\n",
    "    # Filter the contours by size\n",
    "    filtered_contours = [contour for contour in contours if 15 < cv2.contourArea(contour) < 1000]\n",
    "    # Draw the contours on the frame\n",
    "    cv2.drawContours(frame, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "    if key_pressed == ord('o'):\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "\n",
    "        calibration_data['offset'] = [x-X_init, y-Y_init]\n",
    "\n",
    "        utils.save_calibration_config(calibration_profile, calibration_data)\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        openapi.dispense_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "    elif key_pressed == ord('a'):\n",
    "        openapi.aspirate_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "\n",
    "    elif key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosshair detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the template image\n",
    "# path = os.path.join(paths.BASE_DIR, 'outputs', 'images', 'target_template.png')\n",
    "path = os.path.join(paths.BASE_DIR, 'outputs', 'images', 'target_template_2.png')\n",
    "template = cv2.imread(path, 0)  # Replace 'template.png' with your template image path\n",
    "template_height, template_width = template.shape[:2]\n",
    "\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "# Perform multi-object detection using template matching\n",
    "# Start video stream\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    global X_init, Y_init, diff\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        for (rect_x, rect_y, rect_w, rect_h) in rectangles:\n",
    "            if rect_x <= x <= rect_x + rect_w and rect_y <= y <= rect_y + rect_h:\n",
    "                cX = rect_x + rect_w // 2\n",
    "                cY = rect_y + rect_h // 2\n",
    "\n",
    "                X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "                print('init:', X_init, Y_init)\n",
    "\n",
    "                x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "                X = X_init + diff[0] + offset[0]\n",
    "                Y = Y_init + diff[1] + offset[1]\n",
    "                \n",
    "                print(f\"Robot coords: ({x}, {y})\")\n",
    "                print(f\"Clicked on: ({X}, {Y})\")\n",
    "                # openapi.move_to_coordinates((X, Y, 66.1), min_z_height=1, verbose=False)\n",
    "                openapi.move_to_coordinates((X, Y, 70), min_z_height=1, verbose=False)\n",
    "                break\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False)\n",
    "        # openapi.move_to_coordinates((255, 145.25,100), min_z_height=1, verbose=False)\n",
    "\n",
    "# window = cap.get_window()\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "cv2.setMouseCallback(\"video\", on_mouse_click)\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    # frame = cap.get_frame(undist=True)\n",
    "    ret, frame = over_cam.read()\n",
    "    frame = frame_ops.undistort_frame(frame)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Draw the center of the frame\n",
    "    frame_center_x = frame.shape[1] // 2\n",
    "    frame_center_y = frame.shape[0] // 2\n",
    "    cv2.circle(frame, (frame_center_x, frame_center_y), 5, (0, 0, 255), -1)\n",
    "    cv2.putText(frame, \"Center\", (frame_center_x + 10, frame_center_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    assert ret, \"Failed to capture frame from over_cam.\"\n",
    "    image = frame.copy()\n",
    "    image = image[..., ::-1]  # Convert BGR to RGB as YOLO expects RGB input\n",
    "    results = model.predict(\n",
    "            source=image,  # Now pointing to a directory instead of a single file\n",
    "            conf=0.25,         # Confidence threshold\n",
    "            save=False,         # Save the annotated images\n",
    "            save_txt=False,    # Save YOLO-format prediction labels (optional)\n",
    "            show=False,         # Show images in pop-up windows (if GUI available)\n",
    "            imgsz=2016,\n",
    "            verbose = False               # Ensure inference matches your training resolution\n",
    "        )\n",
    "\n",
    "    image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "    data = []\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            data.append({'class': model.names[cls], 'confidence': conf, 'center_x': center_x, 'center_y': center_y})\n",
    "\n",
    "    # Select the point closest to the center of the image\n",
    "    if data:\n",
    "        closest_obj = min(\n",
    "            (obj for obj in data if obj['class'] == 'point'),\n",
    "            key=lambda obj: (obj['center_x'] - image_center[0]) ** 2 + (obj['center_y'] - image_center[1]) ** 2,\n",
    "            default=None\n",
    "        )\n",
    "        if closest_obj is not None:\n",
    "            cv2.circle(frame, (closest_obj['center_x'], closest_obj['center_y']), 8, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, \"Closest\", (closest_obj['center_x'] + 10, closest_obj['center_y'] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    # for obj in data:\n",
    "    #     if obj['class'] == 'point':\n",
    "    #         cv2.circle(frame, (obj['center_x'], obj['center_y']), 3, (0, 255, 255), 2)\n",
    "    # Perform template matching\n",
    "    # result = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    # min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "\n",
    "    # # Eliminate overlapping matches\n",
    "    # locations = np.where(result >= 0.7)  # Adjust the threshold as needed\n",
    "    # rectangles = []\n",
    "    # for pt in zip(*locations[::-1]):\n",
    "    #     rectangles.append([pt[0], pt[1], template_width, template_height])\n",
    "\n",
    "    # # Apply non-maximum suppression to remove overlapping rectangles\n",
    "    # rectangles, _ = cv2.groupRectangles(rectangles, groupThreshold=1, eps=0.2)\n",
    "    # for (x, y, w, h) in rectangles:\n",
    "    #     cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    #     center_x = x + w // 2\n",
    "    #     center_y = y + h // 2\n",
    "    #     cv2.circle(frame, (center_x, center_y), 3, (255, 0, 0), -1)\n",
    "    #     cv2.putText(frame, f\"({center_x}, {center_y})\", (center_x + 10, center_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow(\"video\", frame)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "    # Break the loop on 'q' key press\n",
    "    if key_pressed == ord('o'):\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "\n",
    "        x_prev = X_init + diff[0] + offset[0]\n",
    "        y_prev = Y_init + diff[1] + offset[1]\n",
    "\n",
    "        print([x-(X_init+diff[0]), y-(Y_init+diff[1])])\n",
    "        # calibration_data['offset'] = [x-X_init, y-Y_init]\n",
    "        utils.save_calibration_config(calibration_profile, calibration_data)\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        openapi.dispense_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "    elif key_pressed == ord('a'):\n",
    "        openapi.aspirate_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "\n",
    "    elif key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: 155.10688679892897 143.81938124985732\n",
      "Robot coords: (255.00000000000003, 145.25)\n",
      "Clicked on: (298.99024557676734, 222.71454798646985)\n",
      "-37 -46\n",
      "x_dist_to_tip_mm: -2.281158143648407, y_dist_to_tip_mm: -1.8348445938041533\n",
      "Actual offset applied: (-0.28115814364840697, 0.16515540619584668) mm\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(paths.BASE_DIR, 'outputs', 'images', 'target_template_2.png')\n",
    "template = cv2.imread(path, 0)  # Replace 'template.png' with your template image path\n",
    "template_height, template_width = template.shape[:2]\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "model_path = os.path.join(paths.ML_MODELS_DIR,'tip_detector_v1.pt')\n",
    "model = YOLO(model_path)\n",
    "\n",
    "\n",
    "#Settings\n",
    "calib_module_coordinates = (255, 145.25, 100)  # Coordinates for the pipette offset calibration module\n",
    "calib_module_height = 69  # Height for the pipette offset calibration module\n",
    "detection_offset_x = 2\n",
    "detection_offset_y = 2  # Offset to apply to the detected coordinates\n",
    "#Move to pipette offset calibration module:\n",
    "openapi.move_to_coordinates(calib_module_coordinates, min_z_height=calib_module_height-0.1, verbose=False)\n",
    "time.sleep(1)\n",
    "\n",
    "ret, frame = over_cam.read()\n",
    "assert ret, \"Failed to capture frame from over_cam.\"\n",
    "frame = frame_ops.undistort_frame(frame)\n",
    "image = frame.copy()\n",
    "image = image[..., ::-1]  # Convert BGR to RGB as YOLO expects RGB input\n",
    "results = model.predict(\n",
    "        source=image,  # Now pointing to a directory instead of a single file\n",
    "        conf=0.25,         # Confidence threshold\n",
    "        save=False,         # Save the annotated images\n",
    "        save_txt=False,    # Save YOLO-format prediction labels (optional)\n",
    "        show=False,         # Show images in pop-up windows (if GUI available)\n",
    "        imgsz=2016,\n",
    "        verbose = False               # Ensure inference matches your training resolution\n",
    "    )\n",
    "\n",
    "image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "data = []\n",
    "for r in results:\n",
    "    for box in r.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        center_x = (x1 + x2) // 2\n",
    "        center_y = (y1 + y2) // 2\n",
    "        data.append({'class': model.names[cls], 'confidence': conf, 'center_x': center_x, 'center_y': center_y})\n",
    "\n",
    "# Select the point closest to the center of the image\n",
    "if data:\n",
    "    closest_obj = min(\n",
    "        (obj for obj in data if obj['class'] == 'point'),\n",
    "        key=lambda obj: (obj['center_x'] - image_center[0]) ** 2 + (obj['center_y'] - image_center[1]) ** 2,\n",
    "        default=None\n",
    "    )\n",
    "    if closest_obj is not None:\n",
    "        cv2.circle(frame, (closest_obj['center_x'], closest_obj['center_y']), 8, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Closest\", (closest_obj['center_x'] + 10, closest_obj['center_y'] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "assert closest_obj is not None, \"No 'point' class detected in the image.\"\n",
    "crosshair_x, crosshair_y = closest_obj['center_x'], closest_obj['center_y']\n",
    "\n",
    "#Move to the center of the detected template\n",
    "X_init, Y_init, _ = tf_mtx @ (crosshair_x, crosshair_y, 1)\n",
    "print('init:', X_init, Y_init)\n",
    "\n",
    "x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "X = X_init + diff[0] + offset[0]\n",
    "Y = Y_init + diff[1] + offset[1]\n",
    "\n",
    "print(f\"Robot coords: ({x}, {y})\")\n",
    "print(f\"Clicked on: ({X}, {Y})\")\n",
    "openapi.move_to_coordinates((X + detection_offset_x, Y + detection_offset_y, calib_module_height), min_z_height=calib_module_height-0.1, verbose=False)\n",
    "time.sleep(1)\n",
    "\n",
    "ret, frame = under_cam.read()\n",
    "assert ret, \"Failed to capture frame from under_cam.\"\n",
    "frame = frame[..., ::-1]  # Convert BGR to RGB as YOLO expects RGB input\n",
    "results = model.predict(\n",
    "        source=frame,  # Now pointing to a directory instead of a single file\n",
    "        conf=0.25,         # Confidence threshold\n",
    "        save=False,         # Save the annotated images\n",
    "        save_txt=False,    # Save YOLO-format prediction labels (optional)\n",
    "        show=False,         # Show images in pop-up windows (if GUI available)\n",
    "        imgsz=2016,\n",
    "        verbose = False               # Ensure inference matches your training resolution\n",
    "    )\n",
    "\n",
    "image = frame.copy()\n",
    "image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "data = []\n",
    "for r in results:\n",
    "    for box in r.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        center_x = (x1 + x2) // 2\n",
    "        center_y = (y1 + y2) // 2\n",
    "        data.append({'class': model.names[cls], 'confidence': conf, 'center_x': center_x, 'center_y': center_y})\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the distance of each \"point\" to the center of the frame\n",
    "df['distance_to_center'] = ((df['center_x'] - image_center[0]) ** 2 + (df['center_y'] - image_center[1]) ** 2) ** 0.5\n",
    "\n",
    "# Identify the closest \"point\" to the center of the frame\n",
    "df['is_closest_to_center'] = (df['class'] == 'point') & (df['distance_to_center'] == df.loc[df['class'] == 'point', 'distance_to_center'].min()) & (df['distance_to_center'] < 100)\n",
    "\n",
    "if df['is_closest_to_center'].any():\n",
    "    assert 'tip' in df['class'].values and 'point' in df['class'].values, \"Both 'tip' and 'point' classes must be present in the dataframe.\"\n",
    "    distances_from_closest = np.sqrt(\n",
    "        (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_x'].values[0] - df.loc[df['class'] == 'point', 'center_x'])**2 +\n",
    "        (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_y'].values[0] - df.loc[df['class'] == 'point', 'center_y'])**2\n",
    "    )\n",
    "    distances_from_closest = distances_from_closest[distances_from_closest > 0]\n",
    "    linear_distance_ratio = 20.25 / np.mean(distances_from_closest)\n",
    "        # Calculate the distance from the center-most \"point\" class to the \"tip\" class\n",
    "    center_point_coords = df.loc[df['is_closest_to_center'], ['center_x', 'center_y']].values[0]\n",
    "    tip_coords = df.loc[df['class'] == 'tip', ['center_x', 'center_y']].values[0]\n",
    "\n",
    "    x_dist_to_tip = center_point_coords[0] - tip_coords[0]\n",
    "    y_dist_to_tip = center_point_coords[1] - tip_coords[1]\n",
    "    print(x_dist_to_tip, y_dist_to_tip)\n",
    "\n",
    "    y_dist_to_tip_mm = x_dist_to_tip * linear_distance_ratio\n",
    "    x_dist_to_tip_mm = y_dist_to_tip * linear_distance_ratio\n",
    "    print(f\"x_dist_to_tip_mm: {x_dist_to_tip_mm}, y_dist_to_tip_mm: {y_dist_to_tip_mm}\")\n",
    "\n",
    "assert x_dist_to_tip_mm and y_dist_to_tip_mm, \"Failed to calculate distances to tip.\"\n",
    "actual_offset_x = x_dist_to_tip_mm + detection_offset_x\n",
    "actual_offset_y = y_dist_to_tip_mm + detection_offset_y\n",
    "assert abs(actual_offset_x) < 40 and abs(actual_offset_y) < 40, \"Offsets are too large, please check the calibration.\"\n",
    "openapi.move_relative('x', x_dist_to_tip_mm, verbose=False)\n",
    "openapi.move_relative('y', y_dist_to_tip_mm, verbose=False)\n",
    "\n",
    "print(f\"Actual offset applied: ({actual_offset_x}, {actual_offset_y}) mm\")\n",
    "x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "calibration_data['offset'] = [x-(X_init+diff[0]), y-(Y_init+diff[1])]\n",
    "utils.save_calibration_config(calibration_profile, calibration_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_from_closest = np.sqrt(\n",
    "    (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_x'].values[0] - df.loc[df['class'] == 'tip', 'center_x'])**2 +\n",
    "    (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_y'].values[0] - df.loc[df['class'] == 'tip', 'center_y'])**2\n",
    ")\n",
    "\n",
    "distances_from_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_from_closest = np.sqrt(\n",
    "    (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_x'].values[0] - df.loc[df['class'] == 'point', 'center_x'])**2 +\n",
    "    (df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_y'].values[0] - df.loc[df['class'] == 'point', 'center_y'])**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[df['is_closest_to_center'] & (df['class'] == 'point'), 'center_x'].values[0] - df.loc[df['class'] == 'point', 'center_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_offset_x, actual_offset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dist_to_tip_mm, y_dist_to_tip_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "def on_mouse_click(event, cX, cY, flags, param):\n",
    "    global X_init, Y_init, X, Y, target_x, target_y\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        target_x, target_y = cX, cY\n",
    "        # print(\"Clicked at pixel coordinate: ({}, {})\".format(cX, cY))\n",
    "        X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "        X = X_init + diff[0] + offset[0]\n",
    "        Y = Y_init + diff[1] + offset[1]\n",
    "        print(cX, cY)\n",
    "        print(X_init, Y_init)\n",
    "        print(f\"Robot coords: ({x}, {y})\")\n",
    "        print(f\"Clicked on: ({X}, {Y})\")\n",
    "        # openapi.move_to_coordinates((X, Y, 80), min_z_height=1)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        openapi.move_to_coordinates((300, 220, 100), min_z_height=1, verbose=False)\n",
    "\n",
    "    # Use scrollwheel to change well name\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        # List of well names in 96-well plate (A1-H12)\n",
    "        if not hasattr(on_mouse_click, \"well_index\"):\n",
    "            on_mouse_click.well_index = 0\n",
    "        if not hasattr(on_mouse_click, \"well_names\"):\n",
    "            rows = \"ABCDEFGH\"\n",
    "            cols = range(1, 13)\n",
    "            on_mouse_click.well_names = [f\"{row}{col}\" for row in rows for col in cols]\n",
    "        num_wells = len(on_mouse_click.well_names)\n",
    "        # event flags: positive for scroll up, negative for scroll down\n",
    "        if flags > 0:\n",
    "            on_mouse_click.well_index = (on_mouse_click.well_index + 1) % num_wells\n",
    "        else:\n",
    "            on_mouse_click.well_index = (on_mouse_click.well_index - 1) % num_wells\n",
    "        current_well = on_mouse_click.well_names[on_mouse_click.well_index]\n",
    "        # print(f\"Selected well: {current_well}\")\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "# window = cap.get_window()\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "cv2.resizeWindow(\"video\", 1050, 1348)\n",
    "cv2.setMouseCallback(\"video\", on_mouse_click)\n",
    "\n",
    "target_x, target_y = 0, 0\n",
    "\n",
    "dish_bottom = 70# - 11.5\n",
    "pickup_offset = 0.0 #0.6\n",
    "flow_rate = 250\n",
    "volume = 50\n",
    "\n",
    "while True:\n",
    "    # frame = cap.get_frame(undist=True)\n",
    "    ret, frame = under_cam.read()\n",
    "    # frame = frame_ops.undistort_frame(frame)\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    # x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    # (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 2, 4)\n",
    "    # cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 190), (0, 0, 0), -1)\n",
    "    # cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    # cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    # cv2.putText(frame, f\"Flow rate: {flow_rate} uL/s\", (10, 250), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    # cv2.putText(frame, f\"Volume: {volume} uL\", (10, 350), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    # cv2.putText(frame, f\"Pickup height: {dish_bottom + pickup_offset} mm\", (10, 450), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "\n",
    "    center_screen_x = frame.shape[1] // 2\n",
    "    center_screen_y = frame.shape[0] // 2\n",
    "    # cv2.circle(frame, (center_screen_x, center_screen_y), 5, (0, 0, 255), -1)\n",
    "    square_size = 2250  # length of the square's side in pixels\n",
    "    top_left = (center_screen_x - square_size // 2, center_screen_y - square_size // 2)\n",
    "    bottom_right = (center_screen_x + square_size // 2, center_screen_y + square_size // 2)\n",
    "    # cv2.rectangle(frame, top_left, bottom_right, (255, 0, 0), 5)\n",
    "    # Crop the frame to the square defined by top_left and bottom_right\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "    cropped_frame = frame[y1:y2, x1:x2]\n",
    "    frame = cropped_frame\n",
    "    cv2.circle(frame, (target_x, target_y), 3, (0, 0, 255), -1)\n",
    "    # cv2.putText(frame, f\"Center: ({center_screen_x}, {center_screen_y})\", (center_screen_x + 10, center_screen_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    # (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 2, 4)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    cv2.putText(frame, f\"Flow rate: {flow_rate} uL/s\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    cv2.putText(frame, f\"Volume: {volume} uL\", (10, 300), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    if hasattr(on_mouse_click, \"well_names\") and hasattr(on_mouse_click, \"well_index\"):\n",
    "        current_well = on_mouse_click.well_names[on_mouse_click.well_index]\n",
    "        cv2.putText(frame, f\"Current well: {current_well}\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    \n",
    "    cv2.imshow(\"video\", frame)\n",
    "\n",
    "    # Draw a point at the center of the screen\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "    elif key_pressed == ord('c'):\n",
    "        x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "        calibration_data['calib_origin'] = [x, y, 115]\n",
    "        utils.save_calibration_config(calibration_profile, calibration_data)\n",
    "\n",
    "    elif key_pressed == ord('o'):\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "\n",
    "        calibration_data['offset'] = [x-X_init, y-Y_init]\n",
    "\n",
    "        utils.save_calibration_config(calibration_profile, calibration_data)\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        openapi.dispense_in_place(flow_rate = flow_rate, volume = volume)\n",
    "\n",
    "    elif key_pressed == ord('b'):\n",
    "        openapi.blow_out_in_place(50)\n",
    "\n",
    "    elif key_pressed == ord('a'):\n",
    "        openapi.aspirate_in_place(flow_rate = flow_rate, volume = volume, verbose=True)\n",
    "\n",
    "    elif key_pressed == ord('g'):\n",
    "        if current_well:\n",
    "            openapi.move_to_well(openapi.labware_dct['8'], well_name=current_well, well_location='top', offset = (0,0,20), min_z_height=70, verbose=False)\n",
    "\n",
    "    # elif key_pressed == ord('p'):\n",
    "        # openapi.move_to_coordinates((X, Y, dish_bottom+pickup_offset), min_z_height=dish_bottom)\n",
    "\n",
    "    elif key_pressed == ord('s'):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y_%m_%d_%H-%M-%S')\n",
    "        filename = f\"frame_{timestamp}.png\"\n",
    "        cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\2025-05-28_slice_test\\\\'+filename, frame)\n",
    "        print(f\"Frame saved as {filename}\")\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = openapi.get_position(verbose=False)[0].values()\n",
    "print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mtx @ (1009, 1273, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_coordinates((330, 130, 115), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(1):\n",
    "    i = 0\n",
    "    while i < 1:\n",
    "        openapi.move_to_coordinates((X + i*3, Y - k*3, dish_bottom + pickup_offset), min_z_height=1)\n",
    "        time.sleep(1)\n",
    "        openapi.move_relative('z', -pickup_offset)\n",
    "        time.sleep(1)\n",
    "        r = openapi.aspirate_in_place(flow_rate = 200, volume = 100, verbose=True)\n",
    "        responce_dict = json.loads(r.text)['data']\n",
    "\n",
    "        for _ in range(3):\n",
    "            openapi.move_relative('z', 0.2)\n",
    "            time.sleep(0.2)\n",
    "            openapi.move_relative('z', -0.2)\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        if responce_dict['status'] == 'failed':\n",
    "            if responce_dict['error']['errorType'] == 'InvalidAspirateVolumeError':\n",
    "                print('Dumping fluid')\n",
    "                openapi.move_relative('z', 50)\n",
    "                openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='bottom', flow_rate = 200)\n",
    "                openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 10, flow_rate = 200)\n",
    "                openapi.dispense_in_place(flow_rate = 200, volume = 10)\n",
    "                continue\n",
    "        else:\n",
    "            for j in range(24):\n",
    "                openapi.move_relative('z', 0.25)\n",
    "                time.sleep(0.3)\n",
    "            i += 1\n",
    "    openapi.move_relative('z', 50)\n",
    "    openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='bottom', flow_rate = 200)\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 10, flow_rate = 200)\n",
    "    openapi.dispense_in_place(flow_rate = 200, volume = 10)  \n",
    "    openapi.move_relative('z', 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('x', -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.move_to_well(openapi.labware_dct['6'], 'A1', well_location='top', offset=(0,0,5), verbose=False, force_direct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.aspirate(openapi.labware_dct['6'], \"A1\", well_location ='bottom', volume = 10, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1):\n",
    "    i = 0\n",
    "    while i < 1:\n",
    "        openapi.move_to_coordinates((X + i*3, Y - k*3, dish_bottom + pickup_offset + 3 - 0.2), min_z_height=dish_bottom)\n",
    "        time.sleep(1)\n",
    "        for j in range(6):\n",
    "            openapi.move_relative('z', -0.5)\n",
    "            r = openapi.aspirate_in_place(flow_rate = flow_rate, volume = 10, verbose=True)\n",
    "            time.sleep(0.3)\n",
    "\n",
    "        # responce_dict = json.loads(r.text)['data']\n",
    "        # if responce_dict['status'] == 'failed':\n",
    "        #     if responce_dict['error']['errorType'] == 'InvalidAspirateVolumeError':\n",
    "        #         print('Dumping fluid')\n",
    "        #         openapi.move_relative('z', 50)\n",
    "        #         openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='center', flow_rate = 200)\n",
    "        #         openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='center', volume = 10, flow_rate = 200)\n",
    "        #         openapi.dispense_in_place(flow_rate = 200, volume = 10)\n",
    "        #         continue\n",
    "        # else:\n",
    "        #     for j in range(6):\n",
    "        #         openapi.move_relative('z', 0.5)\n",
    "        #         time.sleep(0.3)\n",
    "            i += 1\n",
    "    openapi.move_relative('z', 50)\n",
    "    openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='center', flow_rate = 200)\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='center', volume = 10, flow_rate = 200)\n",
    "    openapi.dispense_in_place(flow_rate = 200, volume = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='top', flow_rate = 200)\n",
    "openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 10, flow_rate = 200)\n",
    "openapi.dispense_in_place(flow_rate = 200, volume = 10)\n",
    "openapi.move_relative('z', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 50)\n",
    "openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='center', flow_rate = 200)\n",
    "openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='center', volume = 10, flow_rate = 200)\n",
    "openapi.dispense_in_place(flow_rate = 200, volume = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='center', flow_rate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 10, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.dispense(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 200, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive around\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "def on_mouse_click(event, cX, cY, flags, param):\n",
    "    global X_init, Y_init, X, Y, target_x, target_y\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        target_x, target_y = cX, cY\n",
    "        # print(\"Clicked at pixel coordinate: ({}, {})\".format(cX, cY))\n",
    "        X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "        X = X_init + diff[0] + offset[0]\n",
    "        Y = Y_init + diff[1] + offset[1]\n",
    "        print(cX, cY)\n",
    "        print(X_init, Y_init)\n",
    "        print(f\"Robot coords: ({x}, {y})\")\n",
    "        print(f\"Clicked on: ({X}, {Y})\")\n",
    "\n",
    "        openapi.move_to_coordinates((X, Y, 70), min_z_height=65, verbose=False)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False)\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "cv2.setMouseCallback(\"video\", on_mouse_click)\n",
    "\n",
    "target_x, target_y = 0, 0\n",
    "\n",
    "dish_bottom = 70# - 11.5\n",
    "pickup_offset = 0.0 #0.6\n",
    "flow_rate = 250\n",
    "volume = 50\n",
    "\n",
    "while True:\n",
    "    ret, frame = over_cam.read()\n",
    "    frame = frame_ops.undistort_frame(frame)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 190), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Flow rate: {flow_rate} uL/s\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Volume: {volume} uL\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Pickup height: {dish_bottom + pickup_offset} mm\", (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # cv2.circle(frame, (center_screen_x, center_screen_y), 5, (0, 0, 255), -1)\n",
    "    \n",
    "    cv2.imshow(\"video\", frame)\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        openapi.dispense_in_place(flow_rate = flow_rate, volume = volume)\n",
    "\n",
    "    elif key_pressed == ord('b'):\n",
    "        openapi.blow_out_in_place(50)\n",
    "\n",
    "    elif key_pressed == ord('a'):\n",
    "        openapi.aspirate_in_place(flow_rate = flow_rate, volume = volume, verbose=True)\n",
    "\n",
    "    elif key_pressed == ord('s'):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y_%m_%d_%H-%M-%S')\n",
    "        filename = f\"frame_{timestamp}.png\"\n",
    "        cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\2025-05-28_slice_test\\\\'+filename, frame)\n",
    "        print(f\"Frame saved as {filename}\")\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "def on_mouse_click(event, cX, cY, flags, param):\n",
    "    global X_init, Y_init, X, Y, target_x, target_y\n",
    "    # if event == cv2.EVENT_LBUTTONDOWN:\n",
    "    #     target_x, target_y = cX, cY\n",
    "    #     # print(\"Clicked at pixel coordinate: ({}, {})\".format(cX, cY))\n",
    "    #     X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "    #     x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "    #     diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "    #     X = X_init + diff[0] + offset[0]\n",
    "    #     Y = Y_init + diff[1] + offset[1]\n",
    "    #     print(cX, cY)\n",
    "    #     print(X_init, Y_init)\n",
    "    #     print(f\"Robot coords: ({x}, {y})\")\n",
    "    #     print(f\"Clicked on: ({X}, {Y})\")\n",
    "\n",
    "    #     openapi.move_to_coordinates((X, Y, 70), min_z_height=65, verbose=False)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "        openapi.move_to_coordinates((256.56,145,100), min_z_height=1, verbose=False)\n",
    "\n",
    "        # Handle double click event to move to the clicked contour\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        for contour in internal_contours:\n",
    "            if cv2.pointPolygonTest(contour, (cX, cY), False) >= 0:\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    X_init, Y_init, _ = tf_mtx @ (cx, cy, 1)\n",
    "                    x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                    diff = np.array([x, y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "                    X = X_init + diff[0] + offset[0]\n",
    "                    Y = Y_init + diff[1] + offset[1]\n",
    "                    print(f\"Double-clicked inside contour at centroid: ({cx}, {cy})\")\n",
    "                    print(f\"Moving robot to: ({X}, {Y})\")\n",
    "                    openapi.move_to_coordinates((X, Y, 70), min_z_height=65, verbose=False)\n",
    "                    # break\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "cv2.setMouseCallback(\"video\", on_mouse_click)\n",
    "\n",
    "target_x, target_y = 0, 0\n",
    "\n",
    "dish_bottom = 70# - 11.5\n",
    "pickup_offset = 0.0 #0.6\n",
    "flow_rate = 250\n",
    "volume = 50\n",
    "\n",
    "while True:\n",
    "    ret, frame = over_cam.read()\n",
    "    frame = frame_ops.undistort_frame(frame)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 190), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Flow rate: {flow_rate} uL/s\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Volume: {volume} uL\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Pickup height: {dish_bottom + pickup_offset} mm\", (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Draw a small circle in the middle of the frame and mask everything else out\n",
    "\n",
    "    # Convert masked_frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    mask = np.zeros_like(gray)\n",
    "    center = (gray.shape[1] // 2, gray.shape[0] // 2)\n",
    "    radius = 200  # adjust radius as needed\n",
    "    cv2.circle(mask, center, radius, (255, 255, 255), -1)\n",
    "    cv2.circle(frame, center, radius, (255, 255, 255), 2)\n",
    "    # Apply adaptive threshold\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 41, 3\n",
    "    )\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    masked_frame = cv2.bitwise_and(thresh, mask)\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(masked_frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Keep only internal contours (child contours)\n",
    "    if hierarchy is not None and len(hierarchy) > 0:\n",
    "        # hierarchy[0] shape: (num_contours, 4), last value is parent index\n",
    "        internal_contours = [contour for idx, contour in enumerate(contours)\n",
    "                             if hierarchy[0][idx][3] != -1]\n",
    "        contours = internal_contours\n",
    "    # Draw contours on the original frame\n",
    "    cv2.drawContours(frame, internal_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"video\", frame)\n",
    "    \n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        openapi.dispense_in_place(flow_rate = flow_rate, volume = volume)\n",
    "\n",
    "    elif key_pressed == ord('b'):\n",
    "        openapi.blow_out_in_place(50)\n",
    "\n",
    "    elif key_pressed == ord('a'):\n",
    "        openapi.aspirate_in_place(flow_rate = flow_rate, volume = volume, verbose=True)\n",
    "\n",
    "    elif key_pressed == ord('s'):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y_%m_%d_%H-%M-%S')\n",
    "        filename = f\"frame_{timestamp}.png\"\n",
    "        cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\2025-05-28_slice_test\\\\'+filename, frame)\n",
    "        print(f\"Frame saved as {filename}\")\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydrogel core detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_profile = 'standardDeck'\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    global circle_center, circle_radius\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False)\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONDOWN:\n",
    "        circle_center = (x, y)\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            circle_radius += 10\n",
    "        else:\n",
    "            circle_radius -= 10\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "\n",
    "target_x, target_y = 0, 0\n",
    "\n",
    "dish_bottom = 9.4# - 11.5\n",
    "pickup_offset = 0 #0.6\n",
    "flow_rate = 300\n",
    "volume = 50\n",
    "\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 190), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Flow rate: {flow_rate} uL/s\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Volume: {volume} uL\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Pickup height: {dish_bottom + pickup_offset} mm\", (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "    center_screen_x = frame.shape[1] // 2\n",
    "    center_screen_y = frame.shape[0] // 2\n",
    "    cv2.circle(frame, (target_x, target_y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(gray_img, dtype=np.uint8)\n",
    "    cv2.circle(mask, circle_center, circle_radius, (255, 255, 255), -1)\n",
    "    gray_img = cv2.GaussianBlur(gray_img, (21, 21), 0)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_img = clahe.apply(gray_img)\n",
    "    thresh_img = cv2.adaptiveThreshold(clahe_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 65, 9)\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, kernel)\n",
    "    masked_opening = cv2.bitwise_and(opening, mask)\n",
    "    contours, _ = cv2.findContours(masked_opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    min_contour_area = 500\n",
    "    max_contour_area = 5000\n",
    "\n",
    "    circular_contours = []\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if perimeter == 0 or area < min_contour_area or area > max_contour_area:\n",
    "            continue\n",
    "        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "        if 0.7 < circularity < 1.3:  # Adjust the range as needed\n",
    "            circular_contours.append(contour)\n",
    "\n",
    "    contours = circular_contours\n",
    "\n",
    "    contour_centers = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            contour_centers.append((cX, cY))\n",
    "        else:\n",
    "            contour_centers.append((0, 0))\n",
    "\n",
    "    contour_img = frame.copy()\n",
    "    cv2.circle(contour_img, circle_center, circle_radius, (255, 0, 0), 2)\n",
    "    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "    # Draw contour centers on the image\n",
    "    for center in contour_centers:\n",
    "        cv2.circle(contour_img, center, 5, (255, 0, 0), -1)\n",
    "    \n",
    "    cv2.imshow(cap.window_name, contour_img)\n",
    "    # Draw a point at the center of the screen\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "    elif key_pressed == ord('s'):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y_%m_%d_%H-%M-%S')\n",
    "        filename = f\"frame_{timestamp}.png\"\n",
    "        cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\'+filename, frame)\n",
    "        print(f\"Frame saved as {filename}\")\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_contour_centers = []\n",
    "x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "for center in contour_centers:\n",
    "    cX, cY = center\n",
    "    X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "    diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "    X = X_init + diff[0] + offset[0]\n",
    "    Y = Y_init + diff[1] + offset[1]\n",
    "    converted_contour_centers.append((X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(converted_contour_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x, y = converted_contour_centers[i]\n",
    "    openapi.move_to_coordinates((x,y,12), min_z_height=1, verbose=False)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "openapi.move_relative('z', 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking procedure (semi-automatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = core.Core()\n",
    "\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "size_conversion_ratio = calibration_data['size_conversion_ratio']\n",
    "one_d_ratio = calibration_data['one_d_ratio']\n",
    "\n",
    "vol = 10\n",
    "dish_bottom = 10 #10.60 for 300ul, 9.5 for 200ul\n",
    "pickup_offset = 0.5\n",
    "pickup_height = dish_bottom + pickup_offset\n",
    "flow_rate = 50\n",
    "cuboid_size_theshold = (300, 450)\n",
    "failure_threshold = 0.5\n",
    "minimum_distance = 1.7\n",
    "\n",
    "window = cap.get_window()\n",
    "\n",
    "def create_well_mapping():\n",
    "    rows = list(\"ABCDEFGHIJKLMNOP\")\n",
    "    columns = list(range(1, 25))\n",
    "    well_mapping = {}\n",
    "\n",
    "    for i in range(384):\n",
    "        row = rows[i // 24]\n",
    "        column = columns[i % 24]\n",
    "        well_mapping[i] = f\"{row}{column}\"\n",
    "\n",
    "    return well_mapping\n",
    "\n",
    "well_mapping = create_well_mapping()\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    global circle_center\n",
    "    global circle_radius\n",
    "    global filtered_contours\n",
    "    global X_init, Y_init\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONDOWN:\n",
    "        circle_center = (x, y)\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            circle_radius += 10\n",
    "        else:\n",
    "            circle_radius -= 10\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        for contour in filtered_contours:\n",
    "            r=cv2.pointPolygonTest(contour, (x,y), False)\n",
    "            if r>0:\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "                    x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                    diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "                    X = X_init + diff[0] + offset[0]\n",
    "                    Y = Y_init + diff[1] + offset[1]\n",
    "                    \n",
    "                    print(f\"Robot coords: ({x}, {y})\")\n",
    "                    print(f\"Clicked on: ({X}, {Y})\")\n",
    "                    openapi.move_to_coordinates((X, Y, 20), min_z_height=1, verbose=False)\n",
    "                    time.sleep(0.1)\n",
    "                    openapi.aspirate_in_place(flow_rate = flow_rate, volume = vol)\n",
    "                    time.sleep(0.1)\n",
    "                    openapi.move_to_coordinates((X, Y, pickup_height), min_z_height=1, verbose=False, force_direct=True)\n",
    "                    time.sleep(1)\n",
    "                    openapi.move_to_coordinates((X, Y, 30), min_z_height=1, verbose=False)\n",
    "                else:\n",
    "                    print(\"Contour center could not be found\")\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False)\n",
    "\n",
    "        \n",
    "\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "circle_center = (int(1296.0), int(972.0))\n",
    "circle_radius = 900\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "# Which wells to fill\n",
    "columns = list(range(1,25))\n",
    "#rows = ['F', 'G', 'H', 'I']\n",
    "rows = ['G']\n",
    "\n",
    "wells_to_fill = [f\"{row}{column}\" for row in rows for column in columns]\n",
    "\n",
    "reversed_well_mapping = {v: k for k, v in well_mapping.items()}\n",
    "wells_to_fill_indices = [reversed_well_mapping[well] for well in wells_to_fill]\n",
    "\n",
    "idx = wells_to_fill_indices[0]\n",
    "end_idx = wells_to_fill_indices[-1] + 1\n",
    "\n",
    "cuboid_chosen = False\n",
    "cuboid_choice = None\n",
    "times = []\n",
    "while idx < end_idx:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.circle(frame, circle_center, circle_radius + int(minimum_distance / one_d_ratio), (0, 0, 255), 2)\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "    cv2.circle(mask, circle_center, circle_radius + int(minimum_distance / one_d_ratio), (255, 255, 255), -1)\n",
    "    masked_frame = cv2.bitwise_and(frame, mask)\n",
    "    cv2.circle(frame, circle_center, circle_radius, (0, 255, 0), 2)\n",
    "\n",
    "    gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,2) \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "    # Find contours in the masked frame\n",
    "    contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cr.cuboids = contours\n",
    "    filtered_contours = [contour for contour in cr.cuboids if 30 < cv2.contourArea(contour) < 700]\n",
    "    cr.cuboid_dataframe(filtered_contours)\n",
    "\n",
    "    cuboid_size_micron2 = cr.cuboid_df.area * size_conversion_ratio * 1000000\n",
    "    cuboid_diameter = 2 * np.sqrt(cuboid_size_micron2 / np.pi)\n",
    "    dist_mm = cr.cuboid_df.min_dist * one_d_ratio\n",
    "    cr.cuboid_df['diameter_microns'] = cuboid_diameter\n",
    "    cr.cuboid_df['min_dist_mm'] = dist_mm\n",
    "    \n",
    "    # Filter out elongated contours\n",
    "\n",
    "    pickable_cuboids = cr.cuboid_df.loc[(cuboid_size_theshold[0] < cr.cuboid_df['diameter_microns']) & \n",
    "                                        (cr.cuboid_df['diameter_microns'] < cuboid_size_theshold[1]) &\n",
    "                                        ((cr.cuboid_df['aspect_ratio'] > 0.75) | (cr.cuboid_df['aspect_ratio'] < 1.25)) &\n",
    "                                        (cr.cuboid_df['circularity'] > 0.6)].copy()\n",
    "\n",
    "    # Check if cuboid centers are within the circle radius from the current circle center\n",
    "    pickable_cuboids['distance_to_center'] = pickable_cuboids.apply(\n",
    "        lambda row: np.sqrt((row['cX'] - circle_center[0])**2 + (row['cY'] - circle_center[1])**2), axis=1\n",
    "    )\n",
    "    pickable_cuboids = pickable_cuboids[pickable_cuboids['distance_to_center'] <= circle_radius]\n",
    "    isolated = pickable_cuboids.loc[pickable_cuboids.min_dist_mm > minimum_distance]\n",
    "    draw = isolated.contour.values.tolist()\n",
    "    cv2.drawContours(frame, filtered_contours, -1, (0, 0, 255), 2)\n",
    "    cv2.drawContours(frame, pickable_cuboids.contour.values.tolist(), -1, (0, 255, 255), 2)\n",
    "    cv2.drawContours(frame, draw, -1, (0, 255, 0), 2)\n",
    "\n",
    "    if not cuboid_chosen and len(isolated) > 0:\n",
    "        if cuboid_choice is not None:\n",
    "            prev_x, prev_y = cuboid_choice[['cX', 'cY']].values[0]\n",
    "            \n",
    "            cv2.circle(frame, (int(prev_x), int(prev_y)), int(round(failure_threshold / one_d_ratio)), (255, 0, 0), 2)\n",
    "            distances = cr.cuboid_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "            distances *= one_d_ratio\n",
    "            if any(distances <= failure_threshold):\n",
    "                print(\"Miss detected ...\")\n",
    "                idx -= 1\n",
    "\n",
    "        cuboid_choice = isolated.sample(n=1)\n",
    "        cuboid_chosen = True\n",
    "        # cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\'+f\"frame_{idx}.png\", frame)\n",
    "        \n",
    "\n",
    "    # for i, row in cr.cuboid_df.iterrows():\n",
    "    #     cX, cY = int(row['cX']), int(row['cY'])\n",
    "    #     aspect_ratio = row['aspect_ratio']\n",
    "    #     circularity = row['circularity']\n",
    "    #     cv2.putText(frame, f\"{aspect_ratio:.2f}, {circularity:.2f}\", (cX+20, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "    if cuboid_chosen:    \n",
    "        cv2.drawContours(frame, cuboid_choice.contour.values.tolist(), -1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    #-----------------------------------------------INTERACTION------------------------------------------------\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "    elif key_pressed == ord('m'):\n",
    "        start_time = time.time()\n",
    "        print(len(isolated))\n",
    "        if len(isolated) > 2:\n",
    "            chosen = isolated.sample(n=2)\n",
    "        else:\n",
    "            chosen = isolated.copy()\n",
    "\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        for i in range(len(chosen)):\n",
    "            cX, cY = chosen.iloc[i][['cX', 'cY']].values\n",
    "\n",
    "            X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "            diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "            X = X_init + diff[0] + offset[0]\n",
    "            Y = Y_init + diff[1] + offset[1]\n",
    "\n",
    "            openapi.move_to_coordinates((X, Y, pickup_height+20), min_z_height=dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.move_to_coordinates((X, Y, pickup_height), min_z_height=dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.aspirate_in_place(flow_rate = flow_rate, volume = 10)\n",
    "            openapi.move_relative('z', 10)\n",
    "            openapi.aspirate_in_place(flow_rate = flow_rate, volume = 20)\n",
    "            time.sleep(0.1)\n",
    "        openapi.move_relative('z', 20)\n",
    "\n",
    "        # wells = ['B11', 'B12', 'B13', 'B14', 'B15']\n",
    "        openapi.move_to_well(openapi.labware_dct['6'], well_mapping[idx], well_location='top', offset=(0.9,-0.9,5), verbose=False, force_direct=True)\n",
    "        for j in range(len(chosen)):\n",
    "            if j == 0:\n",
    "                air_disp_vol = 25\n",
    "                liq_disp_vol = 10\n",
    "            elif j == 1:\n",
    "                air_disp_vol = 15\n",
    "                liq_disp_vol = 10\n",
    "\n",
    "            openapi.dispense(openapi.labware_dct['6'], well_mapping[idx], well_location='top', offset = (0.9,-0.9,5), volume = air_disp_vol, flow_rate = 50)\n",
    "            time.sleep(0.1)\n",
    "            openapi.dispense(openapi.labware_dct['6'], well_mapping[idx], well_location='bottom', offset = (0.9,-0.9,0), volume = liq_disp_vol, flow_rate = 50)\n",
    "            time.sleep(0.3)\n",
    "            idx += 1\n",
    "\n",
    "        openapi.move_relative('z', 20)\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False, force_direct=True)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    # elif key_pressed == ord('n'):\n",
    "    #     for i in range(2):\n",
    "    #         # if i == 0:\n",
    "    #         #     air_disp_vol = 30\n",
    "    #         #     liq_disp_vol = 10\n",
    "    #         # elif i == 4:\n",
    "    #         #     air_disp_vol = 10\n",
    "    #         #     liq_disp_vol = 10\n",
    "    #         # else:\n",
    "    #         #     air_disp_vol = 20\n",
    "    #         #     liq_disp_vol = 10\n",
    "    #         # openapi.move_relative('z', 10)\n",
    "    #         openapi.dispense_in_place(volume = 20, flow_rate = 50)\n",
    "    #         time.sleep(1)\n",
    "    #         openapi.move_relative('z', -10)\n",
    "    #         openapi.dispense_in_place(volume = 10, flow_rate = 50)\n",
    "    #         time.sleep(1)\n",
    "    #         openapi.move_relative('z', 10)\n",
    "    #         openapi.move_relative('x', -8.5)\n",
    "\n",
    "        \n",
    "\n",
    "    elif key_pressed == ord('c'):\n",
    "        if len(isolated) > 0:\n",
    "            cuboid_choice = isolated.sample(n=1)\n",
    "\n",
    "    elif key_pressed == ord('p'):\n",
    "        if len(isolated) == 0:\n",
    "            print(\"No cuboids found in the selected region\")\n",
    "            continue\n",
    "\n",
    "        cX, cY = cuboid_choice[['cX', 'cY']].values[0]\n",
    "\n",
    "        X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "        X = X_init + diff[0] + offset[0]\n",
    "        Y = Y_init + diff[1] + offset[1]\n",
    "        \n",
    "        openapi.move_to_coordinates((X, Y, pickup_height), min_z_height=dish_bottom, verbose=False)\n",
    "        openapi.aspirate_in_place(flow_rate = flow_rate, volume = vol)\n",
    "        # ---------------------------------WHERE TO DISPENSE---------------------------------------\n",
    "        # x_d, y_d = converted_contour_centers[idx]\n",
    "        # openapi.move_to_coordinates((x_d,y_d, dish_bottom + 2.5), min_z_height=1, verbose=False)\n",
    "        # time.sleep(0.5)\n",
    "        # openapi.dispense_in_place(flow_rate = flow_rate, volume = vol)\n",
    "        # time.sleep(0.5)\n",
    "        openapi.dispense(openapi.labware_dct['6'], well_mapping[idx], well_location='bottom', offset = (0.9,-0.9,0), volume = vol, flow_rate = flow_rate)\n",
    "        time.sleep(0.3)\n",
    "        openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=dish_bottom, verbose=False)\n",
    "        idx += 1\n",
    "        cuboid_chosen = False\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        r = openapi.dispense_in_place(flow_rate = flow_rate, volume = vol)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "keyboard.unhook_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(times) /24 * 384 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.control_run('stop') # Stop the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = chosen.iloc[i][['cX', 'cY']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard.unhook_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out_in_place(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_well(openapi.labware_dct['6'], 'A1', well_location='top', offset=(0,0,1), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.dispense(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 100, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location='bottom', offset = (0,0,0), volume = 100, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.dispense(openapi.labware_dct['6'], well_mapping[idx], well_location='bottom', volume = vol, flow_rate = flow_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking procedure (Automatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_well_mapping(plate_type='384'):\n",
    "    if plate_type == '384':\n",
    "        rows = list(\"ABCDEFGHIJKLMNOP\")\n",
    "        columns = list(range(1, 25))\n",
    "    elif plate_type == '96':\n",
    "        rows = list(\"ABCDEFGH\")\n",
    "        columns = list(range(1, 13))\n",
    "    elif plate_type == '24':\n",
    "        rows = list(\"ABCD\")\n",
    "        columns = list(range(1, 7))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported plate type. Use '384', '96', or '24'.\")\n",
    "\n",
    "    well_mapping = {}\n",
    "    for i in range(len(rows) * len(columns)):\n",
    "        row = rows[i // len(columns)]\n",
    "        column = columns[i % len(columns)]\n",
    "        well_mapping[i] = f\"{row}{column}\"\n",
    "\n",
    "    return well_mapping\n",
    "\n",
    "well_mapping = create_well_mapping('24')  # Change to '96' if using a 96 well plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to stop threads gracefully\n",
    "stop_event = threading.Event()\n",
    "pause_event = threading.Event()\n",
    "pause_event.set()  # Start in paused state\n",
    "coord_queue = queue.Queue()\n",
    "cr = core.Core()\n",
    "\n",
    "# ----------------------Robot configs-----------------------\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "size_conversion_ratio = calibration_data['size_conversion_ratio']\n",
    "one_d_ratio = calibration_data['one_d_ratio']\n",
    "\n",
    "# ----------------------Picking configs-----------------------\n",
    "vol = 10\n",
    "dish_bottom = 11 #10.60 for 300ul, 9.5 for 200ul\n",
    "pickup_offset = 0.5\n",
    "pickup_height = dish_bottom + pickup_offset\n",
    "flow_rate = 100\n",
    "cuboid_size_theshold = (250, 500)\n",
    "failure_threshold = 0.5\n",
    "minimum_distance = 1.7\n",
    "\n",
    "columns = list(range(1,5))\n",
    "# rows = ['G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "# rows = ['A', 'B', 'C', 'D']\n",
    "rows = ['A']\n",
    "well_offset_x = 0#0.9 #384 well plate\n",
    "well_offset_y = 0#-0.9 #384 well plate\n",
    "\n",
    "wells_to_fill = [f\"{row}{column}\" for row in rows for column in columns]\n",
    "reversed_well_mapping = {v: k for k, v in well_mapping.items()}\n",
    "wells_to_fill_indices = [reversed_well_mapping[well] for well in wells_to_fill]\n",
    "idx = wells_to_fill_indices[0]\n",
    "end_idx = wells_to_fill_indices[-1] + 1\n",
    "\n",
    "# ----------------------Video configs-----------------------\n",
    "circle_center = (int(1296.0), int(972.0))\n",
    "circle_radius = 650\n",
    "\n",
    "# ----------------------Dict for misses---------------------\n",
    "misses = {}\n",
    "\n",
    "\n",
    "class SharedSettings:\n",
    "    def __init__(self):\n",
    "        self.lock = threading.Lock()\n",
    "        self.cuboid_chosen = False  # Movement speed (modifiable)\n",
    "        self.idx = idx  # Current index (modifiable)\n",
    "        self.local_timer_set = False\n",
    "\n",
    "settings = SharedSettings()\n",
    "\n",
    "def video_stream(): # Open default camera (change index if needed)\n",
    "    window = cap.get_window()\n",
    "    cuboid_choice = None\n",
    "\n",
    "    start_time = time.time()\n",
    "    local_timer_start = None\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        frame = cap.get_frame(undist=True)\n",
    "\n",
    "        with settings.lock:\n",
    "            cuboid_chosen = settings.cuboid_chosen\n",
    "            local_timer_set = settings.local_timer_set\n",
    "            idx = settings.idx\n",
    "\n",
    "        if not pause_event.is_set() and not local_timer_set:\n",
    "            local_timer_start = time.time()\n",
    "            with settings.lock:\n",
    "                settings.local_timer_set = True\n",
    "        elif pause_event.is_set() and local_timer_set:\n",
    "            local_timer_end = time.time()\n",
    "            local_timer_duration = local_timer_end - local_timer_start\n",
    "            print(f\"Operation between pauses {local_timer_duration:.2f}\")\n",
    "            with settings.lock:\n",
    "                settings.local_timer_set = False\n",
    "\n",
    "        if idx >= end_idx:\n",
    "            stop_event.set()\n",
    "            break\n",
    "        #-----------------------------------------VISION PROCESSING-----------------------------------------\n",
    "        x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "        (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "        cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 150), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Filling well: {well_mapping[idx]}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if pause_event.is_set():\n",
    "            cv2.putText(frame, \"Paused\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "        cv2.circle(frame, circle_center, circle_radius + int(minimum_distance / one_d_ratio), (0, 0, 255), 2)\n",
    "        mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "        cv2.circle(mask, circle_center, circle_radius + int(minimum_distance / one_d_ratio), (255, 255, 255), -1)\n",
    "        masked_frame = cv2.bitwise_and(frame, mask)\n",
    "        cv2.circle(frame, circle_center, circle_radius, (0, 255, 0), 2)\n",
    "\n",
    "        if not cuboid_chosen:\n",
    "            gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "            thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,2) \n",
    "            kernel = np.ones((3,3),np.uint8)\n",
    "            thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "            mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "            # Find contours in the masked frame\n",
    "            contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cr.cuboids = contours\n",
    "            filtered_contours = [contour for contour in cr.cuboids if 30 < cv2.contourArea(contour) < 1000]\n",
    "            cr.cuboid_dataframe(filtered_contours)\n",
    "\n",
    "            cuboid_size_micron2 = cr.cuboid_df.area * size_conversion_ratio * 1000000\n",
    "            cuboid_diameter = 2 * np.sqrt(cuboid_size_micron2 / np.pi)\n",
    "            dist_mm = cr.cuboid_df.min_dist * one_d_ratio\n",
    "            cr.cuboid_df['diameter_microns'] = cuboid_diameter\n",
    "            cr.cuboid_df['min_dist_mm'] = dist_mm\n",
    "            \n",
    "            # Filter out elongated contours\n",
    "\n",
    "            pickable_cuboids = cr.cuboid_df.loc[(cuboid_size_theshold[0] < cr.cuboid_df['diameter_microns']) & \n",
    "                                                (cr.cuboid_df['diameter_microns'] < cuboid_size_theshold[1]) &\n",
    "                                                ((cr.cuboid_df['aspect_ratio'] > 0.75) | (cr.cuboid_df['aspect_ratio'] < 1.25)) &\n",
    "                                                (cr.cuboid_df['circularity'] > 0.6)].copy()\n",
    "\n",
    "            # Check if cuboid centers are within the circle radius from the current circle center\n",
    "            pickable_cuboids['distance_to_center'] = pickable_cuboids.apply(\n",
    "                lambda row: np.sqrt((row['cX'] - circle_center[0])**2 + (row['cY'] - circle_center[1])**2), axis=1\n",
    "            )\n",
    "            pickable_cuboids = pickable_cuboids[pickable_cuboids['distance_to_center'] <= circle_radius]\n",
    "            isolated = pickable_cuboids.loc[pickable_cuboids.min_dist_mm > minimum_distance]\n",
    "            draw = isolated.contour.values.tolist()\n",
    "            cv2.drawContours(frame, filtered_contours, -1, (0, 0, 255), 2)\n",
    "            cv2.drawContours(frame, pickable_cuboids.contour.values.tolist(), -1, (0, 255, 255), 2)\n",
    "            cv2.drawContours(frame, draw, -1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, f\"# GOOD objects / # ALL: {len(pickable_cuboids)}/{len(cr.cuboid_df)}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        #-----------------------------------------------INTERACTION------------------------------------------------\n",
    "\n",
    "            # if not cuboid_chosen and len(isolated) > 0:\n",
    "            #     if cuboid_choice is not None:\n",
    "            #         prev_x, prev_y = cuboid_choice[['cX', 'cY']].values[0]\n",
    "                    \n",
    "            #         cv2.circle(frame, (int(prev_x), int(prev_y)), int(round(failure_threshold / one_d_ratio)), (255, 0, 0), 2)\n",
    "            #         distances = cr.cuboid_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "            #         distances *= one_d_ratio\n",
    "            #         if any(distances <= failure_threshold):\n",
    "            #             print(\"Miss detected ...\")\n",
    "            #             with settings.lock:\n",
    "            #                 settings.idx -= 1\n",
    "\n",
    "            #     cuboid_choice = isolated.sample(n=1) \n",
    "            #     cv2.drawContours(frame, cuboid_choice.contour.values.tolist(), -1, (255, 0, 0), 2)\n",
    "\n",
    "        if not coord_queue.full() and not cuboid_chosen and not pause_event.is_set() and len(isolated) > 0:\n",
    "            if cuboid_choice is not None:\n",
    "                prev_x, prev_y = cuboid_choice[['cX', 'cY']].values[0]\n",
    "                \n",
    "                cv2.circle(frame, (int(prev_x), int(prev_y)), int(round(failure_threshold / one_d_ratio)), (255, 0, 0), 2)\n",
    "                distances = cr.cuboid_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "                distances *= one_d_ratio\n",
    "                if any(distances <= failure_threshold):\n",
    "                    with settings.lock:\n",
    "                        settings.idx -= 1\n",
    "                    print(f\"Miss detected at well {well_mapping[idx]}.\")\n",
    "                    if well_mapping[idx] in misses:\n",
    "                        misses[well_mapping[idx]] += 1\n",
    "                    else:\n",
    "                        misses[well_mapping[idx]] = 1\n",
    "\n",
    "            cuboid_choice = isolated.sample(n=1) \n",
    "            cv2.drawContours(frame, cuboid_choice.contour.values.tolist(), -1, (255, 0, 0), 2)\n",
    "            # cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\'+f\"frame_{idx}.png\", frame)\n",
    "\n",
    "            cX, cY = cuboid_choice[['cX', 'cY']].values[0]\n",
    "            X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "            x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "            diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "            X = X_init + diff[0] + offset[0]\n",
    "            Y = Y_init + diff[1] + offset[1]\n",
    "\n",
    "            coord_queue.put((X, Y))\n",
    "            with settings.lock:\n",
    "                settings.cuboid_chosen = True\n",
    "        elif len(isolated) == 0 and not pause_event.is_set():\n",
    "            pause_event.set()\n",
    "            print(\"No cuboids found in the selected region. Pausing...\")\n",
    "\n",
    "        cv2.imshow(cap.window_name, frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            stop_event.set()\n",
    "        elif key == ord('p'):\n",
    "            if pause_event.is_set():\n",
    "                pause_event.clear()\n",
    "                print(\"Resuming movement...\")\n",
    "            else:\n",
    "                print(\"Pausing movement...\")\n",
    "                pause_event.set()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    if local_timer_start:\n",
    "        print(f\"Last local time: {end_time - local_timer_start} seconds\")\n",
    "    # print(f\"Last index: {well_mapping[idx]}\")\n",
    "\n",
    "def robot_movement():\n",
    "    openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=dish_bottom, verbose=False)\n",
    "    while not stop_event.is_set():\n",
    "        if pause_event.is_set():\n",
    "            time.sleep(0.1)  # Small sleep to prevent excessive CPU usage\n",
    "            continue  # Skip to next iteration while paused\n",
    "        # print(\"Moving robot...\")\n",
    "        try:\n",
    "            # Get latest coordinates from the queue (non-blocking)\n",
    "            x, y = coord_queue.get(timeout=1)  # Timeout prevents indefinite blocking\n",
    "            openapi.move_to_coordinates((x, y, pickup_height+30), min_z_height=dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.move_to_coordinates((x, y, pickup_height), min_z_height=dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.aspirate_in_place(flow_rate = flow_rate, volume = vol)\n",
    "            openapi.move_relative('z', 30)\n",
    "\n",
    "            with settings.lock:\n",
    "                idx = settings.idx\n",
    "\n",
    "            openapi.move_to_well(openapi.labware_dct['6'], well_mapping[idx], well_location='top', offset=(well_offset_x,well_offset_y,15), verbose=False, force_direct=True)\n",
    "            openapi.dispense(openapi.labware_dct['6'], well_mapping[idx], well_location='bottom', offset=(well_offset_x, well_offset_y, 1), volume = vol, flow_rate = flow_rate)\n",
    "            time.sleep(0.5)\n",
    "            openapi.move_to_well(openapi.labware_dct['6'], well_mapping[idx], well_location='top', offset=(well_offset_x,well_offset_y,15), verbose=False)\n",
    "            openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=dish_bottom, verbose=False, force_direct=True)\n",
    "            time.sleep(0.5)\n",
    "            with settings.lock:\n",
    "                settings.cuboid_chosen = False\n",
    "                settings.idx += 1 \n",
    "        except queue.Empty:\n",
    "            pass  # No new coordinates, continue looping\n",
    "# Create threads\n",
    "video_thread = threading.Thread(target=video_stream, daemon=True)\n",
    "robot_thread = threading.Thread(target=robot_movement, daemon=True)\n",
    "\n",
    "# Start threads\n",
    "video_thread.start()\n",
    "robot_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "video_thread.join()\n",
    "robot_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_well(openapi.labware_dct['6'], 'B1', well_location='top', offset=(well_offset_x,well_offset_y,15), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "while idx < len(misses):\n",
    "    well_name, miss_count = list(misses.items())[idx]\n",
    "    r = openapi.aspirate(openapi.labware_dct['6'], f\"{well_name}\", well_location = 'bottom', offset = (well_offset_x,well_offset_y,0), volume = miss_count*vol, flow_rate = 5)\n",
    "    responce_dict = json.loads(r.text)['data']\n",
    "    if responce_dict['status'] == 'failed':\n",
    "        if responce_dict['error']['errorType'] == 'InvalidAspirateVolumeError':\n",
    "            print('Dumping fluid')\n",
    "            openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='center', flow_rate = 200)\n",
    "    else:\n",
    "        idx += 1\n",
    "    \n",
    "openapi.blow_out(openapi.labware_dct['3'], \"A1\", well_location='center', flow_rate = 200)\n",
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.dispense(openapi.labware_dct['3'], \"A1\", well_location='center', offset = (0,0,0), volume = 10, flow_rate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.put((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one, two = test.get(timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.full()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking procedure (Auto + class) redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedSettings:\n",
    "    def __init__(self):\n",
    "        self.lock = threading.Lock()\n",
    "        self.cuboid_chosen = False\n",
    "        self.idx = None\n",
    "        self.local_timer_set = False\n",
    "        self.stop_event = threading.Event()\n",
    "        self.pause_event = threading.Event()\n",
    "        self.pause_event.set()\n",
    "\n",
    "class PickingProcedure():\n",
    "\n",
    "    def __init__(self, shared_settings):\n",
    "        self.coord_queue = queue.Queue()\n",
    "        self.cr = core.Core()\n",
    "        self.shared_settings_inst = shared_settings\n",
    "        self.misses = {}\n",
    "\n",
    "        # ----------------------Robot configs-----------------------\n",
    "        self.calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "        self.tf_mtx = np.array(self.calibration_data['tf_mtx'])\n",
    "        self.calib_origin = np.array(self.calibration_data['calib_origin'])[:2]\n",
    "        self.offset = np.array(self.calibration_data['offset'])\n",
    "        self.size_conversion_ratio = self.calibration_data['size_conversion_ratio']\n",
    "        self.one_d_ratio = self.calibration_data['one_d_ratio']\n",
    "\n",
    "        # ----------------------Picking configs-----------------------\n",
    "        self.vol = 10\n",
    "        self.dish_bottom = 10.3 #10.60 for 300ul, 9.5 for 200ul\n",
    "        self.pickup_offset = 0.5\n",
    "        self.pickup_height = self.dish_bottom + self.pickup_offset\n",
    "        self.flow_rate = 50\n",
    "        self.cuboid_size_theshold = (300, 500)\n",
    "        self.failure_threshold = 0.5\n",
    "        self.minimum_distance = 1.7\n",
    "\n",
    "        # ----------------------Deposit configs-----------------------\n",
    "        self.well_plate_type = '384'\n",
    "        self.columns = list(range(1,25))\n",
    "        # self.rows = ['A', 'B', 'C', 'D', 'E', 'F','G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "        self.rows = ['C']\n",
    "        # self.wells_to_fill = [f\"{row}{column}\" for row in self.rows for column in self.columns]\n",
    "        self.wells_to_fill = ['A1', 'A2', 'A3']\n",
    "        self.current_idx = 0\n",
    "        self.shared_settings_inst.idx = self.current_idx\n",
    "        self.end_idx = len(self.wells_to_fill)\n",
    "\n",
    "        self.well_offset_x = 0.9 #384 well plate\n",
    "        self.well_offset_y = -0.9 #384 well plate\n",
    "\n",
    "        # ----------------------Video configs-----------------------\n",
    "        self.circle_center = (int(1296.0), int(972.0))\n",
    "        self.circle_radius = 900\n",
    "\n",
    "        self.isolated = []\n",
    "        self.pickable_cuboids = []\n",
    "\n",
    "    def cv_pipeline(self, frame):\n",
    "        mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "        cv2.circle(mask, self.circle_center, self.circle_radius + int(self.minimum_distance / self.one_d_ratio), (255, 255, 255), -1)\n",
    "        masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "        gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,2) \n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "        # Find contours in the masked frame\n",
    "        contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        self.cr.cuboids = contours\n",
    "        filtered_contours = [contour for contour in self.cr.cuboids if 30 < cv2.contourArea(contour) < 1000]\n",
    "        self.cr.cuboid_dataframe(filtered_contours)\n",
    "\n",
    "        cuboid_size_micron2 = self.cr.cuboid_df.area * self.size_conversion_ratio * 1000000\n",
    "        cuboid_diameter = 2 * np.sqrt(cuboid_size_micron2 / np.pi)\n",
    "        dist_mm = self.cr.cuboid_df.min_dist * self.one_d_ratio\n",
    "        self.cr.cuboid_df['diameter_microns'] = cuboid_diameter\n",
    "        self.cr.cuboid_df['min_dist_mm'] = dist_mm\n",
    "        \n",
    "        # Filter out elongated contours\n",
    "        self.pickable_cuboids = self.cr.cuboid_df.loc[(self.cuboid_size_theshold[0] < self.cr.cuboid_df['diameter_microns']) & \n",
    "                                            (self.cr.cuboid_df['diameter_microns'] < self.cuboid_size_theshold[1]) &\n",
    "                                            ((self.cr.cuboid_df['aspect_ratio'] > 0.75) | (self.cr.cuboid_df['aspect_ratio'] < 1.25)) &\n",
    "                                            (self.cr.cuboid_df['circularity'] > 0.6)].copy()\n",
    "\n",
    "        # Check if cuboid centers are within the circle radius from the current circle center\n",
    "        self.pickable_cuboids['distance_to_center'] = self.pickable_cuboids.apply(\n",
    "            lambda row: np.sqrt((row['cX'] - self.circle_center[0])**2 + (row['cY'] - self.circle_center[1])**2), axis=1\n",
    "        )\n",
    "        self.pickable_cuboids = self.pickable_cuboids[self.pickable_cuboids['distance_to_center'] <= self.circle_radius]\n",
    "        self.isolated = self.pickable_cuboids.loc[self.pickable_cuboids.min_dist_mm > self.minimum_distance]\n",
    "\n",
    "    def draw_annotations(self, frame, coords_tuple):\n",
    "        cv2.circle(frame, self.circle_center, self.circle_radius + int(self.minimum_distance / self.one_d_ratio), (0, 0, 255), 2)\n",
    "        cv2.circle(frame, self.circle_center, self.circle_radius, (0, 255, 0), 2)\n",
    "        x,y,z = coords_tuple\n",
    "        cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Filling well: {self.wells_to_fill[self.current_idx]}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if self.shared_settings_inst.pause_event.is_set():\n",
    "            cv2.putText(frame, \"Paused\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        with self.shared_settings_inst.lock:\n",
    "            cuboid_chosen = self.shared_settings_inst.cuboid_chosen\n",
    "        if not cuboid_chosen:\n",
    "            cv2.drawContours(frame, self.cr.cuboids, -1, (0, 0, 255), 2)\n",
    "            cv2.drawContours(frame, self.pickable_cuboids.contour.values.tolist(), -1, (0, 255, 255), 2)\n",
    "            cv2.drawContours(frame, self.isolated.contour.values.tolist(), -1, (0, 255, 0), 2)\n",
    "        return frame\n",
    "    \n",
    "    def video(self):\n",
    "        window = cap.get_window()\n",
    "        cuboid_choice = None\n",
    "\n",
    "        while not self.shared_settings_inst.stop_event.is_set():\n",
    "            frame = cap.get_frame(undist=True)\n",
    "            plot_frame = frame.copy()\n",
    "\n",
    "            with self.shared_settings_inst.lock:\n",
    "                cuboid_chosen = self.shared_settings_inst.cuboid_chosen\n",
    "                local_timer_set = self.shared_settings_inst.local_timer_set\n",
    "                self.current_idx = self.shared_settings_inst.idx\n",
    "\n",
    "            if self.current_idx >= self.end_idx:\n",
    "                self.shared_settings_inst.stop_event.set()\n",
    "                break\n",
    "\n",
    "            x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "            # if not self.shared_settings_inst.pause_event.is_set():\n",
    "            if not cuboid_chosen:\n",
    "                self.cv_pipeline(frame)\n",
    "            self.draw_annotations(plot_frame, (x, y, z))\n",
    "\n",
    "            if not self.coord_queue.full() and not cuboid_chosen and not self.shared_settings_inst.pause_event.is_set() and len(self.isolated) > 0:\n",
    "                if cuboid_choice is not None:\n",
    "                    prev_x, prev_y = cuboid_choice[['cX', 'cY']].values[0]\n",
    "                    \n",
    "                    cv2.circle(plot_frame, (int(prev_x), int(prev_y)), int(round(self.failure_threshold / self.one_d_ratio)), (255, 0, 0), 2)\n",
    "                    distances = self.cr.cuboid_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "                    distances *= self.one_d_ratio\n",
    "                    if any(distances <= self.failure_threshold):\n",
    "                        with self.shared_settings_inst.lock:\n",
    "                            self.shared_settings_inst.idx -= 1\n",
    "                        print(f\"Miss detected at well {self.wells_to_fill[self.current_idx]}.\")\n",
    "                        if self.wells_to_fill[self.current_idx] in self.misses:\n",
    "                            self.misses[self.wells_to_fill[self.current_idx]] += 1\n",
    "                        else:\n",
    "                            self.misses[self.wells_to_fill[self.current_idx]] = 1\n",
    "\n",
    "                cuboid_choice = self.isolated.sample(n=1) \n",
    "                cv2.drawContours(frame, cuboid_choice.contour.values.tolist(), -1, (255, 0, 0), 2)\n",
    "                # cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\'+f\"frame_{idx}.png\", frame)\n",
    "\n",
    "                cX, cY = cuboid_choice[['cX', 'cY']].values[0]\n",
    "                X_init, Y_init, _ = self.tf_mtx @ (cX, cY, 1)\n",
    "                x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                diff = np.array([x,y]) - np.array(self.calibration_data['calib_origin'])[:2]\n",
    "                X = X_init + diff[0] + self.offset[0]\n",
    "                Y = Y_init + diff[1] + self.offset[1]\n",
    "\n",
    "                self.coord_queue.put((X, Y))\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    self.shared_settings_inst.cuboid_chosen = True\n",
    "            elif len(self.isolated) == 0 and not self.shared_settings_inst.pause_event.is_set():\n",
    "                self.shared_settings_inst.pause_event.set()\n",
    "                print(\"No cuboids found in the selected region. Pausing...\")\n",
    "\n",
    "            cv2.imshow(cap.window_name, plot_frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if key == ord('q'):\n",
    "                self.shared_settings_inst.stop_event.set()\n",
    "            elif key == ord('p'):\n",
    "                if self.shared_settings_inst.pause_event.is_set():\n",
    "                    self.shared_settings_inst.pause_event.clear()\n",
    "                    print(\"Resuming movement...\")\n",
    "                else:\n",
    "                    print(\"Pausing movement...\")\n",
    "                    self.shared_settings_inst.pause_event.set()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def robot_movement(self):\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],100), min_z_height=self.dish_bottom, verbose=False)\n",
    "        while not self.shared_settings_inst.stop_event.is_set():\n",
    "            if self.shared_settings_inst.pause_event.is_set():\n",
    "                time.sleep(0.1)  # Small sleep to prevent excessive CPU usage\n",
    "                continue  # Skip to next iteration while paused\n",
    "            # print(\"Moving robot...\")\n",
    "            try:\n",
    "                # Get latest coordinates from the queue (non-blocking)\n",
    "                x, y = self.coord_queue.get(timeout=1)  # Timeout prevents indefinite blocking\n",
    "                openapi.move_to_coordinates((x, y, self.pickup_height+20), min_z_height=self.dish_bottom, verbose=False, force_direct=True)\n",
    "                openapi.move_to_coordinates((x, y, self.pickup_height), min_z_height=self.dish_bottom, verbose=False, force_direct=True)\n",
    "                openapi.aspirate_in_place(flow_rate = self.flow_rate, volume = self.vol)\n",
    "                openapi.move_relative('z', 20)\n",
    "\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    idx = self.shared_settings_inst.idx\n",
    "\n",
    "                openapi.move_to_well(openapi.labware_dct['6'], self.wells_to_fill[idx], well_location='top', offset=(self.well_offset_x, self.well_offset_y, 5), verbose = False, force_direct = True)\n",
    "                openapi.dispense(openapi.labware_dct['6'], self.wells_to_fill[idx], well_location='bottom', offset=(self.well_offset_x, self.well_offset_y, 0), volume = self.vol, flow_rate = self.flow_rate)\n",
    "                time.sleep(0.3)\n",
    "                openapi.move_to_well(openapi.labware_dct['6'], self.wells_to_fill[idx], well_location='top', offset=(self.well_offset_x, self.well_offset_y, 5), verbose=False)\n",
    "                openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],100), min_z_height=self.dish_bottom, verbose=False, force_direct=True)\n",
    "                time.sleep(0.5)\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    self.shared_settings_inst.cuboid_chosen = False\n",
    "                    self.shared_settings_inst.idx += 1 \n",
    "            except queue.Empty:\n",
    "                pass  # No new coordinates, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_settings = SharedSettings()\n",
    "cls = PickingProcedure(shared_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_thread = threading.Thread(target=cls.video, daemon=True)\n",
    "robot_thread = threading.Thread(target=cls.robot_movement, daemon=True)\n",
    "\n",
    "# Start threads\n",
    "video_thread.start()\n",
    "robot_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "video_thread.join()\n",
    "robot_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.shared_settings_inst.stop_event.is_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking procedure v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Destination:\n",
    "    WELL_PLATE_PRESETS = {\n",
    "        6: (2, 3),   # 2 rows × 3 cols\n",
    "        24: (4, 6),  # 4 rows × 6 cols\n",
    "        48: (6, 8),  # 6 rows × 8 cols\n",
    "        96: (8, 12),  # 8 rows × 12 cols\n",
    "        384: (16, 24)  # 16 rows × 24 cols\n",
    "    }\n",
    "\n",
    "    def __init__(self, plate_type=None, custom_positions=None):\n",
    "        \"\"\"\n",
    "        Defines a destination, which can be a standard well plate or custom locations.\n",
    "\n",
    "        :param plate_type: Integer for a standard well plate (6, 24, 48, 96, 384).\n",
    "        :param custom_positions: List of arbitrary locations if not using a well plate.\n",
    "        \"\"\"\n",
    "        self.plate_type = plate_type\n",
    "        self.layout = self.WELL_PLATE_PRESETS.get(plate_type, None)\n",
    "        self.custom_positions = custom_positions\n",
    "        self.positions = self.generate_positions()\n",
    "\n",
    "    def generate_positions(self):\n",
    "        \"\"\"Generates well names based on plate type or uses custom positions.\"\"\"\n",
    "        if self.custom_positions:\n",
    "            return self.custom_positions  # Use provided custom locations\n",
    "        \n",
    "        if not self.layout:\n",
    "            raise ValueError(\"Invalid well plate type or missing custom positions.\")\n",
    "\n",
    "        rows, cols = self.layout\n",
    "        row_labels = string.ascii_uppercase[:rows]  # First N letters for rows\n",
    "        return [f\"{row}{col}\" for row in row_labels for col in range(1, cols + 1)]\n",
    "\n",
    "    def get_well_index(self, well_label):\n",
    "        \"\"\"Returns the index of a well label like 'A1'.\"\"\"\n",
    "        if well_label in self.positions:\n",
    "            return self.positions.index(well_label)\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Destination(plate_type={self.plate_type}, positions={self.positions})\"\n",
    "\n",
    "\n",
    "class Routine:\n",
    "    def __init__(self, destination, well_plan, fill_strategy=\"well_by_well\"):\n",
    "        \"\"\"\n",
    "        Routine class for controlling how a well plate or location is filled.\n",
    "\n",
    "        :param destination: Destination object defining well plate/grid.\n",
    "        :param well_plan: Dictionary {well_label: target_count} defining objects per well.\n",
    "        :param fill_strategy: How the wells should be filled.\n",
    "                              Options: \"vertical\", \"horizontal\", \"well_by_well\", \"spread_out\"\n",
    "        \"\"\"\n",
    "        self.destination = destination\n",
    "        self.well_plan = well_plan  # {well_label: target_count}\n",
    "        self.fill_strategy = fill_strategy\n",
    "        self.filled_wells = {k: 0 for k in well_plan}\n",
    "        self.miss_counts = {k: 0 for k in well_plan}\n",
    "        self.completed = False\n",
    "        self.current_well = None\n",
    "\n",
    "    def get_fill_order(self):\n",
    "        \"\"\"Returns the order in which wells should be filled based on strategy.\"\"\"\n",
    "        wells = list(self.well_plan.keys())\n",
    "\n",
    "        if self.fill_strategy == \"vertical\":\n",
    "            return sorted(wells, key=lambda well: int(well[1:]))  # Sort by column number\n",
    "        elif self.fill_strategy == \"horizontal\":\n",
    "            return sorted(wells, key=lambda well: well[0])  # Sort by row letter\n",
    "        elif self.fill_strategy == \"spread_out\":\n",
    "            return sorted(wells, key=lambda well: self.well_plan[well])  # Spread out based on needs\n",
    "        else:  # Default: well_by_well\n",
    "            return wells\n",
    "\n",
    "    def get_next_well(self):\n",
    "        \"\"\"Returns the next well to be filled based on the strategy.\"\"\"\n",
    "        for well in self.get_fill_order():\n",
    "            if self.filled_wells[well] < self.well_plan[well]:\n",
    "                self.current_well = well\n",
    "                return well\n",
    "        self.completed = True\n",
    "        return None\n",
    "\n",
    "    def update_well(self, success=True):\n",
    "        \"\"\"Updates well status after an attempt.\"\"\"\n",
    "        if self.current_well is not None:\n",
    "            if success:\n",
    "                self.filled_wells[self.current_well] += 1\n",
    "            else:\n",
    "                self.miss_counts[self.current_well] += 1\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"Checks if routine is completed.\"\"\"\n",
    "        return self.completed\n",
    "\n",
    "def create_well_plan(plate_type):\n",
    "    \"\"\"Creates an empty DataFrame for well input based on the plate size.\"\"\"\n",
    "    rows, cols = Destination.WELL_PLATE_PRESETS[plate_type]\n",
    "    row_labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"[:rows])\n",
    "    col_labels = list(range(1, cols + 1))\n",
    "\n",
    "    well_df = pd.DataFrame(np.zeros((rows, cols), dtype=int), index=row_labels, columns=col_labels)\n",
    "    return well_df\n",
    "\n",
    "class SharedSettings:\n",
    "    def __init__(self, routine: Routine):\n",
    "        self.lock = threading.Lock()\n",
    "        self.cuboid_chosen = False\n",
    "        self.local_timer_set = False\n",
    "        self.routine = routine\n",
    "        self.stop_event = threading.Event()\n",
    "        self.pause_event = threading.Event()\n",
    "        self.pause_event.set()\n",
    "\n",
    "class PickingProcedure():\n",
    "    def __init__(self, shared_settings):\n",
    "        self.coord_queue = queue.Queue()\n",
    "        self.cr = core.Core()\n",
    "        self.shared_settings_inst = shared_settings\n",
    "\n",
    "        # ----------------------Robot configs-----------------------\n",
    "        self.calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "        self.tf_mtx = np.array(self.calibration_data['tf_mtx'])\n",
    "        self.calib_origin = np.array(self.calibration_data['calib_origin'])[:2]\n",
    "        self.offset = np.array(self.calibration_data['offset'])\n",
    "        self.size_conversion_ratio = self.calibration_data['size_conversion_ratio']\n",
    "        self.one_d_ratio = self.calibration_data['one_d_ratio']\n",
    "\n",
    "        # ----------------------Picking configs-----------------------\n",
    "        self.vol = 10\n",
    "        self.dish_bottom = 10.2 #10.60 for 300ul, 9.5 for 200ul\n",
    "        self.pickup_offset = 0.5\n",
    "        self.pickup_height = self.dish_bottom + self.pickup_offset\n",
    "        self.flow_rate = 50\n",
    "        self.cuboid_size_theshold = (250, 500)\n",
    "        self.failure_threshold = 0.5\n",
    "        self.minimum_distance = 1.7\n",
    "\n",
    "        # ----------------------Deposit configs-----------------------\n",
    "        self.well_offset_x = 0 \n",
    "        self.well_offset_y = 0 \n",
    "\n",
    "        # ----------------------Video configs-----------------------\n",
    "        self.circle_center = (int(1296.0), int(972.0))\n",
    "        self.circle_radius = 900\n",
    "\n",
    "        self.isolated = []\n",
    "        self.pickable_cuboids = []\n",
    "\n",
    "    def cv_pipeline(self, frame):\n",
    "        mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "        cv2.circle(mask, self.circle_center, self.circle_radius + int(self.minimum_distance / self.one_d_ratio), (255, 255, 255), -1)\n",
    "        masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "        gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,2) \n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "        # Find contours in the masked frame\n",
    "        contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        filtered_contours = [contour for contour in contours if 30 < cv2.contourArea(contour) < 1000]\n",
    "        self.cr.cuboids = filtered_contours\n",
    "        self.cr.cuboid_dataframe(self.cr.cuboids)\n",
    "\n",
    "        cuboid_size_micron2 = self.cr.cuboid_df.area * self.size_conversion_ratio * 1000000\n",
    "        cuboid_diameter = 2 * np.sqrt(cuboid_size_micron2 / np.pi)\n",
    "        dist_mm = self.cr.cuboid_df.min_dist * self.one_d_ratio\n",
    "        self.cr.cuboid_df['diameter_microns'] = cuboid_diameter\n",
    "        self.cr.cuboid_df['min_dist_mm'] = dist_mm\n",
    "        self.cr.cuboid_df['bubble'] = self.cr.cuboid_df.apply(lambda row: not bool(thresh[int(row['cY']), int(row['cX'])]), axis=1)\n",
    "        \n",
    "        # Filter out elongated contours\n",
    "        self.pickable_cuboids = self.cr.cuboid_df.loc[(self.cuboid_size_theshold[0] < self.cr.cuboid_df['diameter_microns']) & \n",
    "                                            (self.cr.cuboid_df['diameter_microns'] < self.cuboid_size_theshold[1]) &\n",
    "                                            ((self.cr.cuboid_df['aspect_ratio'] > 0.75) | (self.cr.cuboid_df['aspect_ratio'] < 1.25)) &\n",
    "                                            (self.cr.cuboid_df['circularity'] > 0.6) & \n",
    "                                            (self.cr.cuboid_df['bubble'] != True)].copy()\n",
    "\n",
    "        # Check if cuboid centers are within the circle radius from the current circle center\n",
    "        self.pickable_cuboids['distance_to_center'] = self.pickable_cuboids.apply(\n",
    "            lambda row: np.sqrt((row['cX'] - self.circle_center[0])**2 + (row['cY'] - self.circle_center[1])**2), axis=1\n",
    "        )\n",
    "        self.pickable_cuboids = self.pickable_cuboids[self.pickable_cuboids['distance_to_center'] <= self.circle_radius]\n",
    "        self.isolated = self.pickable_cuboids.loc[self.pickable_cuboids.min_dist_mm > self.minimum_distance]\n",
    "\n",
    "    def draw_annotations(self, frame, coords_tuple):\n",
    "        cv2.circle(frame, self.circle_center, self.circle_radius + int(self.minimum_distance / self.one_d_ratio), (0, 0, 255), 2)\n",
    "        cv2.circle(frame, self.circle_center, self.circle_radius, (0, 255, 0), 2)\n",
    "        x,y,z = coords_tuple\n",
    "        cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if self.routine.current_well is None:\n",
    "            self.routine.get_next_well()\n",
    "        cv2.putText(frame, f\"Filling well: {self.routine.current_well}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if self.shared_settings_inst.pause_event.is_set():\n",
    "            cv2.putText(frame, \"Paused\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        with self.shared_settings_inst.lock:\n",
    "            cuboid_chosen = self.shared_settings_inst.cuboid_chosen\n",
    "        if not cuboid_chosen:\n",
    "            cv2.drawContours(frame, self.cr.cuboids, -1, (0, 0, 255), 2)\n",
    "            cv2.drawContours(frame, self.pickable_cuboids.contour.values.tolist(), -1, (0, 255, 255), 2)\n",
    "            cv2.drawContours(frame, self.isolated.contour.values.tolist(), -1, (0, 255, 0), 2)\n",
    "        return frame\n",
    "    \n",
    "    def video(self):\n",
    "        window = cap.get_window()\n",
    "        cuboid_choice = None\n",
    "\n",
    "        while not self.shared_settings_inst.stop_event.is_set():\n",
    "            frame = cap.get_frame(undist=True)\n",
    "            plot_frame = frame.copy()\n",
    "\n",
    "            with self.shared_settings_inst.lock:\n",
    "                cuboid_chosen = self.shared_settings_inst.cuboid_chosen\n",
    "                local_timer_set = self.shared_settings_inst.local_timer_set\n",
    "                # self.current_idx = self.shared_settings_inst.idx\n",
    "                self.routine = self.shared_settings_inst.routine\n",
    "\n",
    "            x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "            if not cuboid_chosen:\n",
    "                self.cv_pipeline(frame)\n",
    "            self.draw_annotations(plot_frame, (x, y, z))\n",
    "\n",
    "            if not self.coord_queue.full() and not cuboid_chosen and not self.shared_settings_inst.pause_event.is_set() and len(self.isolated) > 0:\n",
    "                if cuboid_choice is not None:\n",
    "                    prev_x, prev_y = cuboid_choice[['cX', 'cY']].values[0]\n",
    "                    \n",
    "                    cv2.circle(plot_frame, (int(prev_x), int(prev_y)), int(round(self.failure_threshold / self.one_d_ratio)), (255, 0, 0), 2)\n",
    "                    distances = self.cr.cuboid_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "                    distances *= self.one_d_ratio\n",
    "                    if any(distances <= self.failure_threshold):\n",
    "                        with self.shared_settings_inst.lock:\n",
    "                            self.shared_settings_inst.routine.update_well(success=False)\n",
    "                        print(f\"Miss detected at well {self.routine.current_well}.\")\n",
    "                    else:\n",
    "                        with self.shared_settings_inst.lock:\n",
    "                            self.shared_settings_inst.routine.update_well(success=True)\n",
    "                            # print(f\"Filled well {self.shared_settings_inst.routine.current_well}.\")\n",
    "                            self.shared_settings_inst.routine.get_next_well()\n",
    "                            # print(f\"Next well: {self.shared_settings_inst.routine.current_well}\")\n",
    "\n",
    "                if self.shared_settings_inst.routine.is_done():\n",
    "                    self.shared_settings_inst.stop_event.set()\n",
    "                    break\n",
    "\n",
    "                cuboid_choice = self.isolated.sample(n=1) \n",
    "                cv2.drawContours(frame, cuboid_choice.contour.values.tolist(), -1, (255, 0, 0), 2)\n",
    "                # cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\'+f\"frame_{idx}.png\", frame)\n",
    "\n",
    "                cX, cY = cuboid_choice[['cX', 'cY']].values[0]\n",
    "                X_init, Y_init, _ = self.tf_mtx @ (cX, cY, 1)\n",
    "                x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                diff = np.array([x,y]) - np.array(self.calibration_data['calib_origin'])[:2]\n",
    "                X = X_init + diff[0] + self.offset[0]\n",
    "                Y = Y_init + diff[1] + self.offset[1]\n",
    "\n",
    "                next_well = self.shared_settings_inst.routine.get_next_well()\n",
    "                self.coord_queue.put((X, Y, next_well))\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    self.shared_settings_inst.cuboid_chosen = True\n",
    "            elif len(self.isolated) == 0 and not self.shared_settings_inst.pause_event.is_set():\n",
    "                self.shared_settings_inst.pause_event.set()\n",
    "                print(\"No cuboids found in the selected region. Pausing...\")\n",
    "\n",
    "            cv2.imshow(cap.window_name, plot_frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if key == ord('q'):\n",
    "                self.shared_settings_inst.stop_event.set()\n",
    "            elif key == ord('p'):\n",
    "                if self.shared_settings_inst.pause_event.is_set():\n",
    "                    self.shared_settings_inst.pause_event.clear()\n",
    "                    print(\"Resuming movement...\")\n",
    "                else:\n",
    "                    print(\"Pausing movement...\")\n",
    "                    self.shared_settings_inst.pause_event.set()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def robot_movement(self):\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],100), min_z_height=self.dish_bottom, verbose=False)\n",
    "        while not self.shared_settings_inst.stop_event.is_set():\n",
    "            if self.shared_settings_inst.pause_event.is_set():\n",
    "                time.sleep(0.1)  # Small sleep to prevent excessive CPU usage\n",
    "                continue  # Skip to next iteration while paused\n",
    "            # print(\"Moving robot...\")\n",
    "            try:\n",
    "                # with self.shared_settings_inst.lock:\n",
    "                # well = self.shared_settings_inst.routine.get_next_well()\n",
    "                # Get latest coordinates from the queue (non-blocking)\n",
    "                x, y, well = self.coord_queue.get(timeout=1)  # Timeout prevents indefinite blocking\n",
    "                openapi.move_to_coordinates((x, y, self.pickup_height+20), min_z_height=self.dish_bottom, verbose=False, force_direct=True)\n",
    "                openapi.move_to_coordinates((x, y, self.pickup_height), min_z_height=self.dish_bottom, verbose=False, force_direct=True)\n",
    "                openapi.aspirate_in_place(flow_rate = self.flow_rate, volume = self.vol)\n",
    "                openapi.move_relative('z', 20)\n",
    "\n",
    "                # print(f'actually filling well {well}')\n",
    "                openapi.move_to_well(openapi.labware_dct['6'], well, well_location='top', offset=(self.well_offset_x, self.well_offset_y, 5), verbose = False, force_direct = True)\n",
    "                openapi.dispense(openapi.labware_dct['6'], well, well_location='bottom', offset=(self.well_offset_x, self.well_offset_y, 1), volume = self.vol, flow_rate = self.flow_rate)\n",
    "                time.sleep(0.3)\n",
    "                openapi.move_to_well(openapi.labware_dct['6'], well, well_location='top', offset=(self.well_offset_x, self.well_offset_y, 5), verbose=False)\n",
    "                openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],100), min_z_height=self.dish_bottom, verbose=False, force_direct=True)\n",
    "                time.sleep(0.5)\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    self.shared_settings_inst.cuboid_chosen = False\n",
    "                    \n",
    "            except queue.Empty:\n",
    "                pass  # No new coordinates, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tip cleaning\n",
    "for i in range(5):\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location = 'bottom', volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 100, flow_rate = 200)\n",
    "openapi.move_relative('z', 40)\n",
    "\n",
    "for i in range(5):\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"B1\", well_location = 'bottom', volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct['3'], \"B1\", well_location='bottom', volume = 100, flow_rate = 200)\n",
    "openapi.move_relative('z', 40)\n",
    "\n",
    "openapi.blow_out(openapi.labware_dct['3'], \"A2\", well_location='center', flow_rate = 200)\n",
    "openapi.aspirate(openapi.labware_dct['3'], \"A2\", well_location = 'center', volume = 10, flow_rate = 200)\n",
    "openapi.dispense(openapi.labware_dct['3'], \"A2\", well_location='center', volume = 10, flow_rate = 200)\n",
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some picking solution into the tip\n",
    "openapi.aspirate(openapi.labware_dct['6'], \"B4\", well_location = 'bottom', volume = 20, offset=(0,0,1), flow_rate = 50)\n",
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.dispense(openapi.labware_dct['6'], \"B4\", well_location = 'bottom', volume = 20, flow_rate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_type = 96\n",
    "dest = Destination(plate_type)\n",
    "well_df = create_well_plan(plate_type)\n",
    "well_df.loc[['A'], 1:5] = 1 \n",
    "well_plan = {f\"{row}{col}\": well_df.loc[row, col] for row in well_df.index for col in well_df.columns if well_df.loc[row, col] > 0}\n",
    "well_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine = Routine(dest, well_plan, fill_strategy=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_settings = SharedSettings(routine)\n",
    "picking = PickingProcedure(shared_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_thread = threading.Thread(target=picking.video, daemon=True)\n",
    "robot_thread = threading.Thread(target=picking.robot_movement, daemon=True)\n",
    "\n",
    "# Start threads\n",
    "video_thread.start()\n",
    "robot_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "video_thread.join()\n",
    "robot_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking procedure v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Destination:\n",
    "    WELL_PLATE_PRESETS = {\n",
    "        6: (2, 3),   # 2 rows × 3 cols\n",
    "        24: (4, 6),  # 4 rows × 6 cols\n",
    "        48: (6, 8),  # 6 rows × 8 cols\n",
    "        96: (8, 12),  # 8 rows × 12 cols\n",
    "        384: (16, 24)  # 16 rows × 24 cols\n",
    "    }\n",
    "\n",
    "    def __init__(self, plate_type=None, custom_positions=None):\n",
    "        \"\"\"\n",
    "        Defines a destination, which can be a standard well plate or custom locations.\n",
    "\n",
    "        :param plate_type: Integer for a standard well plate (6, 24, 48, 96, 384).\n",
    "        :param custom_positions: List of arbitrary locations if not using a well plate.\n",
    "        \"\"\"\n",
    "        self.plate_type = plate_type\n",
    "        self.layout = self.WELL_PLATE_PRESETS.get(plate_type, None)\n",
    "        self.custom_positions = custom_positions\n",
    "        self.positions = self.generate_positions()\n",
    "\n",
    "    def generate_positions(self):\n",
    "        \"\"\"Generates well names based on plate type or uses custom positions.\"\"\"\n",
    "        if self.custom_positions:\n",
    "            return self.custom_positions  # Use provided custom locations\n",
    "        \n",
    "        if not self.layout:\n",
    "            raise ValueError(\"Invalid well plate type or missing custom positions.\")\n",
    "\n",
    "        rows, cols = self.layout\n",
    "        row_labels = string.ascii_uppercase[:rows]  # First N letters for rows\n",
    "        return [f\"{row}{col}\" for row in row_labels for col in range(1, cols + 1)]\n",
    "\n",
    "    def get_well_index(self, well_label):\n",
    "        \"\"\"Returns the index of a well label like 'A1'.\"\"\"\n",
    "        if well_label in self.positions:\n",
    "            return self.positions.index(well_label)\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Destination(plate_type={self.plate_type}, positions={self.positions})\"\n",
    "\n",
    "\n",
    "class Routine:\n",
    "    def __init__(self, destination, well_plan, fill_strategy=\"well_by_well\"):\n",
    "        \"\"\"\n",
    "        Routine class for controlling how a well plate or location is filled.\n",
    "\n",
    "        :param destination: Destination object defining well plate/grid.\n",
    "        :param well_plan: Dictionary {well_label: target_count} defining objects per well.\n",
    "        :param fill_strategy: How the wells should be filled.\n",
    "                              Options: \"vertical\", \"horizontal\", \"well_by_well\", \"spread_out\"\n",
    "        \"\"\"\n",
    "        self.destination = destination\n",
    "        self.well_plan = well_plan  # {well_label: target_count}\n",
    "        self.fill_strategy = fill_strategy\n",
    "        self.filled_wells = {k: 0 for k in well_plan}\n",
    "        self.miss_counts = {k: 0 for k in well_plan}\n",
    "        self.completed = False\n",
    "        self.current_well = None\n",
    "\n",
    "    def get_fill_order(self):\n",
    "        \"\"\"Returns the order in which wells should be filled based on strategy.\"\"\"\n",
    "        wells = list(self.well_plan.keys())\n",
    "\n",
    "        if self.fill_strategy == \"vertical\":\n",
    "            return sorted(wells, key=lambda well: int(well[1:]))  # Sort by column number\n",
    "        elif self.fill_strategy == \"horizontal\":\n",
    "            return sorted(wells, key=lambda well: well[0])  # Sort by row letter\n",
    "        elif self.fill_strategy == \"spread_out\":\n",
    "            return sorted(wells, key=lambda well: self.well_plan[well])  # Spread out based on needs\n",
    "        else:  # Default: well_by_well\n",
    "            return wells\n",
    "\n",
    "    def get_next_well(self):\n",
    "        \"\"\"Returns the next well to be filled based on the strategy.\"\"\"\n",
    "        for well in self.get_fill_order():\n",
    "            if self.filled_wells[well] < self.well_plan[well]:\n",
    "                self.current_well = well\n",
    "                return well\n",
    "        self.completed = True\n",
    "        return None\n",
    "\n",
    "    def update_well(self, success=True):\n",
    "        \"\"\"Updates well status after an attempt.\"\"\"\n",
    "        if self.current_well is not None:\n",
    "            if success:\n",
    "                self.filled_wells[self.current_well] += 1\n",
    "            else:\n",
    "                self.miss_counts[self.current_well] += 1\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"Checks if routine is completed.\"\"\"\n",
    "        return self.completed\n",
    "\n",
    "def create_well_plan(plate_type):\n",
    "    \"\"\"Creates an empty DataFrame for well input based on the plate size.\"\"\"\n",
    "    rows, cols = Destination.WELL_PLATE_PRESETS[plate_type]\n",
    "    row_labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"[:rows])\n",
    "    col_labels = list(range(1, cols + 1))\n",
    "\n",
    "    well_df = pd.DataFrame(np.zeros((rows, cols), dtype=int), index=row_labels, columns=col_labels)\n",
    "    return well_df\n",
    "\n",
    "def is_instance_of_type(value: Any, expected_type: Any) -> bool:\n",
    "    origin = get_origin(expected_type)\n",
    "    args = get_args(expected_type)\n",
    "\n",
    "    if origin is None:\n",
    "        return isinstance(value, expected_type)\n",
    "\n",
    "    if origin is Union:\n",
    "        return any(is_instance_of_type(value, arg) for arg in args)\n",
    "\n",
    "    if origin is tuple:\n",
    "        if len(args) == 2 and args[1] is ...:  # Tuple[int, ...]\n",
    "            return isinstance(value, tuple) and all(is_instance_of_type(v, args[0]) for v in value)\n",
    "        return (\n",
    "            isinstance(value, tuple)\n",
    "            and len(value) == len(args)\n",
    "            and all(is_instance_of_type(v, t) for v, t in zip(value, args))\n",
    "        )\n",
    "\n",
    "    if origin is list:\n",
    "        return isinstance(value, list) and all(is_instance_of_type(v, args[0]) for v in value)\n",
    "\n",
    "    if origin is dict:\n",
    "        return (\n",
    "            isinstance(value, dict)\n",
    "            and all(is_instance_of_type(k, args[0]) and is_instance_of_type(v, args[1]) for k, v in value.items())\n",
    "        )\n",
    "\n",
    "    return isinstance(value, expected_type)\n",
    "\n",
    "class MarkdownLogger:\n",
    "    def __init__(self, log_dir=paths.LOGS_DIR, experiment_name=None, settings: dict = None, well_plate: pd.DataFrame = None):\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if experiment_name is None:\n",
    "            experiment_name = f\"experiment_{timestamp}\"\n",
    "        self.log_file = os.path.join(log_dir, f\"{experiment_name}_log_{timestamp}.md\")\n",
    "        self._start_log(experiment_name, settings, well_plate)\n",
    "\n",
    "    def _start_log(self, experiment_name, settings, well_plate):\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            f.write(f\"# Log for {experiment_name}\\n\")\n",
    "            f.write(f\"_Started on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_\\n\\n\")\n",
    "            \n",
    "            if settings:\n",
    "                f.write(\"## Settings\\n\\n\")\n",
    "                f.write(\"| Key | Value |\\n\")\n",
    "                f.write(\"| --- | ----- |\\n\")\n",
    "                for key, value in settings.items():\n",
    "                    f.write(f\"| `{key}` | `{value}` |\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            if well_plate is not None:\n",
    "                f.write(\"## Well Plate Plan\\n\\n\")\n",
    "                f.write(well_plate.to_markdown(index=True))\n",
    "                f.write(\"\\n\\n\")\n",
    "\n",
    "    def log_table(self, df: pd.DataFrame, title: str = \"Table\"):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"- **[{timestamp}]** {title}\\n\\n\")\n",
    "            f.write(df.to_markdown(index=False) + '\\n\\n')\n",
    "\n",
    "    def log(self, message):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"- **[{timestamp}]** {message}\\n\")\n",
    "\n",
    "    def log_section(self, title):\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"\\n## {title}\\n\\n\")\n",
    "\n",
    "@dataclass\n",
    "class PickingConfig:\n",
    "    vol: float = 10.0\n",
    "    dish_bottom: float = 66.1 #10.60 for 300ul, 9.5 for 200ul\n",
    "    pickup_offset: float = 0.5\n",
    "    pickup_height: float = dish_bottom + pickup_offset\n",
    "    flow_rate: float = 50.0\n",
    "    cuboid_size_theshold: tuple[int, int] = (250, 500)\n",
    "    failure_threshold: float = 0.5\n",
    "    minimum_distance: float = 1.7\n",
    "    wait_time_after_deposit: float = 0.5\n",
    "    one_by_one: bool = False\n",
    "\n",
    "    # ----------------------Deposit configs-----------------------\n",
    "    well_offset_x: float = -0.3 #384 well plate\n",
    "    well_offset_y: float = -0.9 #384 well plate\n",
    "    deposit_offset_z: float = 0.5\n",
    "    destination_slot: int = 5\n",
    "\n",
    "    # ----------------------Video configs-----------------------\n",
    "    circle_center: tuple[int, int] = (1296, 972)\n",
    "    circle_radius: int = 900\n",
    "    contour_filter_window: tuple[int, int] = (30, 1000)  # min and max area for contour filtering\n",
    "    aspect_ratio_window: tuple[float, float] = (0.75, 1.25)  # min and max aspect ratio for contour filtering\n",
    "    circularity_window: tuple[float, float] = (0.6, 0.9)  # circularity range for contour filtering\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict) -> \"PickingConfig\":\n",
    "        type_hints = get_type_hints(cls)\n",
    "        init_args = {}\n",
    "\n",
    "        for f in fields(cls):\n",
    "            name = f.name\n",
    "            if name in data:\n",
    "                value = data[name]\n",
    "            elif f.default is not MISSING:\n",
    "                value = f.default\n",
    "            else:\n",
    "                raise ValueError(f\"Missing required field: {name}\")\n",
    "\n",
    "            expected_type = type_hints[name]\n",
    "            if not is_instance_of_type(value, expected_type):\n",
    "                raise TypeError(f\"Field '{name}' is expected to be {expected_type}, got {type(value)}\")\n",
    "\n",
    "            init_args[name] = value\n",
    "\n",
    "        return cls(**init_args)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "class SharedSettings:\n",
    "    def __init__(self, routine: Routine):\n",
    "        self.lock = threading.Lock()\n",
    "        self.cuboid_chosen = False\n",
    "        self.local_timer_set = False\n",
    "        self.routine = routine\n",
    "        self.stop_event = threading.Event()\n",
    "        self.pause_event = threading.Event()\n",
    "        self.pause_event.set()\n",
    "\n",
    "class PickingProcedure():\n",
    "    def __init__(self, shared_settings: SharedSettings, picking_config: PickingConfig, logger: MarkdownLogger):\n",
    "        self.coord_queue = queue.Queue()\n",
    "        self.cr = core.Core()\n",
    "        self.shared_settings_inst = shared_settings\n",
    "        self.config = picking_config\n",
    "        self.logger = logger\n",
    "\n",
    "        # ----------------------Robot configs-----------------------\n",
    "        self.calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "        self.tf_mtx = np.array(self.calibration_data['tf_mtx'])\n",
    "        self.calib_origin = np.array(self.calibration_data['calib_origin'])[:2]\n",
    "        self.offset = np.array(self.calibration_data['offset'])\n",
    "        self.size_conversion_ratio = self.calibration_data['size_conversion_ratio']\n",
    "        self.one_d_ratio = self.calibration_data['one_d_ratio']\n",
    "\n",
    "        self.isolated = []\n",
    "        self.pickable_cuboids = []\n",
    "\n",
    "    def cv_pipeline(self, frame):\n",
    "        mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "        cv2.circle(mask, self.config.circle_center, self.config.circle_radius + int(self.config.minimum_distance / self.one_d_ratio), (255, 255, 255), -1)\n",
    "        masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "        gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (11, 11), 0) #was (11, 11)\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,41,3) #was 4\n",
    "        bubble_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,5)\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "        # Find contours in the masked frame\n",
    "        contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        filtered_contours = [contour for contour in contours if self.config.contour_filter_window[0] < cv2.contourArea(contour) < self.config.contour_filter_window[1]]\n",
    "        self.cr.cuboids = filtered_contours\n",
    "        self.cr.cuboid_dataframe(self.cr.cuboids)\n",
    "\n",
    "        cuboid_size_micron2 = self.cr.cuboid_df.area * self.size_conversion_ratio * 10e5\n",
    "        cuboid_diameter = 2 * np.sqrt(cuboid_size_micron2 / np.pi)\n",
    "        dist_mm = self.cr.cuboid_df.min_dist * self.one_d_ratio\n",
    "        self.cr.cuboid_df['diameter_microns'] = cuboid_diameter\n",
    "        self.cr.cuboid_df['min_dist_mm'] = dist_mm\n",
    "        self.cr.cuboid_df['bubble'] = self.cr.cuboid_df.apply(lambda row: not bool(bubble_thresh[int(row['cY']), int(row['cX'])]), axis=1)\n",
    "        # self.cr.cuboid_df['in_range'] = self.cr.cuboid_df['diameter_microns'].between(self.config.cuboid_size_theshold[0], self.config.cuboid_size_theshold[1])\n",
    "        \n",
    "        # Filter out elongated contours\n",
    "        self.pickable_cuboids = self.cr.cuboid_df.loc[(self.config.cuboid_size_theshold[0] < self.cr.cuboid_df['diameter_microns']) & \n",
    "                                            (self.cr.cuboid_df['diameter_microns'] < self.config.cuboid_size_theshold[1]) &\n",
    "                                            ((self.cr.cuboid_df['aspect_ratio'] > self.config.aspect_ratio_window[0]) & \n",
    "                                             (self.cr.cuboid_df['aspect_ratio'] < self.config.aspect_ratio_window[1])) &\n",
    "                                            ((self.cr.cuboid_df['circularity'] > self.config.circularity_window[0]) &\n",
    "                                             (self.cr.cuboid_df['circularity'] < self.config.circularity_window[1])) & \n",
    "                                            (self.cr.cuboid_df['bubble'] != True)].copy()\n",
    "\n",
    "        # Check if cuboid centers are within the circle radius from the current circle center\n",
    "        self.pickable_cuboids['distance_to_center'] = self.pickable_cuboids.apply(\n",
    "            lambda row: np.sqrt((row['cX'] - self.config.circle_center[0])**2 + (row['cY'] - self.config.circle_center[1])**2), axis=1\n",
    "        )\n",
    "        self.pickable_cuboids = self.pickable_cuboids[self.pickable_cuboids['distance_to_center'] <= self.config.circle_radius]\n",
    "        self.isolated = self.pickable_cuboids.loc[self.pickable_cuboids.min_dist_mm > self.config.minimum_distance]\n",
    "\n",
    "    def draw_annotations(self, frame, coords_tuple):\n",
    "        cv2.circle(frame, self.config.circle_center, self.config.circle_radius + int(self.config.minimum_distance / self.one_d_ratio), (0, 0, 255), 2)\n",
    "        cv2.circle(frame, self.config.circle_center, self.config.circle_radius, (0, 255, 0), 2)\n",
    "        x,y,z = coords_tuple\n",
    "        # Add a black rectangle behind the text\n",
    "        text_background_height = 250  # Adjust height to fit all text lines\n",
    "        text_background_width = 320  # Full width of the frame\n",
    "        cv2.rectangle(frame, (0, 0), (text_background_width, text_background_height), (0, 0, 0), -1)\n",
    "        # cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if self.routine.current_well is None:\n",
    "            self.routine.get_next_well()\n",
    "        cv2.putText(frame, f\"Filling well: {self.routine.current_well}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if self.shared_settings_inst.pause_event.is_set():\n",
    "            cv2.putText(frame, \"Paused\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        with self.shared_settings_inst.lock:\n",
    "            cuboid_chosen = self.shared_settings_inst.cuboid_chosen\n",
    "        if not cuboid_chosen:\n",
    "            cv2.drawContours(frame, self.cr.cuboids, -1, (0, 0, 255), 2)\n",
    "            cv2.drawContours(frame, self.pickable_cuboids.contour.values.tolist(), -1, (0, 255, 255), 2)\n",
    "            cv2.drawContours(frame, self.isolated.contour.values.tolist(), -1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"# Objects: {len(self.cr.cuboids)}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"# Pickable: {len(self.pickable_cuboids)}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"# Isolated: {len(self.isolated)}\", (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cuboids_in_size_range = self.cr.cuboid_df.loc[(self.config.cuboid_size_theshold[0] < self.cr.cuboid_df['diameter_microns']) & \n",
    "                                            (self.cr.cuboid_df['diameter_microns'] < self.config.cuboid_size_theshold[1])].copy()\n",
    "            cv2.putText(frame, f\"# In size range: {len(cuboids_in_size_range)}\", (10, 230), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        return frame\n",
    "    \n",
    "    def calculate_robot_coordinates(self, cX, cY, robot_x, robot_y):\n",
    "        X_init, Y_init, _ = self.tf_mtx @ (cX, cY, 1)\n",
    "        diff = np.array([robot_x,robot_y]) - np.array(self.calibration_data['calib_origin'])[:2]\n",
    "        X = X_init + diff[0] + self.offset[0]\n",
    "        Y = Y_init + diff[1] + self.offset[1]\n",
    "        return X, Y\n",
    "    \n",
    "    def video(self):\n",
    "        # window = cap.get_window()\n",
    "        cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "        cuboid_choice = None\n",
    "\n",
    "        while not self.shared_settings_inst.stop_event.is_set():\n",
    "            # frame = cap.get_frame(undist=True)\n",
    "            ret, frame = over_cam.read()\n",
    "            frame = frame_ops.undistort_frame(frame)\n",
    "            plot_frame = frame.copy()\n",
    "\n",
    "            with self.shared_settings_inst.lock:\n",
    "                cuboid_chosen = self.shared_settings_inst.cuboid_chosen\n",
    "                local_timer_set = self.shared_settings_inst.local_timer_set\n",
    "                # self.current_idx = self.shared_settings_inst.idx\n",
    "                self.routine = self.shared_settings_inst.routine\n",
    "\n",
    "            robot_x, robot_y, robot_z = openapi.get_position(verbose=False)[0].values()\n",
    "            if not cuboid_chosen:\n",
    "                self.cv_pipeline(frame)\n",
    "            self.draw_annotations(plot_frame, (robot_x, robot_y, robot_z))\n",
    "\n",
    "            if not self.coord_queue.full() and not cuboid_chosen and not self.shared_settings_inst.pause_event.is_set() and len(self.isolated) > 0:\n",
    "                if cuboid_choice is not None:\n",
    "                    for prev_x, prev_y in cuboid_choice[['cX', 'cY']].values:\n",
    "                    # prev_x, prev_y = cuboid_choice[['cX', 'cY']].values\n",
    "                        cv2.circle(plot_frame, (int(prev_x), int(prev_y)), int(round(self.config.failure_threshold / self.one_d_ratio)), (255, 0, 0), 2)\n",
    "                        check_miss_df = self.cr.cuboid_df.loc[(self.cr.cuboid_df['bubble'] != True)].copy()\n",
    "                        distances = check_miss_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "                        distances *= self.one_d_ratio\n",
    "                        if any(distances <= self.config.failure_threshold):\n",
    "                            with self.shared_settings_inst.lock:\n",
    "                                self.shared_settings_inst.routine.update_well(success=False)\n",
    "                            print(f\"Miss detected at well {self.routine.current_well}.\")\n",
    "                            self.logger.log(f\"Miss detected at well {self.routine.current_well}.\")\n",
    "                        else:\n",
    "                            with self.shared_settings_inst.lock:\n",
    "                                self.shared_settings_inst.routine.update_well(success=True)\n",
    "                                self.shared_settings_inst.routine.get_next_well()\n",
    "\n",
    "                if self.shared_settings_inst.routine.is_done():\n",
    "                    self.shared_settings_inst.stop_event.set()\n",
    "                    break\n",
    "\n",
    "                next_well = self.shared_settings_inst.routine.get_next_well()\n",
    "                cuboids_to_fill = self.shared_settings_inst.routine.well_plan[next_well] - self.shared_settings_inst.routine.filled_wells[next_well]\n",
    "                if not self.config.one_by_one:\n",
    "                    if len(self.isolated) > cuboids_to_fill:\n",
    "                        cuboid_choice = self.isolated.sample(n=cuboids_to_fill)\n",
    "                    else:\n",
    "                        cuboid_choice = self.isolated\n",
    "                else:\n",
    "                    cuboid_choice = self.isolated.sample(n=1)\n",
    "\n",
    "                for idx, row in cuboid_choice.iterrows():\n",
    "                    x, y, w, h = cv2.boundingRect(row['contour'])\n",
    "                    # Calculate center and size of the bounding box\n",
    "                    center_x = x + w / 2\n",
    "                    center_y = y + h / 2\n",
    "                    new_w = int(w * 1.25)\n",
    "                    new_h = int(h * 1.25)\n",
    "                    new_x = int(center_x - new_w / 2)\n",
    "                    new_y = int(center_y - new_h / 2)\n",
    "                    cv2.rectangle(plot_frame, (new_x, new_y), (new_x + new_w, new_y + new_h), (0, 0, 0), 2)\n",
    "\n",
    "                # cuboid_choice = self.isolated.sample(n=1)\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"frame_{timestamp}.png\"\n",
    "                cv2.imwrite(str(paths.BASE_DIR)+'\\\\outputs\\\\images\\\\picking_testing\\\\'+filename, plot_frame)\n",
    "\n",
    "                cuboid_coordinates = cuboid_choice[['cX', 'cY']].values\n",
    "                world_coordinates = []\n",
    "                for cX, cY in cuboid_coordinates:\n",
    "                    X, Y = self.calculate_robot_coordinates(cX, cY, robot_x, robot_y)\n",
    "                    world_coordinates.append((X, Y))\n",
    "\n",
    "                self.coord_queue.put((world_coordinates, next_well))\n",
    "                self.logger.log_table(cuboid_choice.loc[:, cuboid_choice.columns != 'contour'], title=f\"Filling well {next_well}\")\n",
    "\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    self.shared_settings_inst.cuboid_chosen = True\n",
    "            elif len(self.isolated) == 0 and not self.shared_settings_inst.pause_event.is_set():\n",
    "                self.shared_settings_inst.pause_event.set()\n",
    "                print(\"No cuboids found in the selected region. Pausing...\")\n",
    "                self.logger.log(\"No cuboids found in the selected region. Pausing...\")\n",
    "\n",
    "            cv2.imshow(\"video\", plot_frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if key == ord('q'):\n",
    "                self.shared_settings_inst.stop_event.set()\n",
    "            elif key == ord('p'):\n",
    "                if self.shared_settings_inst.pause_event.is_set():\n",
    "                    self.shared_settings_inst.pause_event.clear()\n",
    "                    print(\"Resuming movement...\")\n",
    "                else:\n",
    "                    print(\"Pausing movement...\")\n",
    "                    self.shared_settings_inst.pause_event.set()\n",
    "        self.logger.log(\"Picking procedure finished.\")\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def robot_movement(self):\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],115), min_z_height=self.config.dish_bottom, verbose=False)\n",
    "        while not self.shared_settings_inst.stop_event.is_set():\n",
    "            if self.shared_settings_inst.pause_event.is_set():\n",
    "                time.sleep(0.1)  # Small sleep to prevent excessive CPU usage\n",
    "                continue  # Skip to next iteration while paused\n",
    "            # print(\"Moving robot...\")\n",
    "            try:\n",
    "                world_coordinates, well = self.coord_queue.get(timeout=1)  # Timeout prevents indefinite blocking\n",
    "                for x,y in world_coordinates:\n",
    "                    openapi.move_to_coordinates((x, y, self.config.pickup_height+20), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "                    openapi.move_to_coordinates((x, y, self.config.pickup_height), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "                    time.sleep(2)\n",
    "                    openapi.aspirate_in_place(flow_rate = self.config.flow_rate, volume = self.config.vol)\n",
    "                    openapi.move_relative('z', 20)\n",
    "                openapi.move_to_well(openapi.labware_dct[str(self.config.destination_slot)], well, well_location='top', offset=(self.config.well_offset_x, self.config.well_offset_y, 5), verbose = False, force_direct = True)\n",
    "                openapi.dispense(openapi.labware_dct[str(self.config.destination_slot)], well, well_location='bottom', offset=(self.config.well_offset_x, self.config.well_offset_y, self.config.deposit_offset_z), volume = self.config.vol * len(world_coordinates), flow_rate = self.config.flow_rate)\n",
    "                time.sleep(self.config.wait_time_after_deposit)\n",
    "                openapi.move_to_well(openapi.labware_dct[str(self.config.destination_slot)], well, well_location='top', offset=(self.config.well_offset_x, self.config.well_offset_y, 5), verbose=False)\n",
    "                openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],115), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "                time.sleep(0.5)\n",
    "                with self.shared_settings_inst.lock:\n",
    "                    self.shared_settings_inst.cuboid_chosen = False\n",
    "                    \n",
    "            except queue.Empty:\n",
    "                pass  # No new coordinates, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tip cleaning\n",
    "for i in range(5):\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"A1\", well_location = 'bottom', volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct['3'], \"A1\", well_location='bottom', volume = 100, flow_rate = 200)\n",
    "openapi.move_relative('z', 40)\n",
    "\n",
    "for i in range(5):\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"B1\", well_location = 'bottom', volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct['3'], \"B1\", well_location='bottom', volume = 100, flow_rate = 200)\n",
    "openapi.move_relative('z', 40)\n",
    "\n",
    "openapi.blow_out(openapi.labware_dct['3'], \"B2\", well_location='center', flow_rate = 200)\n",
    "openapi.aspirate(openapi.labware_dct['3'], \"B2\", well_location = 'center', volume = 10, flow_rate = 200)\n",
    "openapi.dispense(openapi.labware_dct['3'], \"B2\", well_location='center', volume = 10, flow_rate = 200)\n",
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.dispense_in_place(volume = 10, flow_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out_in_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    openapi.aspirate(openapi.labware_dct['3'], \"A2\", well_location = 'bottom', volume = 100, flow_rate = 200)\n",
    "    openapi.dispense(openapi.labware_dct['3'], \"A2\", well_location='bottom', volume = 100, flow_rate = 200)\n",
    "openapi.move_relative('z', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.dispense(openapi.labware_dct['4'], \"A1\", well_location='center', volume = 20, flow_rate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.aspirate(openapi.labware_dct['4'], \"A1\", well_location = 'bottom', volume = 20, flow_rate = 50)\n",
    "# openapi.move_relative('z', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = 0.0\n",
    "y_offset = 0.0\n",
    "# openapi.move_to_well(openapi.labware_dct['5'], \"A1\", well_location=\"top\", offset=(x_offset, y_offset, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picking_settings = {'vol': 10.0,\n",
    "                    'dish_bottom': 66.1,\n",
    "                    'pickup_offset': 0.5,\n",
    "                    'flow_rate': 50.0,\n",
    "                    'cuboid_size_theshold': (300, 550),\n",
    "                    'failure_threshold': 0.5,\n",
    "                    'minimum_distance': 2.0,\n",
    "                    'wait_time_after_deposit': 0.3,\n",
    "                    'one_by_one': True,\n",
    "                    'well_offset_x': x_offset,\n",
    "                    'well_offset_y': y_offset,\n",
    "                    'deposit_offset_z': 0.2,\n",
    "                    'destination_slot': 5,\n",
    "                    'circle_center': (1296, 972),\n",
    "                    'circle_radius': 900,\n",
    "                    'contour_filter_window': (50, 3000),\n",
    "                    'aspect_ratio_window': (0.85, 1.15),\n",
    "                    'circularity_window': (0.4, 0.9)}\n",
    "\n",
    "picking_config = PickingConfig.from_dict(picking_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.aspirate_in_place(volume = 10, flow_rate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_type = 96\n",
    "dest = Destination(plate_type)\n",
    "well_df = create_well_plan(plate_type)\n",
    "well_df.loc['A', :] = 1\n",
    "\n",
    "# well_df.loc['A', :] = 1\n",
    "well_plan = {f\"{row}{col}\": well_df.loc[row, col] for row in well_df.index for col in well_df.columns if well_df.loc[row, col] > 0}\n",
    "well_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine = Routine(dest, well_plan, fill_strategy=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_settings = SharedSettings(routine)\n",
    "logger = MarkdownLogger(experiment_name=\"New-platform-test\", settings=picking_settings, well_plate=well_df)\n",
    "logger.log_section(\"Execution start:\")\n",
    "picking = PickingProcedure(shared_settings, picking_config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_thread = threading.Thread(target=picking.video, daemon=True)\n",
    "robot_thread = threading.Thread(target=picking.robot_movement, daemon=True)\n",
    "\n",
    "# Start threads\n",
    "video_thread.start()\n",
    "robot_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "video_thread.join()\n",
    "robot_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "picking.cr.cuboid_df['diameter_microns'].hist(bins=30)\n",
    "plt.xlabel('Diameter (microns)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Cuboid Diameters')\n",
    "plt.show()\n",
    "\n",
    "picking.cr.cuboid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picking.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = over_cam.read()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "cv2.circle(mask, picking.config.circle_center, picking.config.circle_radius + int(picking.config.minimum_distance / picking.one_d_ratio), (255, 255, 255), -1)\n",
    "masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,47,3)\n",
    "bubble_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_miss_counts = {key: value for key, value in routine.miss_counts.items() if value != 0}\n",
    "non_zero_miss_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "well_offset_x = 1\n",
    "well_offset_y = -1.5\n",
    "while idx < len(non_zero_miss_counts):\n",
    "    well_name, miss_count = list(non_zero_miss_counts.items())[idx]\n",
    "    r = openapi.aspirate(openapi.labware_dct['6'], f\"{well_name}\", well_location = 'bottom', offset = (well_offset_x,well_offset_y,3), volume = miss_count*10, flow_rate = 5)\n",
    "    responce_dict = json.loads(r.text)['data']\n",
    "    if responce_dict['status'] == 'failed':\n",
    "        if responce_dict['error']['errorType'] == 'InvalidAspirateVolumeError':\n",
    "            print('Dumping fluid')\n",
    "            openapi.blow_out(openapi.labware_dct['3'], \"B2\", well_location='center', flow_rate = 200)\n",
    "    else:\n",
    "        idx += 1\n",
    "    \n",
    "openapi.blow_out(openapi.labware_dct['3'], \"B2\", well_location='center', flow_rate = 200)\n",
    "openapi.move_relative('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.blow_out_in_place()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking procedure v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Destination:\n",
    "    WELL_PLATE_PRESETS = {\n",
    "        6: (2, 3),   # 2 rows × 3 cols\n",
    "        24: (4, 6),  # 4 rows × 6 cols\n",
    "        48: (6, 8),  # 6 rows × 8 cols\n",
    "        96: (8, 12),  # 8 rows × 12 cols\n",
    "        384: (16, 24)  # 16 rows × 24 cols\n",
    "    }\n",
    "\n",
    "    def __init__(self, plate_type=None, custom_positions=None):\n",
    "        \"\"\"\n",
    "        Defines a destination, which can be a standard well plate or custom locations.\n",
    "\n",
    "        :param plate_type: Integer for a standard well plate (6, 24, 48, 96, 384).\n",
    "        :param custom_positions: List of arbitrary locations if not using a well plate.\n",
    "        \"\"\"\n",
    "        self.plate_type = plate_type\n",
    "        self.layout = self.WELL_PLATE_PRESETS.get(plate_type, None)\n",
    "        self.custom_positions = custom_positions\n",
    "        self.positions = self.generate_positions()\n",
    "\n",
    "    def generate_positions(self):\n",
    "        \"\"\"Generates well names based on plate type or uses custom positions.\"\"\"\n",
    "        if self.custom_positions:\n",
    "            return self.custom_positions  # Use provided custom locations\n",
    "        \n",
    "        if not self.layout:\n",
    "            raise ValueError(\"Invalid well plate type or missing custom positions.\")\n",
    "\n",
    "        rows, cols = self.layout\n",
    "        row_labels = string.ascii_uppercase[:rows]  # First N letters for rows\n",
    "        return [f\"{row}{col}\" for row in row_labels for col in range(1, cols + 1)]\n",
    "\n",
    "    def get_well_index(self, well_label):\n",
    "        \"\"\"Returns the index of a well label like 'A1'.\"\"\"\n",
    "        if well_label in self.positions:\n",
    "            return self.positions.index(well_label)\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Destination(plate_type={self.plate_type}, positions={self.positions})\"\n",
    "\n",
    "\n",
    "class Routine:\n",
    "    def __init__(self, destination, well_plan, fill_strategy=\"well_by_well\"):\n",
    "        \"\"\"\n",
    "        Routine class for controlling how a well plate or location is filled.\n",
    "\n",
    "        :param destination: Destination object defining well plate/grid.\n",
    "        :param well_plan: Dictionary {well_label: target_count} defining objects per well.\n",
    "        :param fill_strategy: How the wells should be filled.\n",
    "                              Options: \"vertical\", \"horizontal\", \"well_by_well\", \"spread_out\"\n",
    "        \"\"\"\n",
    "        self.destination = destination\n",
    "        self.well_plan = well_plan  # {well_label: target_count}\n",
    "        self.fill_strategy = fill_strategy\n",
    "        self.filled_wells = {k: 0 for k in well_plan}\n",
    "        self.miss_counts = {k: 0 for k in well_plan}\n",
    "        self.completed = False\n",
    "        self.current_well = None\n",
    "\n",
    "    def get_fill_order(self):\n",
    "        \"\"\"Returns the order in which wells should be filled based on strategy.\"\"\"\n",
    "        wells = list(self.well_plan.keys())\n",
    "\n",
    "        if self.fill_strategy == \"vertical\":\n",
    "            return sorted(wells, key=lambda well: int(well[1:]))  # Sort by column number\n",
    "        elif self.fill_strategy == \"horizontal\":\n",
    "            return sorted(wells, key=lambda well: well[0])  # Sort by row letter\n",
    "        elif self.fill_strategy == \"spread_out\":\n",
    "            return sorted(wells, key=lambda well: self.well_plan[well])  # Spread out based on needs\n",
    "        else:  # Default: well_by_well\n",
    "            return wells\n",
    "\n",
    "    def get_next_well(self):\n",
    "        \"\"\"Returns the next well to be filled based on the strategy.\"\"\"\n",
    "        for well in self.get_fill_order():\n",
    "            if self.filled_wells[well] < self.well_plan[well]:\n",
    "                self.current_well = well\n",
    "                return well\n",
    "        self.completed = True\n",
    "        return None\n",
    "\n",
    "    def update_well(self, success=True):\n",
    "        \"\"\"Updates well status after an attempt.\"\"\"\n",
    "        if self.current_well is not None:\n",
    "            if success:\n",
    "                self.filled_wells[self.current_well] += 1\n",
    "            else:\n",
    "                self.miss_counts[self.current_well] += 1\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"Checks if routine is completed.\"\"\"\n",
    "        return self.completed\n",
    "\n",
    "def create_well_plan(plate_type):\n",
    "    \"\"\"Creates an empty DataFrame for well input based on the plate size.\"\"\"\n",
    "    rows, cols = Destination.WELL_PLATE_PRESETS[plate_type]\n",
    "    row_labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"[:rows])\n",
    "    col_labels = list(range(1, cols + 1))\n",
    "\n",
    "    well_df = pd.DataFrame(np.zeros((rows, cols), dtype=int), index=row_labels, columns=col_labels)\n",
    "    return well_df\n",
    "\n",
    "def is_instance_of_type(value: Any, expected_type: Any) -> bool:\n",
    "    origin = get_origin(expected_type)\n",
    "    args = get_args(expected_type)\n",
    "\n",
    "    if origin is None:\n",
    "        return isinstance(value, expected_type)\n",
    "\n",
    "    if origin is Union:\n",
    "        return any(is_instance_of_type(value, arg) for arg in args)\n",
    "\n",
    "    if origin is tuple:\n",
    "        if len(args) == 2 and args[1] is ...:  # Tuple[int, ...]\n",
    "            return isinstance(value, tuple) and all(is_instance_of_type(v, args[0]) for v in value)\n",
    "        return (\n",
    "            isinstance(value, tuple)\n",
    "            and len(value) == len(args)\n",
    "            and all(is_instance_of_type(v, t) for v, t in zip(value, args))\n",
    "        )\n",
    "\n",
    "    if origin is list:\n",
    "        return isinstance(value, list) and all(is_instance_of_type(v, args[0]) for v in value)\n",
    "\n",
    "    if origin is dict:\n",
    "        return (\n",
    "            isinstance(value, dict)\n",
    "            and all(is_instance_of_type(k, args[0]) and is_instance_of_type(v, args[1]) for k, v in value.items())\n",
    "        )\n",
    "\n",
    "    return isinstance(value, expected_type)\n",
    "\n",
    "class MarkdownLogger:\n",
    "    def __init__(self, log_dir=paths.LOGS_DIR, experiment_name=None, settings: dict = None, well_plate: pd.DataFrame = None):\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if experiment_name is None:\n",
    "            experiment_name = f\"experiment_{timestamp}\"\n",
    "        self.log_file = os.path.join(log_dir, f\"{experiment_name}_log_{timestamp}.md\")\n",
    "        self._start_log(experiment_name, settings, well_plate)\n",
    "\n",
    "    def _start_log(self, experiment_name, settings, well_plate):\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            f.write(f\"# Log for {experiment_name}\\n\")\n",
    "            f.write(f\"_Started on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_\\n\\n\")\n",
    "            \n",
    "            if settings:\n",
    "                f.write(\"## Settings\\n\\n\")\n",
    "                f.write(\"| Key | Value |\\n\")\n",
    "                f.write(\"| --- | ----- |\\n\")\n",
    "                for key, value in settings.items():\n",
    "                    f.write(f\"| `{key}` | `{value}` |\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            if well_plate is not None:\n",
    "                f.write(\"## Well Plate Plan\\n\\n\")\n",
    "                f.write(well_plate.to_markdown(index=True))\n",
    "                f.write(\"\\n\\n\")\n",
    "\n",
    "    def log_table(self, df: pd.DataFrame, title: str = \"Table\"):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"- **[{timestamp}]** {title}\\n\\n\")\n",
    "            f.write(df.to_markdown(index=False) + '\\n\\n')\n",
    "\n",
    "    def log(self, message):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"- **[{timestamp}]** {message}\\n\")\n",
    "\n",
    "    def log_section(self, title):\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"\\n## {title}\\n\\n\")\n",
    "\n",
    "@dataclass\n",
    "class PickingConfig:\n",
    "    vol: float = 10.0\n",
    "    dish_bottom: float = 66.1 #10.60 for 300ul, 9.5 for 200ul\n",
    "    pickup_offset: float = 0.5\n",
    "    pickup_height: float = dish_bottom + pickup_offset\n",
    "    flow_rate: float = 50.0\n",
    "    cuboid_size_theshold: tuple[int, int] = (250, 500)\n",
    "    failure_threshold: float = 0.5\n",
    "    minimum_distance: float = 1.7\n",
    "    wait_time_after_deposit: float = 0.5\n",
    "    one_by_one: bool = False\n",
    "\n",
    "    # ----------------------Deposit configs-----------------------\n",
    "    well_offset_x: float = -0.3 #384 well plate\n",
    "    well_offset_y: float = -0.9 #384 well plate\n",
    "    deposit_offset_z: float = 0.5\n",
    "    destination_slot: int = 5\n",
    "\n",
    "    # ----------------------Video configs-----------------------\n",
    "    circle_center: tuple[int, int] = (1296, 972)\n",
    "    circle_radius: int = 900\n",
    "    contour_filter_window: tuple[int, int] = (30, 1000)  # min and max area for contour filtering\n",
    "    aspect_ratio_window: tuple[float, float] = (0.75, 1.25)  # min and max aspect ratio for contour filtering\n",
    "    circularity_window: tuple[float, float] = (0.6, 0.9)  # circularity range for contour filtering\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict) -> \"PickingConfig\":\n",
    "        type_hints = get_type_hints(cls)\n",
    "        init_args = {}\n",
    "\n",
    "        for f in fields(cls):\n",
    "            name = f.name\n",
    "            if name in data:\n",
    "                value = data[name]\n",
    "            elif f.default is not MISSING:\n",
    "                value = f.default\n",
    "            else:\n",
    "                raise ValueError(f\"Missing required field: {name}\")\n",
    "\n",
    "            expected_type = type_hints[name]\n",
    "            if not is_instance_of_type(value, expected_type):\n",
    "                raise TypeError(f\"Field '{name}' is expected to be {expected_type}, got {type(value)}\")\n",
    "\n",
    "            init_args[name] = value\n",
    "\n",
    "        return cls(**init_args)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return asdict(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotState(Enum):\n",
    "    IDLE = 'idle'\n",
    "    CAPTURE_FRAME = 'capture_frame'\n",
    "    ANALYZE_FRAME = 'analyze_frame'\n",
    "    APPROACH_TARGET = 'approach_target'\n",
    "    PICKUP_SAMPLE = 'pickup_sample'\n",
    "    VERIFY_PICKUP = 'verify_pickup'\n",
    "    DEPOSIT_BACK = 'deposit_liquid_back'\n",
    "    TRANSFER_TO_WELL = 'transfer_to_well'\n",
    "    PAUSED = 'paused'\n",
    "    CANCELED = 'canceled'\n",
    "    COMPLETED = 'completed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import keyboard\n",
    "    KEYBOARD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    KEYBOARD_AVAILABLE = False\n",
    "    print(\"Warning: 'keyboard' module not found. Install with: pip install keyboard\")\n",
    "\n",
    "class TissuePickerFSM():\n",
    "    def __init__(self, config: PickingConfig, routine: Routine, logger: MarkdownLogger):\n",
    "        self.state = RobotState.IDLE\n",
    "        self.display_process = camera.FrameDisplayProcess(\"Tissue Picker Vision\")\n",
    "        self.logger = logger\n",
    "        self.running = True\n",
    "        self.paused = False\n",
    "        self.keyboard_lock = threading.Lock()\n",
    "        self.keyboard_hooks = []\n",
    "\n",
    "        self.config = config\n",
    "        self.routine = routine\n",
    "        self.cr = core.Core()\n",
    "\n",
    "        self.calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "        self.tf_mtx = np.array(self.calibration_data['tf_mtx'])\n",
    "        self.calib_origin = np.array(self.calibration_data['calib_origin'])[:2]\n",
    "        self.offset = np.array(self.calibration_data['offset'])\n",
    "        self.size_conversion_ratio = self.calibration_data['size_conversion_ratio']\n",
    "        self.one_d_ratio = self.calibration_data['one_d_ratio']\n",
    "\n",
    "        self.isolated = []\n",
    "        self.pickable_cuboids = []\n",
    "        self.world_coordinates = []\n",
    "        self.cuboid_choice = None\n",
    "        self.current_frame = None\n",
    "        self.current_well = self.routine.get_next_well()\n",
    "\n",
    "    def calculate_robot_coordinates(self, cX, cY, robot_x, robot_y):\n",
    "        X_init, Y_init, _ = self.tf_mtx @ (cX, cY, 1)\n",
    "        diff = np.array([robot_x,robot_y]) - self.calib_origin\n",
    "        X = X_init + diff[0] + self.offset[0]\n",
    "        Y = Y_init + diff[1] + self.offset[1]\n",
    "        return X, Y\n",
    "    \n",
    "    def cv_pipeline(self, frame):\n",
    "        mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "        cv2.circle(mask, self.config.circle_center, self.config.circle_radius + int(self.config.minimum_distance / self.one_d_ratio), (255, 255, 255), -1)\n",
    "        masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "        gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (11, 11), 0) #was (11, 11)\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,41,3) #was 4\n",
    "        self.bubble_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,5)\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "        # Find contours in the masked frame\n",
    "        contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        filtered_contours = [contour for contour in contours if self.config.contour_filter_window[0] < cv2.contourArea(contour) < self.config.contour_filter_window[1]]\n",
    "        self.cr.cuboids = filtered_contours\n",
    "        self.cr.cuboid_dataframe(self.cr.cuboids)\n",
    "\n",
    "        cuboid_size_micron2 = self.cr.cuboid_df.area * self.size_conversion_ratio * 10e5\n",
    "        cuboid_diameter = 2 * np.sqrt(cuboid_size_micron2 / np.pi)\n",
    "        dist_mm = self.cr.cuboid_df.min_dist * self.one_d_ratio\n",
    "        self.cr.cuboid_df['diameter_microns'] = cuboid_diameter\n",
    "        self.cr.cuboid_df['min_dist_mm'] = dist_mm\n",
    "        # Check if the dataframe is not empty before applying operations\n",
    "        if len(self.cr.cuboid_df) > 0:\n",
    "            self.cr.cuboid_df['bubble'] = self.cr.cuboid_df.apply(lambda row: not bool(self.bubble_thresh[int(row['cY']), int(row['cX'])]), axis=1)\n",
    "\n",
    "            # Filter out elongated contours\n",
    "            self.pickable_cuboids = self.cr.cuboid_df.loc[(self.config.cuboid_size_theshold[0] < self.cr.cuboid_df['diameter_microns']) & \n",
    "                                                (self.cr.cuboid_df['diameter_microns'] < self.config.cuboid_size_theshold[1]) &\n",
    "                                                ((self.cr.cuboid_df['aspect_ratio'] > self.config.aspect_ratio_window[0]) & \n",
    "                                                    (self.cr.cuboid_df['aspect_ratio'] < self.config.aspect_ratio_window[1])) &\n",
    "                                                ((self.cr.cuboid_df['circularity'] > self.config.circularity_window[0]) &\n",
    "                                                    (self.cr.cuboid_df['circularity'] < self.config.circularity_window[1])) & \n",
    "                                                (self.cr.cuboid_df['bubble'] != True)].copy()\n",
    "\n",
    "            # Check if cuboid centers are within the circle radius from the current circle center\n",
    "            self.pickable_cuboids['distance_to_center'] = self.pickable_cuboids.apply(\n",
    "                lambda row: np.sqrt((row['cX'] - self.config.circle_center[0])**2 + (row['cY'] - self.config.circle_center[1])**2), axis=1\n",
    "            )\n",
    "            self.pickable_cuboids = self.pickable_cuboids[self.pickable_cuboids['distance_to_center'] <= self.config.circle_radius]\n",
    "            self.isolated = self.pickable_cuboids.loc[self.pickable_cuboids.min_dist_mm > self.config.minimum_distance]\n",
    "        else:\n",
    "            self.pickable_cuboids = []\n",
    "            self.isolated = []\n",
    "\n",
    "    def draw_annotations(self, frame):\n",
    "        cv2.circle(frame, self.config.circle_center, self.config.circle_radius + int(self.config.minimum_distance / self.one_d_ratio), (0, 0, 255), 2)\n",
    "        cv2.circle(frame, self.config.circle_center, self.config.circle_radius, (0, 255, 0), 2)\n",
    "        # Add a black rectangle behind the text\n",
    "        text_background_height = 250  # Adjust height to fit all text lines\n",
    "        text_background_width = 320  # Full width of the frame\n",
    "        cv2.rectangle(frame, (0, 0), (text_background_width, text_background_height), (0, 0, 0), -1)\n",
    "        if self.routine.current_well is None:\n",
    "            self.routine.get_next_well()\n",
    "        cv2.putText(frame, f\"Filling well: {self.routine.current_well}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if self.paused:\n",
    "            cv2.putText(frame, \"Paused\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if self.cr.cuboids:\n",
    "            cv2.drawContours(frame, self.cr.cuboids, -1, (0, 0, 255), 2)\n",
    "            cv2.drawContours(frame, self.pickable_cuboids.contour.values.tolist(), -1, (0, 255, 255), 2)\n",
    "            cv2.drawContours(frame, self.isolated.contour.values.tolist(), -1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"# Objects: {len(self.cr.cuboids)}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"# Pickable: {len(self.pickable_cuboids)}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"# Isolated: {len(self.isolated)}\", (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cuboids_in_size_range = self.cr.cuboid_df.loc[(self.config.cuboid_size_theshold[0] < self.cr.cuboid_df['diameter_microns']) & \n",
    "                                        (self.cr.cuboid_df['diameter_microns'] < self.config.cuboid_size_theshold[1])].copy()\n",
    "        cv2.putText(frame, f\"# In size range: {len(cuboids_in_size_range)}\", (10, 230), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        if self.cuboid_choice is not None:\n",
    "            for idx, row in self.cuboid_choice.iterrows():\n",
    "                x, y, w, h = cv2.boundingRect(row['contour'])\n",
    "                # Calculate center and size of the bounding box\n",
    "                center_x = x + w / 2\n",
    "                center_y = y + h / 2\n",
    "                new_w = int(w * 1.25)\n",
    "                new_h = int(h * 1.25)\n",
    "                new_x = int(center_x - new_w / 2)\n",
    "                new_y = int(center_y - new_h / 2)\n",
    "                cv2.rectangle(frame, (new_x, new_y), (new_x + new_w, new_y + new_h), (0, 0, 0), 2)\n",
    "\n",
    "        return frame\n",
    "    \n",
    "    def _setup_keyboard_hooks(self):\n",
    "        \"\"\"Setup global keyboard hooks using the keyboard module\"\"\"\n",
    "        if not KEYBOARD_AVAILABLE:\n",
    "            print(\"Keyboard module not available. No keyboard controls will work.\")\n",
    "            return\n",
    "            \n",
    "        def on_pause_key(event):\n",
    "            if event.event_type == keyboard.KEY_DOWN:\n",
    "                with self.keyboard_lock:\n",
    "                    self.paused = not self.paused\n",
    "                    status = \"PAUSED\" if self.paused else \"RESUMED\"\n",
    "                    print(f\"\\n[CONTROL] Robot {status}\")\n",
    "        \n",
    "        def on_escape_key(event):\n",
    "            if event.event_type == keyboard.KEY_DOWN:\n",
    "                with self.keyboard_lock:\n",
    "                    print(\"\\n[CONTROL] Emergency stop! Shutting down...\")\n",
    "                    self.running = False\n",
    "        \n",
    "        # Register keyboard hooks\n",
    "        try:\n",
    "            self.keyboard_hooks.append(keyboard.on_press_key('p', on_pause_key))\n",
    "            self.keyboard_hooks.append(keyboard.on_press_key('esc', on_escape_key))\n",
    "            print(\"Keyboard hooks registered successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to register keyboard hooks: {e}\")\n",
    "            print(\"Note: On some systems, you may need to run as administrator/root.\")\n",
    "    \n",
    "    def _cleanup_keyboard_hooks(self):\n",
    "        \"\"\"Remove keyboard hooks\"\"\"\n",
    "        if KEYBOARD_AVAILABLE:\n",
    "            try:\n",
    "                for hook in self.keyboard_hooks:\n",
    "                    keyboard.unhook(hook)\n",
    "                self.keyboard_hooks.clear()\n",
    "            except Exception as e:\n",
    "                print(f\"Error cleaning up keyboard hooks: {e}\")\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the FSM with global keyboard controls\"\"\"\n",
    "        print(\"=== Tissue Picker Robot FSM Started ===\")\n",
    "        if KEYBOARD_AVAILABLE:\n",
    "            print(\"  'p' - Pause/Resume\")\n",
    "            print(\"  'ESC' - Emergency stop and quit\")\n",
    "        else:\n",
    "            print(\"No keyboard controls available (keyboard module not installed)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Setup keyboard hooks\n",
    "        self._setup_keyboard_hooks()\n",
    "        self.display_process.start()\n",
    "        \n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.keyboard_lock:\n",
    "                    if self.paused:\n",
    "                        time.sleep(0.1)\n",
    "                        continue\n",
    "                \n",
    "                # Execute current state\n",
    "                if hasattr(self, f\"state_{self.state.value}\"):\n",
    "                    getattr(self, f\"state_{self.state.value}\")()\n",
    "                else:\n",
    "                    print(f\"Error: Unknown state {self.state.value}\")\n",
    "                    self.running = False\n",
    "                \n",
    "                # Small delay to prevent overwhelming the output\n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n[CONTROL] Keyboard interrupt received. Shutting down...\")\n",
    "            self.running = False\n",
    "        \n",
    "        finally:\n",
    "            # Cleanup keyboard hooks\n",
    "            self._cleanup_keyboard_hooks()\n",
    "            self.display_process.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"\\n=== Tissue Picker Robot FSM Stopped ===\")\n",
    "\n",
    "    def state_idle(self):\n",
    "        print(\"Robot is idle. Press 'p' to continue...\")\n",
    "        self.paused = True  # Ensure the robot is paused in idle state\n",
    "        # Move to picking position\n",
    "        openapi.retract_axis('leftZ')\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],115), min_z_height=self.config.dish_bottom, verbose=False)\n",
    "        # Turn off lights\n",
    "        current_status = openapi.get(\"lights\", openapi.HEADERS)\n",
    "        current_status = json.loads(current_status.text)\n",
    "        is_on = current_status['on']\n",
    "        if is_on:\n",
    "            openapi.toggle_lights()\n",
    "        self.display_process.send_status(\"Robot IDLE - Press 'p' to continue\", (0, 0, 255))\n",
    "\n",
    "        while self.paused and self.running:\n",
    "            try:\n",
    "                ret, frame = over_cam.read()\n",
    "                frame = frame_ops.undistort_frame(frame)\n",
    "                plot_frame = frame.copy()\n",
    "                self.cv_pipeline(frame)\n",
    "                self.draw_annotations(plot_frame)\n",
    "                self.display_process.send_frame(plot_frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in idle state: {e}\")\n",
    "                self.running = False\n",
    "                break\n",
    "\n",
    "        self.state = RobotState.CAPTURE_FRAME\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def state_capture_frame(self):\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],115), min_z_height=self.config.dish_bottom, verbose=False)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        ret, frame = over_cam.read()\n",
    "        self.current_frame = frame_ops.undistort_frame(frame)\n",
    "        self.state = RobotState.ANALYZE_FRAME\n",
    "\n",
    "    def state_analyze_frame(self):\n",
    "        self.cv_pipeline(self.current_frame)\n",
    "        if len(self.isolated) == 0:\n",
    "            print(\"No isolated cuboids found. Pausing...\")\n",
    "            self.logger.log(\"No cuboids found in the selected region. Pausing...\")\n",
    "            self.state = RobotState.IDLE\n",
    "            return\n",
    "\n",
    "        next_well = self.routine.get_next_well()\n",
    "        cuboids_to_fill = self.routine.well_plan[next_well] - self.routine.filled_wells[next_well]\n",
    "        if not self.config.one_by_one:\n",
    "            if len(self.isolated) > cuboids_to_fill:\n",
    "                self.cuboid_choice = self.isolated.sample(n=cuboids_to_fill)\n",
    "            else:\n",
    "                self.cuboid_choice = self.isolated\n",
    "        else:\n",
    "            self.cuboid_choice = self.isolated.sample(n=1)\n",
    "\n",
    "        self.logger.log_table(self.cuboid_choice.loc[:, self.cuboid_choice.columns != 'contour'], title=f\"Filling well {next_well}\")\n",
    "        plot_frame = self.current_frame.copy()\n",
    "        self.draw_annotations(plot_frame)\n",
    "        self.display_process.send_frame(plot_frame)\n",
    "        \n",
    "        self.state = RobotState.APPROACH_TARGET\n",
    "\n",
    "    def state_approach_target(self):\n",
    "        cuboid_coordinates = self.cuboid_choice[['cX', 'cY']].values\n",
    "        self.world_coordinates = []\n",
    "        for cX, cY in cuboid_coordinates:\n",
    "            X, Y = self.calculate_robot_coordinates(cX, cY, self.calib_origin[0], self.calib_origin[1])\n",
    "            self.world_coordinates.append((X, Y))\n",
    "        self.state = RobotState.PICKUP_SAMPLE\n",
    "\n",
    "    def state_pickup_sample(self):\n",
    "        for x,y in self.world_coordinates:\n",
    "            openapi.move_to_coordinates((x, y, self.config.pickup_height+20), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.move_to_coordinates((x, y, self.config.pickup_height), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.aspirate_in_place(flow_rate = self.config.flow_rate, volume = self.config.vol)\n",
    "            openapi.move_relative('z', 20)\n",
    "\n",
    "        self.state = RobotState.VERIFY_PICKUP\n",
    "\n",
    "    def state_verify_pickup(self):\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],115), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "        time.sleep(0.5)\n",
    "        ret, frame = over_cam.read()\n",
    "        self.current_frame = frame_ops.undistort_frame(frame)\n",
    "        self.cv_pipeline(self.current_frame)\n",
    "\n",
    "        plot_frame = self.current_frame.copy()\n",
    "        self.draw_annotations(plot_frame)\n",
    "        miss_occurred = False\n",
    "        if self.cuboid_choice is not None:\n",
    "            for prev_x, prev_y in self.cuboid_choice[['cX', 'cY']].values:\n",
    "                cv2.circle(plot_frame, (int(prev_x), int(prev_y)), int(round(self.config.failure_threshold / self.one_d_ratio)), (255, 0, 0), 2)\n",
    "                check_miss_df = self.cr.cuboid_df.loc[(self.cr.cuboid_df['bubble'] != True)].copy()\n",
    "                distances = check_miss_df.apply(lambda row: np.sqrt((row['cX'] - prev_x)**2 + (row['cY'] - prev_y)**2), axis=1).to_numpy()\n",
    "                distances *= self.one_d_ratio\n",
    "                if any(distances <= self.config.failure_threshold):\n",
    "                    print(f\"Miss detected at well {self.routine.current_well}.\")\n",
    "                    self.routine.update_well(success=False)\n",
    "                    miss_occurred = True\n",
    "                    self.logger.log(f\"Miss detected at well {self.routine.current_well}.\")\n",
    "                else:\n",
    "                    self.routine.update_well(success=True)\n",
    "\n",
    "        if miss_occurred:\n",
    "            self.state = RobotState.DEPOSIT_BACK\n",
    "        else:\n",
    "            self.state = RobotState.TRANSFER_TO_WELL\n",
    "\n",
    "        self.display_process.send_frame(plot_frame)\n",
    "        \n",
    "\n",
    "    def state_deposit_liquid_back(self):\n",
    "        for x,y in self.world_coordinates:\n",
    "            openapi.move_to_coordinates((x, y, self.config.pickup_height+20), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.move_to_coordinates((x, y, self.config.pickup_height), min_z_height=self.config.dish_bottom, verbose=False, force_direct=True)\n",
    "            openapi.dispense_in_place(flow_rate = self.config.flow_rate, volume = self.config.vol * len(self.world_coordinates))\n",
    "            openapi.move_relative('z', 20)\n",
    "\n",
    "        self.state = RobotState.CAPTURE_FRAME\n",
    "\n",
    "    def state_transfer_to_well(self):\n",
    "\n",
    "        openapi.move_to_well(openapi.labware_dct[str(self.config.destination_slot)], self.current_well, \n",
    "                             well_location='top', \n",
    "                             offset=(self.config.well_offset_x, self.config.well_offset_y, 5), \n",
    "                             verbose = False, \n",
    "                             force_direct = True)\n",
    "        openapi.dispense(openapi.labware_dct[str(self.config.destination_slot)], self.current_well, \n",
    "                         well_location='bottom', \n",
    "                         offset=(self.config.well_offset_x, self.config.well_offset_y, self.config.deposit_offset_z), \n",
    "                         volume = self.config.vol * len(self.world_coordinates), \n",
    "                         flow_rate = self.config.flow_rate)\n",
    "        \n",
    "        time.sleep(self.config.wait_time_after_deposit)\n",
    "        \n",
    "        openapi.move_to_well(openapi.labware_dct[str(self.config.destination_slot)], self.current_well, \n",
    "                             well_location='top', \n",
    "                             offset=(self.config.well_offset_x, self.config.well_offset_y, 5), \n",
    "                             verbose=False)\n",
    "        openapi.move_to_coordinates((self.calib_origin[0],self.calib_origin[1],115), \n",
    "                                    min_z_height=self.config.dish_bottom, \n",
    "                                    verbose=False, \n",
    "                                    force_direct=True)\n",
    "\n",
    "        self.current_well = self.routine.get_next_well() # Check if the routine is done\n",
    "        if self.routine.is_done():\n",
    "            self.state = RobotState.COMPLETED\n",
    "        else:\n",
    "            self.state = RobotState.CAPTURE_FRAME\n",
    "\n",
    "    def state_completed(self):\n",
    "        self.end_time = time.time()\n",
    "        print(\"Process completed successfully.\")\n",
    "        self.logger.log(\"Picking procedure finished.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        self.running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "picking_settings = {'vol': 10.0,\n",
    "                    'dish_bottom': 66.1,\n",
    "                    'pickup_offset': 0.5,\n",
    "                    'flow_rate': 50.0,\n",
    "                    'cuboid_size_theshold': (300, 550),\n",
    "                    'failure_threshold': 0.5,\n",
    "                    'minimum_distance': 2.0,\n",
    "                    'wait_time_after_deposit': 0.3,\n",
    "                    'one_by_one': False,\n",
    "                    'well_offset_x': 0.0,\n",
    "                    'well_offset_y': 0.0,\n",
    "                    'deposit_offset_z': 0.2,\n",
    "                    'destination_slot': 5,\n",
    "                    'circle_center': (1296, 972),\n",
    "                    'circle_radius': 900,\n",
    "                    'contour_filter_window': (50, 3000),\n",
    "                    'aspect_ratio_window': (0.85, 1.15),\n",
    "                    'circularity_window': (0.6, 0.9)}\n",
    "\n",
    "picking_config = PickingConfig.from_dict(picking_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   2   3   4   5   6   7   8   9   10  11  12\n",
       "A   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "B   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "C   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "D   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "E   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "F   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "G   2   2   2   2   2   2   2   2   2   2   2   2\n",
       "H   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_type = 96\n",
    "dest = Destination(plate_type)\n",
    "well_df = create_well_plan(plate_type)\n",
    "well_df.loc['G', :] = 2\n",
    "\n",
    "# well_df.loc['A', :] = 1\n",
    "well_plan = {f\"{row}{col}\": well_df.loc[row, col] for row in well_df.index for col in well_df.columns if well_df.loc[row, col] > 0}\n",
    "well_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine = Routine(dest, well_plan, fill_strategy=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tissue Picker Robot FSM Started ===\n",
      "  'p' - Pause/Resume\n",
      "  'ESC' - Emergency stop and quit\n",
      "============================================================\n",
      "Keyboard hooks registered successfully!\n",
      "Display process started with PID: 3196\n",
      "Robot is idle. Press 'p' to continue...\n",
      "No isolated cuboids found. Pausing...\n",
      "Robot is idle. Press 'p' to continue...\n",
      "Process completed successfully.\n",
      "\n",
      "=== Tissue Picker Robot FSM Stopped ===\n"
     ]
    }
   ],
   "source": [
    "logger = MarkdownLogger(experiment_name=\"New-platform-test\", settings=picking_settings, well_plate=well_df)\n",
    "logger.log_section(\"Execution start:\")\n",
    "fsm = TissuePickerFSM(picking_config, routine, logger)\n",
    "fsm.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vol': 10.0,\n",
       " 'dish_bottom': 66.1,\n",
       " 'pickup_offset': 0.5,\n",
       " 'pickup_height': 66.6,\n",
       " 'flow_rate': 50.0,\n",
       " 'cuboid_size_theshold': (300, 550),\n",
       " 'failure_threshold': 0.5,\n",
       " 'minimum_distance': 2.0,\n",
       " 'wait_time_after_deposit': 0.3,\n",
       " 'one_by_one': False,\n",
       " 'well_offset_x': 0.0,\n",
       " 'well_offset_y': 0.0,\n",
       " 'deposit_offset_z': 0.2,\n",
       " 'destination_slot': 5,\n",
       " 'circle_center': (1296, 972),\n",
       " 'circle_radius': 900,\n",
       " 'contour_filter_window': (50, 3000),\n",
       " 'aspect_ratio_window': (0.85, 1.15),\n",
       " 'circularity_window': (0.4, 0.9)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsm.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B1'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routine.current_well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TissuePickerFSM' object has no attribute 'end_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fsm\u001b[38;5;241m.\u001b[39mstart_time \u001b[38;5;241m-\u001b[39m \u001b[43mfsm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_time\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TissuePickerFSM' object has no attribute 'end_time'"
     ]
    }
   ],
   "source": [
    "fsm.start_time - fsm.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.dispense_in_place(flow_rate = 50, volume = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuboid recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "\n",
    "# window = cap.get_window()\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    global circle_center\n",
    "    global circle_radius\n",
    "    global filtered_contours\n",
    "    global X_init, Y_init\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONDOWN:\n",
    "        circle_center = (x, y)\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            circle_radius += 10\n",
    "        else:\n",
    "            circle_radius -= 10\n",
    "\n",
    "    # if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "    #     for contour in filtered_contours:\n",
    "    #         r=cv2.pointPolygonTest(contour, (x,y), False)\n",
    "    #         if r>0:\n",
    "    #             M = cv2.moments(contour)\n",
    "    #             if M[\"m00\"] != 0:\n",
    "    #                 cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    #                 cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    #                 X_init, Y_init, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "    #                 x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "    #                 diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "    #                 X = X_init + diff[0] + offset[0]\n",
    "    #                 Y = Y_init + diff[1] + offset[1]\n",
    "                    \n",
    "    #                 print(f\"Robot coords: ({x}, {y})\")\n",
    "    #                 print(f\"Clicked on: ({X}, {Y})\")\n",
    "    #                 openapi.move_to_coordinates((X, Y, 15), min_z_height=1, verbose=False)\n",
    "    #                 # openapi.aspirate_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "                    \n",
    "    #             else:\n",
    "    #                 print(\"Contour center could not be found\")\n",
    "\n",
    "    # if event == cv2.EVENT_RBUTTONDOWN:\n",
    "    #     x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "    #     # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "    #     openapi.move_to_coordinates((calib_origin[0],calib_origin[1],100), min_z_height=1, verbose=False)\n",
    "\n",
    "        \n",
    "\n",
    "# cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "circle_center = (int(1296.0), int(972.0))\n",
    "circle_radius = 900\n",
    "# manual_movement = utils.ManualRobotMovement(openapi)\n",
    "cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"video\", 1348, 1011)\n",
    "while True:\n",
    "    ret, frame = over_cam.read()\n",
    "    # x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    # (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    # cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    # cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.circle(frame, circle_center, circle_radius, (255, 0, 0), 2)\n",
    "    # Create a mask with the same dimensions as the frame\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "\n",
    "    # Draw a filled circle on the mask\n",
    "    cv2.circle(mask, circle_center, circle_radius, (255, 255, 255), -1)\n",
    "\n",
    "    # Apply the mask to the frame\n",
    "    masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "    # Convert the masked frame to grayscale\n",
    "    gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply thresholding to the grayscale image\n",
    "    # _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,41,2) \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    # Fill the area outside the circle with black pixels\n",
    "    # Convert the mask to grayscale\n",
    "    mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "    # frame[thresh == 255] = [0, 255, 0]\n",
    "\n",
    "    # Find contours in the masked frame\n",
    "    contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "\n",
    "    # Filter the contours to exclude the outermost\n",
    "    filtered_contours = [contour for contour, h in zip(contours, hei[0]) if h[3] == 1]\n",
    "    # Filter the contours by size\n",
    "    filtered_contours = [contour for contour in contours if 15 < cv2.contourArea(contour) < 1000]\n",
    "    # Draw the contours on the frame\n",
    "    cv2.drawContours(frame, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"video\", frame)\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "\n",
    "    if key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_well(openapi.labware_dct['6'], 'A1', well_location='top', offset=(1,-1,0), verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
