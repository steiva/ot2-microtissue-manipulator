{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the upstream directory to sys.path\n",
    "upstream_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if upstream_dir not in sys.path:\n",
    "    sys.path.insert(0, upstream_dir)\n",
    "\n",
    "# Now you can import the module\n",
    "from opentrons_api import ot2_api\n",
    "from microtissue_manipulator import core, utils\n",
    "import numpy as np \n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import keyboard\n",
    "# from pynput import keyboard\n",
    "from configs import paths\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile 'standardDeck' already exists at C:\\Users\\ivand\\Desktop\\ot2-microtissue-manipulator\\configs\\standardDeck.\n"
     ]
    }
   ],
   "source": [
    "utils.create_configuration_profile('standardDeck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using camera without buffer ...\n",
      "Camera initialized ...\n"
     ]
    }
   ],
   "source": [
    "cap = core.Camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi = ot2_api.OpentronsAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [200]>\n",
      "{\n",
      "  \"message\": \"Homing robot.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.home_robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [201]>\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": \"721289ae-acf2-49d0-a3c5-aa8704077528\",\n",
      "    \"ok\": true,\n",
      "    \"createdAt\": \"2024-11-01T23:49:56.924892+00:00\",\n",
      "    \"status\": \"idle\",\n",
      "    \"current\": true,\n",
      "    \"actions\": [],\n",
      "    \"errors\": [],\n",
      "    \"hasEverEnteredErrorRecovery\": false,\n",
      "    \"pipettes\": [],\n",
      "    \"modules\": [],\n",
      "    \"labware\": [],\n",
      "    \"liquids\": [],\n",
      "    \"labwareOffsets\": [],\n",
      "    \"runTimeParameters\": []\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.create_run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of runs: 20\n",
      "Current run ID: 721289ae-acf2-49d0-a3c5-aa8704077528\n",
      "Current run status: idle\n"
     ]
    }
   ],
   "source": [
    "_ = openapi.get_run_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [201]>\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": \"da6da9e5-84ca-42d6-9c00-766ab9056197\",\n",
      "    \"createdAt\": \"2024-11-01T23:50:07.306471+00:00\",\n",
      "    \"commandType\": \"loadPipette\",\n",
      "    \"key\": \"da6da9e5-84ca-42d6-9c00-766ab9056197\",\n",
      "    \"status\": \"succeeded\",\n",
      "    \"params\": {\n",
      "      \"pipetteName\": \"p300_single_gen2\",\n",
      "      \"mount\": \"left\"\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"pipetteId\": \"8f198455-b39a-484e-805b-ac3b83173b0c\"\n",
      "    },\n",
      "    \"startedAt\": \"2024-11-01T23:50:07.308431+00:00\",\n",
      "    \"completedAt\": \"2024-11-01T23:50:09.436091+00:00\",\n",
      "    \"intent\": \"setup\",\n",
      "    \"notes\": []\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.load_pipette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 127.37760524236512, 'y': 0.24289671842729632, 'z': 152.09999999999997}\n"
     ]
    }
   ],
   "source": [
    "_ = openapi.get_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labware ID:\n",
      "6fb0490f-4f51-4e76-8101-08075f0b96bf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a tip rack. This is the default tip rack for the robot.\n",
    "TIP_RACK = \"opentrons_96_tiprack_300ul\"\n",
    "#Load the tip rack. Slot = 1 by default.\n",
    "openapi.load_labware(TIP_RACK, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_labware_path = os.path.join(paths.BASE_DIR,'protocols','vwr_96_tiprack_200ul.json')\n",
    "with open(custom_labware_path, 'r') as json_file:\n",
    "    custom_labware = json.load(json_file)\n",
    "\n",
    "command_dict = {\n",
    "            \"data\": custom_labware\n",
    "        }\n",
    "\n",
    "command_payload = json.dumps(command_dict)\n",
    "url = openapi.runs_url + f'/{openapi.run_id}/' + 'labware_definitions'\n",
    "r = openapi.post(url = url, headers = openapi.HEADERS,\n",
    "            params={\"waitUntilComplete\": True}, data = command_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labware ID:\n",
      "756d1bdd-9303-42f1-b2ee-3772eef3fddf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a tip rack. This is the default tip rack for the robot.\n",
    "TIP_RACK = \"vwr_96_tiprack_200ul\"\n",
    "#Load the tip rack. Slot = 1 by default.\n",
    "openapi.load_labware(TIP_RACK, 9, namespace='custom_beta',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_dict = {\n",
    "            \"data\": {\n",
    "                \"commandType\": \"moveLabware\",\n",
    "                \"params\": {\n",
    "                    \"labwareId\": openapi.labware_dct['9'],\n",
    "                    \"newLocation\": \"offDeck\",\n",
    "                    \"strategy\": \"manualMoveWithoutPause\"\n",
    "                },\n",
    "                \"intent\": \"setup\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "command_payload = json.dumps(command_dict)\n",
    "r = openapi.post(url = openapi.commands_url, headers = openapi.HEADERS,\n",
    "            params={\"waitUntilComplete\": True}, data = command_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'id': '29acc534-6780-4d36-b3ea-a5d12b586c22',\n",
       "  'createdAt': '2024-10-28T23:00:47.268940+00:00',\n",
       "  'commandType': 'moveLabware',\n",
       "  'key': '29acc534-6780-4d36-b3ea-a5d12b586c22',\n",
       "  'status': 'succeeded',\n",
       "  'params': {'labwareId': '910f9cd5-1336-46af-be0d-b405312a395f',\n",
       "   'newLocation': 'offDeck',\n",
       "   'strategy': 'manualMoveWithoutPause'},\n",
       "  'result': {},\n",
       "  'startedAt': '2024-10-28T23:00:47.270943+00:00',\n",
       "  'completedAt': '2024-10-28T23:00:47.272947+00:00',\n",
       "  'intent': 'setup',\n",
       "  'notes': []}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openapi.pick_up_tip(openapi.labware_dct['9'], \"H12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': None,\n",
       " '2': None,\n",
       " '3': None,\n",
       " '4': None,\n",
       " '5': None,\n",
       " '6': None,\n",
       " '7': None,\n",
       " '8': None,\n",
       " '9': 'a79475eb-b7c9-4c10-9df8-286d7bd56da4',\n",
       " '10': None,\n",
       " '11': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.labware_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'id': '6d0ea145-1de0-4909-83e0-58457a0e1397',\n",
       "  'createdAt': '2024-10-24T03:39:37.516312+00:00',\n",
       "  'commandType': 'pickUpTip',\n",
       "  'key': '6d0ea145-1de0-4909-83e0-58457a0e1397',\n",
       "  'status': 'failed',\n",
       "  'params': {'labwareId': '9fb245c4-eb0e-4ff1-ae11-10440de8bc4c',\n",
       "   'wellName': 'A1',\n",
       "   'wellLocation': {'origin': 'top', 'offset': {'x': 0.0, 'y': 0.0, 'z': 0.0}},\n",
       "   'pipetteId': '08b19b0b-6d8d-4652-ba68-d7a21ebf7819'},\n",
       "  'error': {'id': '41bf86cc-f69b-4a1a-9489-88959da8edab',\n",
       "   'createdAt': '2024-10-24T03:39:37.524690+00:00',\n",
       "   'isDefined': False,\n",
       "   'errorType': 'LabwareNotLoadedError',\n",
       "   'errorCode': '4000',\n",
       "   'detail': 'Labware 9fb245c4-eb0e-4ff1-ae11-10440de8bc4c not found.',\n",
       "   'errorInfo': {},\n",
       "   'wrappedErrors': []},\n",
       "  'startedAt': '2024-10-24T03:39:37.518471+00:00',\n",
       "  'completedAt': '2024-10-24T03:39:37.524690+00:00',\n",
       "  'intent': 'setup',\n",
       "  'notes': []}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.drop_tip(openapi.labware_dct['9'], \"H12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.move_relative(axis=\"z\", distance=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move around with camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Clicked at pixel coordinate: ({}, {})\".format(x, y))\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=False)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        del manual_movement\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"test.jpg\", frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record robot positions and write to calibration.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration.json file exists.\n"
     ]
    }
   ],
   "source": [
    "calibration_profile = 'standardDeck'\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Clicked at pixel coordinate: ({}, {})\".format(x, y))\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=False)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "utils.check_calibration_config(calibration_profile)\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "calibration_data['robot_coords'] = manual_movement.positions\n",
    "utils.save_calibration_config(calibration_profile, calibration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aruco marker test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "squaresX=7\n",
    "squaresY=5 \n",
    "squareLength=0.022\n",
    "markerLength=0.011\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "params = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "board = cv2.aruco.CharucoBoard((squaresX, squaresY), squareLength, markerLength, aruco_dict)\n",
    "\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "while True:\n",
    " # Capture frame-by-frame\n",
    "    frame = cap.get_frame(undist=True)\n",
    "\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(frame)\n",
    "    # print(marker_corners)\n",
    "\n",
    "    top_left =  []\n",
    "    if marker_ids is not None:\n",
    "        for i in range(len(marker_ids)):\n",
    "            corner = marker_corners[i][0][0]  # Upper left corner\n",
    "            top_left.append(corner)\n",
    "            cv2.circle(frame, tuple(corner.astype(int)), 5, (0, 255, 0), -1)\n",
    "            # cv2.putText(frame, str(marker_ids[i][0]), (int(corner[0]), int(corner[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"({int(corner[0])}, {int(corner[1])})\", (int(corner[0]), int(corner[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "# cap.release_camera()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1786.,  564.], dtype=float32),\n",
       " array([738., 581.], dtype=float32),\n",
       " array([1792., 1264.], dtype=float32),\n",
       " array([ 753., 1278.], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record pixel coordinates and write to calibration.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155.0, 49.00000000000001, 100.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "x,y,z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.move_to_coordinates((155,49,100), min_z_height=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration.json file exists.\n"
     ]
    }
   ],
   "source": [
    "openapi.move_to_coordinates((155,49,100), min_z_height=1, verbose=False)\n",
    "\n",
    "calibration_profile = 'standardDeck'\n",
    "squaresX=7\n",
    "squaresY=5 \n",
    "squareLength=0.022\n",
    "markerLength=0.011\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "params = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "board = cv2.aruco.CharucoBoard((squaresX, squaresY), squareLength, markerLength, aruco_dict)\n",
    "\n",
    "\n",
    "window = cap.get_window()\n",
    "while True:\n",
    " # Capture frame-by-frame\n",
    "    frame = cap.get_frame(undist=True)\n",
    "\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(frame)\n",
    "    # print(marker_corners)\n",
    "\n",
    "    top_left =  []\n",
    "    if marker_ids is not None:\n",
    "        for i in range(len(marker_ids)):\n",
    "            corner = marker_corners[i][0][0]  # Upper left corner\n",
    "            top_left.append(corner)\n",
    "            cv2.circle(frame, tuple(corner.astype(int)), 5, (0, 255, 0), -1)\n",
    "            # cv2.putText(frame, str(marker_ids[i][0]), (int(corner[0]), int(corner[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"({int(corner[0])}, {int(corner[1])})\", (int(corner[0]), int(corner[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "# cap.release_camera()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "top_left_array = np.array(top_left)\n",
    "top_left_array.tolist()\n",
    "x,y,z = openapi.get_position(verbose=False)[0].values()\n",
    "\n",
    "\n",
    "utils.check_calibration_config(calibration_profile)\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "if len(top_left_array) != 4:\n",
    "    raise ValueError(\"Markers not detected. Please try again.\")\n",
    "else:\n",
    "    calibration_data['camera_coords'] = top_left_array.tolist()\n",
    "    calibration_data['calib_origin'] = [x,y,z]\n",
    "\n",
    "\n",
    "utils.save_calibration_config(calibration_profile, calibration_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_profile = 'standardDeck'\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "camera_coords = calibration_data['camera_coords']\n",
    "robot_coords = calibration_data['robot_coords']\n",
    "robot_coords = np.array(robot_coords)[:,:2].tolist()\n",
    "\n",
    "camera_coords = utils.sort_coordinates(camera_coords)\n",
    "robot_coords = utils.sort_coordinates(robot_coords, reverse_y=True)\n",
    "\n",
    "robot_to_camera_coords = {tuple(robot_coord): tuple(camera_coord) for robot_coord, camera_coord in zip(robot_coords, camera_coords)}\n",
    "tf_mtx = utils.compute_tf_mtx(robot_to_camera_coords)\n",
    "\n",
    "calibration_data['tf_mtx'] = tf_mtx.tolist()\n",
    "\n",
    "utils.save_calibration_config(calibration_profile, calibration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move and pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths.PROFILES_DIR, 'r') as json_file:\n",
    "    calibration_data = json.load(json_file)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "\n",
    "\n",
    "def on_mouse_click(event, cX, cY, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Clicked at pixel coordinate: ({}, {})\".format(cX, cY))\n",
    "        X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "        x, y, _ = openapi.get_position(verbose=False).values()\n",
    "        diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "        X += diff[0]\n",
    "        Y += diff[1]\n",
    "        print(f\"Robot coords: ({x}, {y})\")\n",
    "        print(f\"Clicked on: ({X}, {Y})\")\n",
    "        openapi.move_to_coordinates((X, Y, 10), min_z_height=1)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False).values()\n",
    "        # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "        openapi.move_to_coordinates((183,49,100), min_z_height=1, verbose=False)\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False).values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record calibration offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot coords: (155.0, 49.0)\n",
      "Clicked on: (200.9965939359119, 128.2350148646557)\n",
      "Robot coords: (155.0, 49.0)\n",
      "Clicked on: (189.13282209561797, 140.4674209833476)\n",
      "Robot coords: (155.0, 49.0)\n",
      "Clicked on: (190.1600433717036, 117.41223780319893)\n",
      "Robot coords: (155.0, 49.0)\n",
      "Clicked on: (212.3739589259393, 116.99842729152495)\n",
      "Robot coords: (155.0, 49.0)\n",
      "Clicked on: (211.6468236163801, 140.1601128854952)\n"
     ]
    }
   ],
   "source": [
    "calibration_profile = 'standardDeck'\n",
    "calibration_data = utils.load_calibration_config(calibration_profile)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])\n",
    "\n",
    "\n",
    "window = cap.get_window()\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    global circle_center\n",
    "    global circle_radius\n",
    "    global filtered_contours\n",
    "    global X, Y\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONDOWN:\n",
    "        circle_center = (x, y)\n",
    "\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            circle_radius += 10\n",
    "        else:\n",
    "            circle_radius -= 10\n",
    "\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        for contour in filtered_contours:\n",
    "            r=cv2.pointPolygonTest(contour, (x,y), False)\n",
    "            if r>0:\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "                    x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "                    diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "                    X += diff[0]# + offset[0]\n",
    "                    Y += diff[1]# + offset[1]\n",
    "                    \n",
    "                    print(f\"Robot coords: ({x}, {y})\")\n",
    "                    print(f\"Clicked on: ({X}, {Y})\")\n",
    "                    openapi.move_to_coordinates((X, Y, 11), min_z_height=1, verbose=False)\n",
    "                    openapi.aspirate_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Contour center could not be found\")\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "        # openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "        openapi.move_to_coordinates((155,49,100), min_z_height=1, verbose=False)\n",
    "\n",
    "        \n",
    "\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "circle_center = (int(0), int(0))\n",
    "circle_radius = 300\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False)[0].values()\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    cv2.rectangle(frame, (10, 0), (10 + text_width, text_height + 70), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.circle(frame, circle_center, circle_radius, (255, 0, 0), 2)\n",
    "    # Create a mask with the same dimensions as the frame\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "\n",
    "    # Draw a filled circle on the mask\n",
    "    cv2.circle(mask, circle_center, circle_radius, (255, 255, 255), -1)\n",
    "\n",
    "    # Apply the mask to the frame\n",
    "    masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "    # Convert the masked frame to grayscale\n",
    "    gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply thresholding to the grayscale image\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Fill the area outside the circle with black pixels\n",
    "    # Convert the mask to grayscale\n",
    "    mask_inv = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.bitwise_and(thresh, mask_inv)\n",
    "\n",
    "\n",
    "    # Find contours in the masked frame\n",
    "    contours, hei = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter the contours to exclude the outermost\n",
    "    # filtered_contours = [contour for contour, h in zip(contours, hei[0]) if h[3] == 1]\n",
    "    # Filter the contours by size\n",
    "    filtered_contours = [contour for contour in contours if 15 < cv2.contourArea(contour) < 300]\n",
    "    # Draw the contours on the frame\n",
    "    cv2.drawContours(frame, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "    if key_pressed == ord('o'):\n",
    "        x, y, _ = openapi.get_position(verbose=False)[0].values()\n",
    "\n",
    "        calibration_data['offset'] = [x-X, y-Y]\n",
    "\n",
    "        utils.save_calibration_config(calibration_profile, calibration_data)\n",
    "\n",
    "    elif key_pressed == ord('d'):\n",
    "        openapi.dispense_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "    elif key_pressed == ord('a'):\n",
    "        openapi.aspirate_in_place(flow_rate = 75, volume = 10)\n",
    "\n",
    "\n",
    "    elif key_pressed == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'id': 'b6305d64-aa5d-4177-a2ab-b3fb663916c9',\n",
       "  'createdAt': '2024-10-24T02:16:16.379713+00:00',\n",
       "  'commandType': 'blowOutInPlace',\n",
       "  'key': 'b6305d64-aa5d-4177-a2ab-b3fb663916c9',\n",
       "  'status': 'succeeded',\n",
       "  'params': {'flowRate': 25.0,\n",
       "   'pipetteId': 'd518c835-ccfd-48ea-a2b3-0f4c2b266520'},\n",
       "  'result': {},\n",
       "  'startedAt': '2024-10-24T02:16:16.381774+00:00',\n",
       "  'completedAt': '2024-10-24T02:16:18.238637+00:00',\n",
       "  'intent': 'setup',\n",
       "  'notes': []}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202.91525716931153, 130.2552449039212)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.39999999999997726, -0.19999999999998863]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_data['offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths.PROFILES_DIR, 'r') as json_file:\n",
    "    calibration_data = json.load(json_file)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "offset = np.array(calibration_data['offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5999999999999659)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': 202.4547281787698, 'y': 130.05610912071882, 'z': 4.0}, <Response [201]>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openapi.get_position(verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
