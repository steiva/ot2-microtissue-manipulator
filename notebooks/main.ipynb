{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the upstream directory to sys.path\n",
    "upstream_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if upstream_dir not in sys.path:\n",
    "    sys.path.insert(0, upstream_dir)\n",
    "\n",
    "# Now you can import the module\n",
    "from opentrons_api import ot2_api\n",
    "from microtissue_manipulator import core, utils\n",
    "import numpy as np \n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import keyboard\n",
    "# from pynput import keyboard\n",
    "from configs import paths\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using camera without buffer ...\n",
      "Camera initialized ...\n"
     ]
    }
   ],
   "source": [
    "cap = core.Camera(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi = ot2_api.OpentronsAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.toggle_lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [200]>\n",
      "{\n",
      "  \"message\": \"Homing robot.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openapi.home_robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.create_run(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of runs: 20\n",
      "Current run ID: 456d3037-5936-4c70-bf59-64b500fd4d6a\n",
      "Current run status: idle\n"
     ]
    }
   ],
   "source": [
    "_ = openapi.get_run_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [201]>\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": \"1693918d-c4b2-4c9b-a226-f4abc9de4ad0\",\n",
      "    \"createdAt\": \"2024-10-03T13:05:18.872339+00:00\",\n",
      "    \"commandType\": \"loadPipette\",\n",
      "    \"key\": \"1693918d-c4b2-4c9b-a226-f4abc9de4ad0\",\n",
      "    \"status\": \"succeeded\",\n",
      "    \"params\": {\n",
      "      \"pipetteName\": \"p300_single_gen2\",\n",
      "      \"mount\": \"left\"\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"pipetteId\": \"48aa3ae3-f94a-42fe-b265-09b1a0fcff11\"\n",
      "    },\n",
      "    \"startedAt\": \"2024-10-03T13:05:18.874358+00:00\",\n",
      "    \"completedAt\": \"2024-10-03T13:05:21.021985+00:00\",\n",
      "    \"intent\": \"setup\",\n",
      "    \"notes\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openapi.load_pipette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 383.154913809626, 'y': 342.3747635258571, 'z': 200.9}\n"
     ]
    }
   ],
   "source": [
    "_ = openapi.get_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labware ID:\n",
      "1c2a8189-6735-4da9-9159-07135cda9d42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define a tip rack. This is the default tip rack for the robot.\n",
    "TIP_RACK = \"opentrons_96_tiprack_300ul\"\n",
    "#Load the tip rack. Slot = 1 by default.\n",
    "openapi.load_labware(TIP_RACK, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.pick_up_tip(openapi.labware_dct['9'], \"A1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.drop_tip(openapi.labware_dct['1'], \"A1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_relative(axis=\"z\", distance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_movement = utils.ManualRobotMovement(openapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard.unhook_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move around with camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Clicked at pixel coordinate: ({}, {})\".format(x, y))\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False).values()\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} mm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record robot positions and write to calibration.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Clicked at pixel coordinate: ({}, {})\".format(x, y))\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "utils.check_calibration_config()\n",
    "\n",
    "with open(paths.CALIBRATION_PATH, 'r') as json_file:\n",
    "    calibration_data = json.load(json_file)\n",
    "\n",
    "calibration_data['robot_coords'] = manual_movement.positions\n",
    "\n",
    "with open(paths.CALIBRATION_PATH, 'w') as json_file:\n",
    "    json.dump(calibration_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record pixel coordinates and write to calibration.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51.37760524236513, 225.2428967184273, 152.09999999999997)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z = openapi.get_position(verbose=False).values()\n",
    "x,y,z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi.move_to_coordinates((51,225,100), min_z_height=1, verbose=False)\n",
    "\n",
    "\n",
    "squaresX=7\n",
    "squaresY=5 \n",
    "squareLength=0.022\n",
    "markerLength=0.011\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "params = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "board = cv2.aruco.CharucoBoard((squaresX, squaresY), squareLength, markerLength, aruco_dict)\n",
    "\n",
    "\n",
    "window = cap.get_window()\n",
    "while True:\n",
    " # Capture frame-by-frame\n",
    "    frame = cap.get_frame(undist=True)\n",
    "\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(frame)\n",
    "    # print(marker_corners)\n",
    "\n",
    "    top_left =  []\n",
    "    if marker_ids is not None:\n",
    "        for i in range(len(marker_ids)):\n",
    "            corner = marker_corners[i][0][0]  # Upper left corner\n",
    "            top_left.append(corner)\n",
    "            cv2.circle(frame, tuple(corner.astype(int)), 5, (0, 255, 0), -1)\n",
    "            # cv2.putText(frame, str(marker_ids[i][0]), (int(corner[0]), int(corner[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"({int(corner[0])}, {int(corner[1])})\", (int(corner[0]), int(corner[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "# cap.release_camera()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "top_left_array = np.array(top_left)\n",
    "top_left_array.tolist()\n",
    "x,y,z = openapi.get_position(verbose=False).values()\n",
    "\n",
    "with open(paths.CALIBRATION_PATH, 'r') as json_file:\n",
    "    calibration_data = json.load(json_file)\n",
    "\n",
    "calibration_data['camera_coords'] = top_left_array.tolist()\n",
    "calibration_data['calib_origin'] = [x,y,z]\n",
    "\n",
    "with open(paths.CALIBRATION_PATH, 'w') as json_file:\n",
    "    json.dump(calibration_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths.CALIBRATION_PATH, 'r') as json_file:\n",
    "    calibration_data = json.load(json_file)\n",
    "\n",
    "camera_coords = calibration_data['camera_coords']\n",
    "robot_coords = calibration_data['robot_coords']\n",
    "robot_coords = np.array(robot_coords)[:,:2].tolist()\n",
    "\n",
    "camera_coords = utils.sort_coordinates(camera_coords)\n",
    "robot_coords = utils.sort_coordinates(robot_coords, reverse_y=True)\n",
    "\n",
    "robot_to_camera_coords = {tuple(robot_coord): tuple(camera_coord) for robot_coord, camera_coord in zip(robot_coords, camera_coords)}\n",
    "tf_mtx = utils.compute_tf_mtx(robot_to_camera_coords)\n",
    "\n",
    "calibration_data['tf_mtx'] = tf_mtx.tolist()\n",
    "\n",
    "with open(paths.CALIBRATION_PATH, 'w') as json_file:\n",
    "    json.dump(calibration_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move and pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths.CALIBRATION_PATH, 'r') as json_file:\n",
    "    calibration_data = json.load(json_file)\n",
    "\n",
    "tf_mtx = np.array(calibration_data['tf_mtx'])\n",
    "calib_origin = np.array(calibration_data['calib_origin'])[:2]\n",
    "\n",
    "\n",
    "def on_mouse_click(event, cX, cY, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Clicked at pixel coordinate: ({}, {})\".format(cX, cY))\n",
    "        X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "\n",
    "        x, y, _ = openapi.get_position(verbose=False).values()\n",
    "        diff = np.array([x,y]) - np.array(calibration_data['calib_origin'])[:2]\n",
    "        X += diff[0]\n",
    "        Y += diff[1]\n",
    "        print(f\"Robot coords: ({x}, {y})\")\n",
    "        print(f\"Clicked on: ({X}, {Y})\")\n",
    "        openapi.move_to_coordinates((X, Y, 10), min_z_height=1)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        x, y, _ = openapi.get_position(verbose=False).values()\n",
    "        openapi.move_to_coordinates((x, y, 100), min_z_height=1)\n",
    "\n",
    "\n",
    "# Create an instance of the ManualRobotMovement class\n",
    "manual_movement = utils.ManualRobotMovement(openapi)\n",
    "\n",
    "window = cap.get_window()\n",
    "cv2.setMouseCallback(cap.window_name, on_mouse_click)\n",
    "while True:\n",
    "    frame = cap.get_frame(undist=True)\n",
    "    x, y, z = openapi.get_position(verbose=False).values()\n",
    "    cv2.putText(frame, f\"Robot coords: ({x:.2f}, {y:.2f}, {z:.2f})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Step size: {manual_movement.step} cm\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(cap.window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        keyboard.unhook_all()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status:\n",
      "<Response [201]>\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": \"1cf40a93-d882-422d-a5e9-fbbe3499c1f7\",\n",
      "    \"createdAt\": \"2024-08-09T09:58:22.375613+00:00\",\n",
      "    \"commandType\": \"moveToCoordinates\",\n",
      "    \"key\": \"1cf40a93-d882-422d-a5e9-fbbe3499c1f7\",\n",
      "    \"status\": \"succeeded\",\n",
      "    \"params\": {\n",
      "      \"minimumZHeight\": 1.0,\n",
      "      \"forceDirect\": false,\n",
      "      \"pipetteId\": \"77850757-0071-4ada-8396-42ec1ba1c667\",\n",
      "      \"coordinates\": {\n",
      "        \"x\": 60.507194082642,\n",
      "        \"y\": 306.7301624781195,\n",
      "        \"z\": 1.0\n",
      "      }\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"position\": {\n",
      "        \"x\": 60.507194082642,\n",
      "        \"y\": 306.7301624781195,\n",
      "        \"z\": 1.0\n",
      "      }\n",
      "    },\n",
      "    \"startedAt\": \"2024-08-09T09:58:22.377527+00:00\",\n",
      "    \"completedAt\": \"2024-08-09T09:58:24.084573+00:00\",\n",
      "    \"intent\": \"setup\",\n",
      "    \"notes\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openapi.move_to_coordinates((X,Y,1), min_z_height=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
